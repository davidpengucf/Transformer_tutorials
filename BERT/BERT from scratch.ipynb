{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f118e592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from random import *\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import math\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f692085",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f67b2122",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 30 # maximum of length\n",
    "batch_size = 6\n",
    "max_pred = 5  # max tokens of prediction\n",
    "n_layers = 6 # number of Encoder of Encoder Layer\n",
    "n_heads = 12 # number of heads in Multi-Head Attention\n",
    "d_model = 768 # Embedding Size\n",
    "d_ff = 768 * 4  # 4*d_model, FeedForward dimension\n",
    "d_k = d_v = 64  # dimension of K(=Q), V\n",
    "n_segments = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b01c74",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2e49a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\n",
    "       'Hello, how are you? I am Romeo.\\n'\n",
    "       'Hello, Romeo My name is Juliet. Nice to meet you.\\n'\n",
    "       'Nice meet you too. How are you today?\\n'\n",
    "       'Great. My baseball team won the competition.\\n'\n",
    "       'Oh Congratulations, Juliet\\n'\n",
    "       'Thanks you Romeo'\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f6d834c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, how are you? I am Romeo.\\nHello, Romeo My name is Juliet. Nice to meet you.\\nNice meet you too. How are you today?\\nGreat. My baseball team won the competition.\\nOh Congratulations, Juliet\\nThanks you Romeo'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76dd0c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello how are you i am romeo',\n",
       " 'hello romeo my name is juliet nice to meet you',\n",
       " 'nice meet you too how are you today',\n",
       " 'great my baseball team won the competition',\n",
       " 'oh congratulations juliet',\n",
       " 'thanks you romeo']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = re.sub(\"[.,!?\\\\-]\", '', text.lower()).split('\\n')  # filter '.', ',', '?', '!', '\\n' and lower letter\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a7348bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['meet',\n",
       " 'baseball',\n",
       " 'i',\n",
       " 'too',\n",
       " 'competition',\n",
       " 'today',\n",
       " 'oh',\n",
       " 'juliet',\n",
       " 'thanks',\n",
       " 'is',\n",
       " 'to',\n",
       " 'romeo',\n",
       " 'team',\n",
       " 'am',\n",
       " 'nice',\n",
       " 'great',\n",
       " 'are',\n",
       " 'name',\n",
       " 'how',\n",
       " 'my',\n",
       " 'won',\n",
       " 'hello',\n",
       " 'you',\n",
       " 'congratulations',\n",
       " 'the']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = list(set(\" \".join(sentences).split())) # turn sentences to a dictionary\n",
    "word_list"
   ]
  },
  {
   "attachments": {
    "illustration.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "e2bab6ae",
   "metadata": {},
   "source": [
    "![illustration.png](attachment:illustration.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff5e0c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3}\n",
      "{'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3, 'meet': 4}\n",
      "{0: '[PAD]', 1: '[CLS]', 2: '[SEP]', 3: '[MASK]', 4: 'meet'}\n",
      "5\n",
      "{'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3, 'meet': 4, 'baseball': 5}\n",
      "{0: '[PAD]', 1: '[CLS]', 2: '[SEP]', 3: '[MASK]', 4: 'meet', 5: 'baseball'}\n",
      "6\n",
      "{'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3, 'meet': 4, 'baseball': 5, 'i': 6}\n",
      "{0: '[PAD]', 1: '[CLS]', 2: '[SEP]', 3: '[MASK]', 4: 'meet', 5: 'baseball', 6: 'i'}\n",
      "7\n",
      "{'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3, 'meet': 4, 'baseball': 5, 'i': 6, 'too': 7}\n",
      "{0: '[PAD]', 1: '[CLS]', 2: '[SEP]', 3: '[MASK]', 4: 'meet', 5: 'baseball', 6: 'i', 7: 'too'}\n",
      "8\n",
      "{'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3, 'meet': 4, 'baseball': 5, 'i': 6, 'too': 7, 'competition': 8}\n",
      "{0: '[PAD]', 1: '[CLS]', 2: '[SEP]', 3: '[MASK]', 4: 'meet', 5: 'baseball', 6: 'i', 7: 'too', 8: 'competition'}\n",
      "9\n",
      "{'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3, 'meet': 4, 'baseball': 5, 'i': 6, 'too': 7, 'competition': 8, 'today': 9}\n",
      "{0: '[PAD]', 1: '[CLS]', 2: '[SEP]', 3: '[MASK]', 4: 'meet', 5: 'baseball', 6: 'i', 7: 'too', 8: 'competition', 9: 'today'}\n",
      "10\n",
      "{'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3, 'meet': 4, 'baseball': 5, 'i': 6, 'too': 7, 'competition': 8, 'today': 9, 'oh': 10}\n",
      "{0: '[PAD]', 1: '[CLS]', 2: '[SEP]', 3: '[MASK]', 4: 'meet', 5: 'baseball', 6: 'i', 7: 'too', 8: 'competition', 9: 'today', 10: 'oh'}\n",
      "11\n",
      "{'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3, 'meet': 4, 'baseball': 5, 'i': 6, 'too': 7, 'competition': 8, 'today': 9, 'oh': 10, 'juliet': 11}\n",
      "{0: '[PAD]', 1: '[CLS]', 2: '[SEP]', 3: '[MASK]', 4: 'meet', 5: 'baseball', 6: 'i', 7: 'too', 8: 'competition', 9: 'today', 10: 'oh', 11: 'juliet'}\n",
      "12\n",
      "{'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3, 'meet': 4, 'baseball': 5, 'i': 6, 'too': 7, 'competition': 8, 'today': 9, 'oh': 10, 'juliet': 11, 'thanks': 12}\n",
      "{0: '[PAD]', 1: '[CLS]', 2: '[SEP]', 3: '[MASK]', 4: 'meet', 5: 'baseball', 6: 'i', 7: 'too', 8: 'competition', 9: 'today', 10: 'oh', 11: 'juliet', 12: 'thanks'}\n",
      "13\n",
      "{'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3, 'meet': 4, 'baseball': 5, 'i': 6, 'too': 7, 'competition': 8, 'today': 9, 'oh': 10, 'juliet': 11, 'thanks': 12, 'is': 13}\n",
      "{0: '[PAD]', 1: '[CLS]', 2: '[SEP]', 3: '[MASK]', 4: 'meet', 5: 'baseball', 6: 'i', 7: 'too', 8: 'competition', 9: 'today', 10: 'oh', 11: 'juliet', 12: 'thanks', 13: 'is'}\n",
      "14\n",
      "{'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3, 'meet': 4, 'baseball': 5, 'i': 6, 'too': 7, 'competition': 8, 'today': 9, 'oh': 10, 'juliet': 11, 'thanks': 12, 'is': 13, 'to': 14}\n",
      "{0: '[PAD]', 1: '[CLS]', 2: '[SEP]', 3: '[MASK]', 4: 'meet', 5: 'baseball', 6: 'i', 7: 'too', 8: 'competition', 9: 'today', 10: 'oh', 11: 'juliet', 12: 'thanks', 13: 'is', 14: 'to'}\n",
      "15\n",
      "{'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3, 'meet': 4, 'baseball': 5, 'i': 6, 'too': 7, 'competition': 8, 'today': 9, 'oh': 10, 'juliet': 11, 'thanks': 12, 'is': 13, 'to': 14, 'romeo': 15}\n",
      "{0: '[PAD]', 1: '[CLS]', 2: '[SEP]', 3: '[MASK]', 4: 'meet', 5: 'baseball', 6: 'i', 7: 'too', 8: 'competition', 9: 'today', 10: 'oh', 11: 'juliet', 12: 'thanks', 13: 'is', 14: 'to', 15: 'romeo'}\n",
      "16\n",
      "{'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3, 'meet': 4, 'baseball': 5, 'i': 6, 'too': 7, 'competition': 8, 'today': 9, 'oh': 10, 'juliet': 11, 'thanks': 12, 'is': 13, 'to': 14, 'romeo': 15, 'team': 16}\n",
      "{0: '[PAD]', 1: '[CLS]', 2: '[SEP]', 3: '[MASK]', 4: 'meet', 5: 'baseball', 6: 'i', 7: 'too', 8: 'competition', 9: 'today', 10: 'oh', 11: 'juliet', 12: 'thanks', 13: 'is', 14: 'to', 15: 'romeo', 16: 'team'}\n",
      "17\n",
      "{'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3, 'meet': 4, 'baseball': 5, 'i': 6, 'too': 7, 'competition': 8, 'today': 9, 'oh': 10, 'juliet': 11, 'thanks': 12, 'is': 13, 'to': 14, 'romeo': 15, 'team': 16, 'am': 17}\n",
      "{0: '[PAD]', 1: '[CLS]', 2: '[SEP]', 3: '[MASK]', 4: 'meet', 5: 'baseball', 6: 'i', 7: 'too', 8: 'competition', 9: 'today', 10: 'oh', 11: 'juliet', 12: 'thanks', 13: 'is', 14: 'to', 15: 'romeo', 16: 'team', 17: 'am'}\n",
      "18\n",
      "{'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3, 'meet': 4, 'baseball': 5, 'i': 6, 'too': 7, 'competition': 8, 'today': 9, 'oh': 10, 'juliet': 11, 'thanks': 12, 'is': 13, 'to': 14, 'romeo': 15, 'team': 16, 'am': 17, 'nice': 18}\n",
      "{0: '[PAD]', 1: '[CLS]', 2: '[SEP]', 3: '[MASK]', 4: 'meet', 5: 'baseball', 6: 'i', 7: 'too', 8: 'competition', 9: 'today', 10: 'oh', 11: 'juliet', 12: 'thanks', 13: 'is', 14: 'to', 15: 'romeo', 16: 'team', 17: 'am', 18: 'nice'}\n",
      "19\n",
      "{'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3, 'meet': 4, 'baseball': 5, 'i': 6, 'too': 7, 'competition': 8, 'today': 9, 'oh': 10, 'juliet': 11, 'thanks': 12, 'is': 13, 'to': 14, 'romeo': 15, 'team': 16, 'am': 17, 'nice': 18, 'great': 19}\n",
      "{0: '[PAD]', 1: '[CLS]', 2: '[SEP]', 3: '[MASK]', 4: 'meet', 5: 'baseball', 6: 'i', 7: 'too', 8: 'competition', 9: 'today', 10: 'oh', 11: 'juliet', 12: 'thanks', 13: 'is', 14: 'to', 15: 'romeo', 16: 'team', 17: 'am', 18: 'nice', 19: 'great'}\n",
      "20\n",
      "{'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3, 'meet': 4, 'baseball': 5, 'i': 6, 'too': 7, 'competition': 8, 'today': 9, 'oh': 10, 'juliet': 11, 'thanks': 12, 'is': 13, 'to': 14, 'romeo': 15, 'team': 16, 'am': 17, 'nice': 18, 'great': 19, 'are': 20}\n",
      "{0: '[PAD]', 1: '[CLS]', 2: '[SEP]', 3: '[MASK]', 4: 'meet', 5: 'baseball', 6: 'i', 7: 'too', 8: 'competition', 9: 'today', 10: 'oh', 11: 'juliet', 12: 'thanks', 13: 'is', 14: 'to', 15: 'romeo', 16: 'team', 17: 'am', 18: 'nice', 19: 'great', 20: 'are'}\n",
      "21\n",
      "{'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3, 'meet': 4, 'baseball': 5, 'i': 6, 'too': 7, 'competition': 8, 'today': 9, 'oh': 10, 'juliet': 11, 'thanks': 12, 'is': 13, 'to': 14, 'romeo': 15, 'team': 16, 'am': 17, 'nice': 18, 'great': 19, 'are': 20, 'name': 21}\n",
      "{0: '[PAD]', 1: '[CLS]', 2: '[SEP]', 3: '[MASK]', 4: 'meet', 5: 'baseball', 6: 'i', 7: 'too', 8: 'competition', 9: 'today', 10: 'oh', 11: 'juliet', 12: 'thanks', 13: 'is', 14: 'to', 15: 'romeo', 16: 'team', 17: 'am', 18: 'nice', 19: 'great', 20: 'are', 21: 'name'}\n",
      "22\n",
      "{'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3, 'meet': 4, 'baseball': 5, 'i': 6, 'too': 7, 'competition': 8, 'today': 9, 'oh': 10, 'juliet': 11, 'thanks': 12, 'is': 13, 'to': 14, 'romeo': 15, 'team': 16, 'am': 17, 'nice': 18, 'great': 19, 'are': 20, 'name': 21, 'how': 22}\n",
      "{0: '[PAD]', 1: '[CLS]', 2: '[SEP]', 3: '[MASK]', 4: 'meet', 5: 'baseball', 6: 'i', 7: 'too', 8: 'competition', 9: 'today', 10: 'oh', 11: 'juliet', 12: 'thanks', 13: 'is', 14: 'to', 15: 'romeo', 16: 'team', 17: 'am', 18: 'nice', 19: 'great', 20: 'are', 21: 'name', 22: 'how'}\n",
      "23\n",
      "{'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3, 'meet': 4, 'baseball': 5, 'i': 6, 'too': 7, 'competition': 8, 'today': 9, 'oh': 10, 'juliet': 11, 'thanks': 12, 'is': 13, 'to': 14, 'romeo': 15, 'team': 16, 'am': 17, 'nice': 18, 'great': 19, 'are': 20, 'name': 21, 'how': 22, 'my': 23}\n",
      "{0: '[PAD]', 1: '[CLS]', 2: '[SEP]', 3: '[MASK]', 4: 'meet', 5: 'baseball', 6: 'i', 7: 'too', 8: 'competition', 9: 'today', 10: 'oh', 11: 'juliet', 12: 'thanks', 13: 'is', 14: 'to', 15: 'romeo', 16: 'team', 17: 'am', 18: 'nice', 19: 'great', 20: 'are', 21: 'name', 22: 'how', 23: 'my'}\n",
      "24\n",
      "{'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3, 'meet': 4, 'baseball': 5, 'i': 6, 'too': 7, 'competition': 8, 'today': 9, 'oh': 10, 'juliet': 11, 'thanks': 12, 'is': 13, 'to': 14, 'romeo': 15, 'team': 16, 'am': 17, 'nice': 18, 'great': 19, 'are': 20, 'name': 21, 'how': 22, 'my': 23, 'won': 24}\n",
      "{0: '[PAD]', 1: '[CLS]', 2: '[SEP]', 3: '[MASK]', 4: 'meet', 5: 'baseball', 6: 'i', 7: 'too', 8: 'competition', 9: 'today', 10: 'oh', 11: 'juliet', 12: 'thanks', 13: 'is', 14: 'to', 15: 'romeo', 16: 'team', 17: 'am', 18: 'nice', 19: 'great', 20: 'are', 21: 'name', 22: 'how', 23: 'my', 24: 'won'}\n",
      "25\n",
      "{'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3, 'meet': 4, 'baseball': 5, 'i': 6, 'too': 7, 'competition': 8, 'today': 9, 'oh': 10, 'juliet': 11, 'thanks': 12, 'is': 13, 'to': 14, 'romeo': 15, 'team': 16, 'am': 17, 'nice': 18, 'great': 19, 'are': 20, 'name': 21, 'how': 22, 'my': 23, 'won': 24, 'hello': 25}\n",
      "{0: '[PAD]', 1: '[CLS]', 2: '[SEP]', 3: '[MASK]', 4: 'meet', 5: 'baseball', 6: 'i', 7: 'too', 8: 'competition', 9: 'today', 10: 'oh', 11: 'juliet', 12: 'thanks', 13: 'is', 14: 'to', 15: 'romeo', 16: 'team', 17: 'am', 18: 'nice', 19: 'great', 20: 'are', 21: 'name', 22: 'how', 23: 'my', 24: 'won', 25: 'hello'}\n",
      "26\n",
      "{'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3, 'meet': 4, 'baseball': 5, 'i': 6, 'too': 7, 'competition': 8, 'today': 9, 'oh': 10, 'juliet': 11, 'thanks': 12, 'is': 13, 'to': 14, 'romeo': 15, 'team': 16, 'am': 17, 'nice': 18, 'great': 19, 'are': 20, 'name': 21, 'how': 22, 'my': 23, 'won': 24, 'hello': 25, 'you': 26}\n",
      "{0: '[PAD]', 1: '[CLS]', 2: '[SEP]', 3: '[MASK]', 4: 'meet', 5: 'baseball', 6: 'i', 7: 'too', 8: 'competition', 9: 'today', 10: 'oh', 11: 'juliet', 12: 'thanks', 13: 'is', 14: 'to', 15: 'romeo', 16: 'team', 17: 'am', 18: 'nice', 19: 'great', 20: 'are', 21: 'name', 22: 'how', 23: 'my', 24: 'won', 25: 'hello', 26: 'you'}\n",
      "27\n",
      "{'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3, 'meet': 4, 'baseball': 5, 'i': 6, 'too': 7, 'competition': 8, 'today': 9, 'oh': 10, 'juliet': 11, 'thanks': 12, 'is': 13, 'to': 14, 'romeo': 15, 'team': 16, 'am': 17, 'nice': 18, 'great': 19, 'are': 20, 'name': 21, 'how': 22, 'my': 23, 'won': 24, 'hello': 25, 'you': 26, 'congratulations': 27}\n",
      "{0: '[PAD]', 1: '[CLS]', 2: '[SEP]', 3: '[MASK]', 4: 'meet', 5: 'baseball', 6: 'i', 7: 'too', 8: 'competition', 9: 'today', 10: 'oh', 11: 'juliet', 12: 'thanks', 13: 'is', 14: 'to', 15: 'romeo', 16: 'team', 17: 'am', 18: 'nice', 19: 'great', 20: 'are', 21: 'name', 22: 'how', 23: 'my', 24: 'won', 25: 'hello', 26: 'you', 27: 'congratulations'}\n",
      "28\n",
      "{'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3, 'meet': 4, 'baseball': 5, 'i': 6, 'too': 7, 'competition': 8, 'today': 9, 'oh': 10, 'juliet': 11, 'thanks': 12, 'is': 13, 'to': 14, 'romeo': 15, 'team': 16, 'am': 17, 'nice': 18, 'great': 19, 'are': 20, 'name': 21, 'how': 22, 'my': 23, 'won': 24, 'hello': 25, 'you': 26, 'congratulations': 27, 'the': 28}\n",
      "{0: '[PAD]', 1: '[CLS]', 2: '[SEP]', 3: '[MASK]', 4: 'meet', 5: 'baseball', 6: 'i', 7: 'too', 8: 'competition', 9: 'today', 10: 'oh', 11: 'juliet', 12: 'thanks', 13: 'is', 14: 'to', 15: 'romeo', 16: 'team', 17: 'am', 18: 'nice', 19: 'great', 20: 'are', 21: 'name', 22: 'how', 23: 'my', 24: 'won', 25: 'hello', 26: 'you', 27: 'congratulations', 28: 'the'}\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "word_dict = {'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3}\n",
    "print(word_dict)\n",
    "for i, w in enumerate(word_list):\n",
    "    word_dict[w] = i + 4 # add elements to the dictionary\n",
    "    print(word_dict)\n",
    "    number_dict = {i: w for i, w in enumerate(word_dict)}# switch key and values\n",
    "    print(number_dict)\n",
    "    vocab_size = len(word_dict)\n",
    "    print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0620c960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[[25, 22, 20, 26, 6, 17, 15]]\n",
      "[[25, 22, 20, 26, 6, 17, 15], [25, 15, 23, 21, 13, 11, 18, 14, 4, 26]]\n",
      "[[25, 22, 20, 26, 6, 17, 15], [25, 15, 23, 21, 13, 11, 18, 14, 4, 26], [18, 4, 26, 7, 22, 20, 26, 9]]\n",
      "[[25, 22, 20, 26, 6, 17, 15], [25, 15, 23, 21, 13, 11, 18, 14, 4, 26], [18, 4, 26, 7, 22, 20, 26, 9], [19, 23, 5, 16, 24, 28, 8]]\n",
      "[[25, 22, 20, 26, 6, 17, 15], [25, 15, 23, 21, 13, 11, 18, 14, 4, 26], [18, 4, 26, 7, 22, 20, 26, 9], [19, 23, 5, 16, 24, 28, 8], [10, 27, 11]]\n",
      "[[25, 22, 20, 26, 6, 17, 15], [25, 15, 23, 21, 13, 11, 18, 14, 4, 26], [18, 4, 26, 7, 22, 20, 26, 9], [19, 23, 5, 16, 24, 28, 8], [10, 27, 11], [12, 26, 15]]\n"
     ]
    }
   ],
   "source": [
    "token_list = list()\n",
    "print(token_list)\n",
    "for sentence in sentences:\n",
    "    arr = [word_dict[s] for s in sentence.split()]\n",
    "    token_list.append(arr)\n",
    "    print(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16fd9cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch():\n",
    "    batch = []\n",
    "    positive = negative = 0\n",
    "    \n",
    "    while positive != batch_size/2 or negative != batch_size/2:\n",
    "        \n",
    "        tokens_a_index, tokens_b_index= randrange(len(sentences)), randrange(len(sentences)) \n",
    "        print(\"tokens_a_index\", tokens_a_index) # 1\n",
    "        print(\"tokens_b_index\", tokens_b_index) # 3\n",
    "\n",
    "        tokens_a, tokens_b= token_list[tokens_a_index], token_list[tokens_b_index]\n",
    "        # choose token version of sentence a & b\n",
    "        print(\"tokens_a\", tokens_a)\n",
    "        print(\"tokens_b\", tokens_b)\n",
    "\n",
    "        input_ids = [word_dict['[CLS]']] + tokens_a + [word_dict['[SEP]']] + tokens_b + [word_dict['[SEP]']]\n",
    "        # 1 + token_a + 2 + token_b + 2\n",
    "        print(\"input_ids\",input_ids)\n",
    "\n",
    "\n",
    "        segment_ids = [0] * (1 + len(tokens_a) + 1) + [1] * (len(tokens_b) + 1)\n",
    "        #[0,0,0,..,0,1,1,..,1]\n",
    "        print(\"segment_ids\",segment_ids)\n",
    "\n",
    "        # MASK LM\n",
    "        n_pred =  min(max_pred, max(1, int(round(len(input_ids) * 0.15)))) # 15 % of tokens in one sentence\n",
    "        print('n_pred', n_pred) # 3\n",
    "        cand_maked_pos = [i for i, token in enumerate(input_ids)\n",
    "                         if token != word_dict['[CLS]'] and token != word_dict['[SEP]']]\n",
    "        # remove index for special notations\n",
    "        print('cand_maked_pos',cand_maked_pos)\n",
    "       \n",
    "        shuffle(cand_maked_pos)\n",
    "        print('cand_maked_pos',cand_maked_pos)\n",
    "        # shuffle in order to randomly select masked token\n",
    "        \n",
    "        masked_tokens, masked_pos = [], []\n",
    "        \n",
    "        for pos in cand_maked_pos[:n_pred]:\n",
    "            masked_pos.append(pos)\n",
    "            masked_tokens.append(input_ids[pos])\n",
    "            \n",
    "            print('masked_pos',masked_pos) # 16\n",
    "            print('masked_tokens',masked_tokens) # 27\n",
    "            \n",
    "            if random() < 0.8:  # 80%\n",
    "                input_ids[pos] = word_dict['[MASK]'] # make mask\n",
    "            elif random() < 0.5:  # 10%\n",
    "                index = randint(0, vocab_size - 1) # random index in vocabulary\n",
    "                print('index',index) # 0\n",
    "                input_ids[pos] = word_dict[number_dict[index]] # replace\n",
    "            \n",
    "            print('input_ids',input_ids)\n",
    "\n",
    "            # Zero Paddings\n",
    "            n_pad = maxlen - len(input_ids)\n",
    "            print(n_pad,'n_pad') # 10\n",
    "            input_ids.extend([0] * n_pad)\n",
    "            print('input_ids',input_ids)\n",
    "            segment_ids.extend([0] * n_pad) #[0,0,0,..,0,1,1,..,1,0,..,0]\n",
    "            print('segment_ids',segment_ids)\n",
    "\n",
    "           # Zero Padding (100% - 15%) tokens\n",
    "            if max_pred > n_pred:\n",
    "                n_pad = max_pred - n_pred # space that needs to pad\n",
    "                print(n_pad,'n_pad') # 2\n",
    "                masked_tokens.extend([0] * n_pad) \n",
    "                masked_pos.extend([0] * n_pad) \n",
    "                print('masked_tokens',masked_tokens)# [27, 0, 0]\n",
    "                print('masked_pos',masked_pos)# [16, 0, 0]\n",
    "            \n",
    "            if tokens_a_index + 1 == tokens_b_index and positive < batch_size/2: # if a & b are near \n",
    "                batch.append([input_ids, segment_ids, masked_tokens, masked_pos, True]) # IsNext\n",
    "                #[sentence pair, sentence location, masked tokens, masked_pos, IsNext]\n",
    "                positive += 1\n",
    "                print('positive',positive)\n",
    "                print('batch',batch)\n",
    "            elif tokens_a_index + 1 != tokens_b_index and negative < batch_size/2:\n",
    "                batch.append([input_ids, segment_ids, masked_tokens, masked_pos, False]) # NotNext\n",
    "                negative += 1\n",
    "                print('negative',negative)\n",
    "                print('batch',batch)\n",
    "                \n",
    "    \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ad95047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens_a_index 3\n",
      "tokens_b_index 3\n",
      "tokens_a [19, 23, 5, 16, 24, 28, 8]\n",
      "tokens_b [19, 23, 5, 16, 24, 28, 8]\n",
      "input_ids [1, 19, 23, 5, 16, 24, 28, 8, 2, 19, 23, 5, 16, 24, 28, 8, 2]\n",
      "segment_ids [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "n_pred 3\n",
      "cand_maked_pos [1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15]\n",
      "cand_maked_pos [5, 11, 13, 15, 4, 10, 14, 12, 2, 3, 6, 9, 1, 7]\n",
      "masked_pos [5]\n",
      "masked_tokens [24]\n",
      "input_ids [1, 19, 23, 5, 16, 3, 28, 8, 2, 19, 23, 5, 16, 24, 28, 8, 2]\n",
      "13 n_pad\n",
      "input_ids [1, 19, 23, 5, 16, 3, 28, 8, 2, 19, 23, 5, 16, 24, 28, 8, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "segment_ids [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "2 n_pad\n",
      "masked_tokens [24, 0, 0]\n",
      "masked_pos [5, 0, 0]\n",
      "negative 1\n",
      "batch [[[1, 19, 23, 5, 16, 3, 28, 8, 2, 19, 23, 5, 16, 24, 28, 8, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [24, 0, 0], [5, 0, 0], False]]\n",
      "masked_pos [5, 0, 0, 11]\n",
      "masked_tokens [24, 0, 0, 5]\n",
      "input_ids [1, 19, 23, 5, 16, 3, 28, 8, 2, 19, 23, 3, 16, 24, 28, 8, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0 n_pad\n",
      "input_ids [1, 19, 23, 5, 16, 3, 28, 8, 2, 19, 23, 3, 16, 24, 28, 8, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "segment_ids [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "2 n_pad\n",
      "masked_tokens [24, 0, 0, 5, 0, 0]\n",
      "masked_pos [5, 0, 0, 11, 0, 0]\n",
      "negative 2\n",
      "batch [[[1, 19, 23, 5, 16, 3, 28, 8, 2, 19, 23, 3, 16, 24, 28, 8, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [24, 0, 0, 5, 0, 0], [5, 0, 0, 11, 0, 0], False], [[1, 19, 23, 5, 16, 3, 28, 8, 2, 19, 23, 3, 16, 24, 28, 8, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [24, 0, 0, 5, 0, 0], [5, 0, 0, 11, 0, 0], False]]\n",
      "masked_pos [5, 0, 0, 11, 0, 0, 13]\n",
      "masked_tokens [24, 0, 0, 5, 0, 0, 24]\n",
      "input_ids [1, 19, 23, 5, 16, 3, 28, 8, 2, 19, 23, 3, 16, 3, 28, 8, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0 n_pad\n",
      "input_ids [1, 19, 23, 5, 16, 3, 28, 8, 2, 19, 23, 3, 16, 3, 28, 8, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "segment_ids [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "2 n_pad\n",
      "masked_tokens [24, 0, 0, 5, 0, 0, 24, 0, 0]\n",
      "masked_pos [5, 0, 0, 11, 0, 0, 13, 0, 0]\n",
      "negative 3\n",
      "batch [[[1, 19, 23, 5, 16, 3, 28, 8, 2, 19, 23, 3, 16, 3, 28, 8, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [24, 0, 0, 5, 0, 0, 24, 0, 0], [5, 0, 0, 11, 0, 0, 13, 0, 0], False], [[1, 19, 23, 5, 16, 3, 28, 8, 2, 19, 23, 3, 16, 3, 28, 8, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [24, 0, 0, 5, 0, 0, 24, 0, 0], [5, 0, 0, 11, 0, 0, 13, 0, 0], False], [[1, 19, 23, 5, 16, 3, 28, 8, 2, 19, 23, 3, 16, 3, 28, 8, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [24, 0, 0, 5, 0, 0, 24, 0, 0], [5, 0, 0, 11, 0, 0, 13, 0, 0], False]]\n",
      "tokens_a_index 0\n",
      "tokens_b_index 4\n",
      "tokens_a [25, 22, 20, 26, 6, 17, 15]\n",
      "tokens_b [10, 27, 11]\n",
      "input_ids [1, 25, 22, 20, 26, 6, 17, 15, 2, 10, 27, 11, 2]\n",
      "segment_ids [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
      "n_pred 2\n",
      "cand_maked_pos [1, 2, 3, 4, 5, 6, 7, 9, 10, 11]\n",
      "cand_maked_pos [5, 4, 10, 6, 9, 2, 3, 1, 7, 11]\n",
      "masked_pos [5]\n",
      "masked_tokens [6]\n",
      "input_ids [1, 25, 22, 20, 26, 3, 17, 15, 2, 10, 27, 11, 2]\n",
      "17 n_pad\n",
      "input_ids [1, 25, 22, 20, 26, 3, 17, 15, 2, 10, 27, 11, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "segment_ids [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "3 n_pad\n",
      "masked_tokens [6, 0, 0, 0]\n",
      "masked_pos [5, 0, 0, 0]\n",
      "masked_pos [5, 0, 0, 0, 4]\n",
      "masked_tokens [6, 0, 0, 0, 26]\n",
      "input_ids [1, 25, 22, 20, 3, 3, 17, 15, 2, 10, 27, 11, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0 n_pad\n",
      "input_ids [1, 25, 22, 20, 3, 3, 17, 15, 2, 10, 27, 11, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "segment_ids [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "3 n_pad\n",
      "masked_tokens [6, 0, 0, 0, 26, 0, 0, 0]\n",
      "masked_pos [5, 0, 0, 0, 4, 0, 0, 0]\n",
      "tokens_a_index 2\n",
      "tokens_b_index 5\n",
      "tokens_a [18, 4, 26, 7, 22, 20, 26, 9]\n",
      "tokens_b [12, 26, 15]\n",
      "input_ids [1, 18, 4, 26, 7, 22, 20, 26, 9, 2, 12, 26, 15, 2]\n",
      "segment_ids [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
      "n_pred 2\n",
      "cand_maked_pos [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12]\n",
      "cand_maked_pos [8, 6, 3, 1, 2, 10, 7, 4, 12, 5, 11]\n",
      "masked_pos [8]\n",
      "masked_tokens [9]\n",
      "input_ids [1, 18, 4, 26, 7, 22, 20, 26, 3, 2, 12, 26, 15, 2]\n",
      "16 n_pad\n",
      "input_ids [1, 18, 4, 26, 7, 22, 20, 26, 3, 2, 12, 26, 15, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "segment_ids [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "3 n_pad\n",
      "masked_tokens [9, 0, 0, 0]\n",
      "masked_pos [8, 0, 0, 0]\n",
      "masked_pos [8, 0, 0, 0, 6]\n",
      "masked_tokens [9, 0, 0, 0, 20]\n",
      "input_ids [1, 18, 4, 26, 7, 22, 3, 26, 3, 2, 12, 26, 15, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0 n_pad\n",
      "input_ids [1, 18, 4, 26, 7, 22, 3, 26, 3, 2, 12, 26, 15, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "segment_ids [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "3 n_pad\n",
      "masked_tokens [9, 0, 0, 0, 20, 0, 0, 0]\n",
      "masked_pos [8, 0, 0, 0, 6, 0, 0, 0]\n",
      "tokens_a_index 1\n",
      "tokens_b_index 2\n",
      "tokens_a [25, 15, 23, 21, 13, 11, 18, 14, 4, 26]\n",
      "tokens_b [18, 4, 26, 7, 22, 20, 26, 9]\n",
      "input_ids [1, 25, 15, 23, 21, 13, 11, 18, 14, 4, 26, 2, 18, 4, 26, 7, 22, 20, 26, 9, 2]\n",
      "segment_ids [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "n_pred 3\n",
      "cand_maked_pos [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "cand_maked_pos [13, 8, 1, 17, 4, 19, 16, 5, 2, 15, 12, 6, 14, 18, 7, 3, 10, 9]\n",
      "masked_pos [13]\n",
      "masked_tokens [4]\n",
      "index 15\n",
      "input_ids [1, 25, 15, 23, 21, 13, 11, 18, 14, 4, 26, 2, 18, 15, 26, 7, 22, 20, 26, 9, 2]\n",
      "9 n_pad\n",
      "input_ids [1, 25, 15, 23, 21, 13, 11, 18, 14, 4, 26, 2, 18, 15, 26, 7, 22, 20, 26, 9, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "segment_ids [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "2 n_pad\n",
      "masked_tokens [4, 0, 0]\n",
      "masked_pos [13, 0, 0]\n",
      "positive 1\n",
      "batch [[[1, 19, 23, 5, 16, 3, 28, 8, 2, 19, 23, 3, 16, 3, 28, 8, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [24, 0, 0, 5, 0, 0, 24, 0, 0], [5, 0, 0, 11, 0, 0, 13, 0, 0], False], [[1, 19, 23, 5, 16, 3, 28, 8, 2, 19, 23, 3, 16, 3, 28, 8, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [24, 0, 0, 5, 0, 0, 24, 0, 0], [5, 0, 0, 11, 0, 0, 13, 0, 0], False], [[1, 19, 23, 5, 16, 3, 28, 8, 2, 19, 23, 3, 16, 3, 28, 8, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [24, 0, 0, 5, 0, 0, 24, 0, 0], [5, 0, 0, 11, 0, 0, 13, 0, 0], False], [[1, 25, 15, 23, 21, 13, 11, 18, 14, 4, 26, 2, 18, 15, 26, 7, 22, 20, 26, 9, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [4, 0, 0], [13, 0, 0], True]]\n",
      "masked_pos [13, 0, 0, 8]\n",
      "masked_tokens [4, 0, 0, 14]\n",
      "index 8\n",
      "input_ids [1, 25, 15, 23, 21, 13, 11, 18, 8, 4, 26, 2, 18, 15, 26, 7, 22, 20, 26, 9, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0 n_pad\n",
      "input_ids [1, 25, 15, 23, 21, 13, 11, 18, 8, 4, 26, 2, 18, 15, 26, 7, 22, 20, 26, 9, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "segment_ids [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "2 n_pad\n",
      "masked_tokens [4, 0, 0, 14, 0, 0]\n",
      "masked_pos [13, 0, 0, 8, 0, 0]\n",
      "positive 2\n",
      "batch [[[1, 19, 23, 5, 16, 3, 28, 8, 2, 19, 23, 3, 16, 3, 28, 8, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [24, 0, 0, 5, 0, 0, 24, 0, 0], [5, 0, 0, 11, 0, 0, 13, 0, 0], False], [[1, 19, 23, 5, 16, 3, 28, 8, 2, 19, 23, 3, 16, 3, 28, 8, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [24, 0, 0, 5, 0, 0, 24, 0, 0], [5, 0, 0, 11, 0, 0, 13, 0, 0], False], [[1, 19, 23, 5, 16, 3, 28, 8, 2, 19, 23, 3, 16, 3, 28, 8, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [24, 0, 0, 5, 0, 0, 24, 0, 0], [5, 0, 0, 11, 0, 0, 13, 0, 0], False], [[1, 25, 15, 23, 21, 13, 11, 18, 8, 4, 26, 2, 18, 15, 26, 7, 22, 20, 26, 9, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [4, 0, 0, 14, 0, 0], [13, 0, 0, 8, 0, 0], True], [[1, 25, 15, 23, 21, 13, 11, 18, 8, 4, 26, 2, 18, 15, 26, 7, 22, 20, 26, 9, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [4, 0, 0, 14, 0, 0], [13, 0, 0, 8, 0, 0], True]]\n",
      "masked_pos [13, 0, 0, 8, 0, 0, 1]\n",
      "masked_tokens [4, 0, 0, 14, 0, 0, 25]\n",
      "input_ids [1, 3, 15, 23, 21, 13, 11, 18, 8, 4, 26, 2, 18, 15, 26, 7, 22, 20, 26, 9, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0 n_pad\n",
      "input_ids [1, 3, 15, 23, 21, 13, 11, 18, 8, 4, 26, 2, 18, 15, 26, 7, 22, 20, 26, 9, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "segment_ids [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "2 n_pad\n",
      "masked_tokens [4, 0, 0, 14, 0, 0, 25, 0, 0]\n",
      "masked_pos [13, 0, 0, 8, 0, 0, 1, 0, 0]\n",
      "positive 3\n",
      "batch [[[1, 19, 23, 5, 16, 3, 28, 8, 2, 19, 23, 3, 16, 3, 28, 8, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [24, 0, 0, 5, 0, 0, 24, 0, 0], [5, 0, 0, 11, 0, 0, 13, 0, 0], False], [[1, 19, 23, 5, 16, 3, 28, 8, 2, 19, 23, 3, 16, 3, 28, 8, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [24, 0, 0, 5, 0, 0, 24, 0, 0], [5, 0, 0, 11, 0, 0, 13, 0, 0], False], [[1, 19, 23, 5, 16, 3, 28, 8, 2, 19, 23, 3, 16, 3, 28, 8, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [24, 0, 0, 5, 0, 0, 24, 0, 0], [5, 0, 0, 11, 0, 0, 13, 0, 0], False], [[1, 3, 15, 23, 21, 13, 11, 18, 8, 4, 26, 2, 18, 15, 26, 7, 22, 20, 26, 9, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [4, 0, 0, 14, 0, 0, 25, 0, 0], [13, 0, 0, 8, 0, 0, 1, 0, 0], True], [[1, 3, 15, 23, 21, 13, 11, 18, 8, 4, 26, 2, 18, 15, 26, 7, 22, 20, 26, 9, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [4, 0, 0, 14, 0, 0, 25, 0, 0], [13, 0, 0, 8, 0, 0, 1, 0, 0], True], [[1, 3, 15, 23, 21, 13, 11, 18, 8, 4, 26, 2, 18, 15, 26, 7, 22, 20, 26, 9, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [4, 0, 0, 14, 0, 0, 25, 0, 0], [13, 0, 0, 8, 0, 0, 1, 0, 0], True]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[[1,\n",
       "   19,\n",
       "   23,\n",
       "   5,\n",
       "   16,\n",
       "   3,\n",
       "   28,\n",
       "   8,\n",
       "   2,\n",
       "   19,\n",
       "   23,\n",
       "   3,\n",
       "   16,\n",
       "   3,\n",
       "   28,\n",
       "   8,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  [24, 0, 0, 5, 0, 0, 24, 0, 0],\n",
       "  [5, 0, 0, 11, 0, 0, 13, 0, 0],\n",
       "  False],\n",
       " [[1,\n",
       "   19,\n",
       "   23,\n",
       "   5,\n",
       "   16,\n",
       "   3,\n",
       "   28,\n",
       "   8,\n",
       "   2,\n",
       "   19,\n",
       "   23,\n",
       "   3,\n",
       "   16,\n",
       "   3,\n",
       "   28,\n",
       "   8,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  [24, 0, 0, 5, 0, 0, 24, 0, 0],\n",
       "  [5, 0, 0, 11, 0, 0, 13, 0, 0],\n",
       "  False],\n",
       " [[1,\n",
       "   19,\n",
       "   23,\n",
       "   5,\n",
       "   16,\n",
       "   3,\n",
       "   28,\n",
       "   8,\n",
       "   2,\n",
       "   19,\n",
       "   23,\n",
       "   3,\n",
       "   16,\n",
       "   3,\n",
       "   28,\n",
       "   8,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  [24, 0, 0, 5, 0, 0, 24, 0, 0],\n",
       "  [5, 0, 0, 11, 0, 0, 13, 0, 0],\n",
       "  False],\n",
       " [[1,\n",
       "   3,\n",
       "   15,\n",
       "   23,\n",
       "   21,\n",
       "   13,\n",
       "   11,\n",
       "   18,\n",
       "   8,\n",
       "   4,\n",
       "   26,\n",
       "   2,\n",
       "   18,\n",
       "   15,\n",
       "   26,\n",
       "   7,\n",
       "   22,\n",
       "   20,\n",
       "   26,\n",
       "   9,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  [4, 0, 0, 14, 0, 0, 25, 0, 0],\n",
       "  [13, 0, 0, 8, 0, 0, 1, 0, 0],\n",
       "  True],\n",
       " [[1,\n",
       "   3,\n",
       "   15,\n",
       "   23,\n",
       "   21,\n",
       "   13,\n",
       "   11,\n",
       "   18,\n",
       "   8,\n",
       "   4,\n",
       "   26,\n",
       "   2,\n",
       "   18,\n",
       "   15,\n",
       "   26,\n",
       "   7,\n",
       "   22,\n",
       "   20,\n",
       "   26,\n",
       "   9,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  [4, 0, 0, 14, 0, 0, 25, 0, 0],\n",
       "  [13, 0, 0, 8, 0, 0, 1, 0, 0],\n",
       "  True],\n",
       " [[1,\n",
       "   3,\n",
       "   15,\n",
       "   23,\n",
       "   21,\n",
       "   13,\n",
       "   11,\n",
       "   18,\n",
       "   8,\n",
       "   4,\n",
       "   26,\n",
       "   2,\n",
       "   18,\n",
       "   15,\n",
       "   26,\n",
       "   7,\n",
       "   22,\n",
       "   20,\n",
       "   26,\n",
       "   9,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  [4, 0, 0, 14, 0, 0, 25, 0, 0],\n",
       "  [13, 0, 0, 8, 0, 0, 1, 0, 0],\n",
       "  True]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_batch() # 3 IsNext & 3 NotNext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2036f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch():\n",
    "    batch = []\n",
    "    positive = negative = 0\n",
    "    while positive != batch_size/2 or negative != batch_size/2:\n",
    "        tokens_a_index, tokens_b_index= randrange(len(sentences)), randrange(len(sentences)) # sample random index in sentences\n",
    "        tokens_a, tokens_b= token_list[tokens_a_index], token_list[tokens_b_index]\n",
    "        input_ids = [word_dict['[CLS]']] + tokens_a + [word_dict['[SEP]']] + tokens_b + [word_dict['[SEP]']]\n",
    "        segment_ids = [0] * (1 + len(tokens_a) + 1) + [1] * (len(tokens_b) + 1)\n",
    "\n",
    "        # MASK LM\n",
    "        n_pred =  min(max_pred, max(1, int(round(len(input_ids) * 0.15)))) # 15 % of tokens in one sentence\n",
    "        cand_maked_pos = [i for i, token in enumerate(input_ids)\n",
    "                          if token != word_dict['[CLS]'] and token != word_dict['[SEP]']]\n",
    "        shuffle(cand_maked_pos)\n",
    "        masked_tokens, masked_pos = [], []\n",
    "        for pos in cand_maked_pos[:n_pred]:\n",
    "            masked_pos.append(pos)\n",
    "            masked_tokens.append(input_ids[pos])\n",
    "            if random() < 0.8:  # 80%\n",
    "                input_ids[pos] = word_dict['[MASK]'] # make mask\n",
    "            elif random() < 0.5:  # 10%\n",
    "                index = randint(0, vocab_size - 1) # random index in vocabulary\n",
    "                input_ids[pos] = word_dict[number_dict[index]] # replace\n",
    "\n",
    "        # Zero Paddings\n",
    "        n_pad = maxlen - len(input_ids)\n",
    "        input_ids.extend([0] * n_pad)\n",
    "        segment_ids.extend([0] * n_pad)\n",
    "\n",
    "        # Zero Padding (100% - 15%) tokens\n",
    "        if max_pred > n_pred:\n",
    "            n_pad = max_pred - n_pred\n",
    "            masked_tokens.extend([0] * n_pad)\n",
    "            masked_pos.extend([0] * n_pad)\n",
    "\n",
    "        if tokens_a_index + 1 == tokens_b_index and positive < batch_size/2:\n",
    "            batch.append([input_ids, segment_ids, masked_tokens, masked_pos, True]) # IsNext\n",
    "            positive += 1\n",
    "        elif tokens_a_index + 1 != tokens_b_index and negative < batch_size/2:\n",
    "            batch.append([input_ids, segment_ids, masked_tokens, masked_pos, False]) # NotNext\n",
    "            negative += 1\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25cf97b",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44c9aa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn_pad_mask(seq_q, seq_k):\n",
    "    batch_size, len_q = seq_q.size()\n",
    "    batch_size, len_k = seq_k.size()\n",
    "    # eq(zero) is PAD token\n",
    "    pad_attn_mask = seq_k.data.eq(0).unsqueeze(1)  # batch_size x 1 x len_k(=len_q), one is masking\n",
    "    print('pad_attn_mask',pad_attn_mask)\n",
    "    print('pad_attn_mask shape ',pad_attn_mask.shape)\n",
    "    return pad_attn_mask.expand(batch_size, len_q, len_k)  # batch_size x len_q x len_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94c46641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_k tensor([[0.7354, 0.1330, 0.0744],\n",
      "        [0.5275, 0.7637, 0.3040]])\n",
      "test_q tensor([[0.6224, 0.5264, 0.0902],\n",
      "        [0.8424, 0.0373, 0.2110]])\n"
     ]
    }
   ],
   "source": [
    "test_k = torch.rand(size=(2,3))\n",
    "test_q = torch.rand(size=(2,3))\n",
    "print('test_k',test_k)\n",
    "print('test_q',test_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fbc5564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_attn_mask tensor([[[False, False, False]],\n",
      "\n",
      "        [[False, False, False]]])\n",
      "pad_attn_mask shape  torch.Size([2, 1, 3])\n",
      "tensor([[[False, False, False],\n",
      "         [False, False, False],\n",
      "         [False, False, False]],\n",
      "\n",
      "        [[False, False, False],\n",
      "         [False, False, False],\n",
      "         [False, False, False]]])\n",
      "torch.Size([2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "test_pad = get_attn_pad_mask(test_q, test_k)\n",
    "print(test_pad)\n",
    "print(test_pad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8e66e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn_pad_mask(seq_q, seq_k):\n",
    "    batch_size, len_q = seq_q.size()\n",
    "    batch_size, len_k = seq_k.size()\n",
    "    # eq(zero) is PAD token\n",
    "    pad_attn_mask = seq_k.data.eq(0).unsqueeze(1)  # batch_size x 1 x len_k(=len_q), one is masking\n",
    "    \n",
    "    return pad_attn_mask.expand(batch_size, len_q, len_k)  # batch_size x len_q x len_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9655e188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gelu(x):\n",
    "    \"Implementation of the gelu activation function by Hugging Face\"\n",
    "    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a439ec39",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bd82fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.tok_embed = nn.Embedding(vocab_size, d_model)  # token embedding [29, 768]\n",
    "        self.pos_embed = nn.Embedding(maxlen, d_model)  # position embedding [30, 768]\n",
    "        self.seg_embed = nn.Embedding(n_segments, d_model)  # segment(token type) embedding [2, 768]\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, seg):\n",
    "        print('x: ',x.shape)\n",
    "        print('seg: ',seg.shape)\n",
    "        seq_len = x.size(1)\n",
    "        pos = torch.arange(seq_len, dtype=torch.long)\n",
    "        pos = pos.unsqueeze(0).expand_as(x)  # (seq_len,) -> (batch_size, seq_len)\n",
    "        print('pos: ',pos.shape)\n",
    "        print('self.tok_embed(x): ', self.tok_embed(x).shape)\n",
    "        print('self.pos_embed(pos): ', self.pos_embed(pos).shape)\n",
    "        print('self.seg_embed(seg): ', self.seg_embed(seg).shape)\n",
    "        embedding = self.tok_embed(x) + self.pos_embed(pos) + self.seg_embed(seg)\n",
    "        print('embedding: ', embedding.shape)\n",
    "        return self.norm(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42ddc1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, segment_ids, masked_tokens, masked_pos, isNext = map(torch.LongTensor, zip(*make_batch()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4dc8dbe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 30])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape # [batch_size, maxlen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9827681a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 30])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_ids.shape # [batch_size, maxlen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1adf0d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 5])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_tokens.shape # [batch_size, max_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "242e3549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[21, 13,  0,  0,  0],\n",
       "        [22, 15,  0,  0,  0],\n",
       "        [11, 26, 11,  0,  0],\n",
       "        [18, 21,  4,  0,  0],\n",
       "        [26, 17,  6,  0,  0],\n",
       "        [27,  5,  0,  0,  0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58a9c503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 5])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_pos.shape # [batch_size, max_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "efaab5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isNext.shape # [batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e46f7aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  torch.Size([6, 30])\n",
      "seg:  torch.Size([6, 30])\n",
      "pos:  torch.Size([6, 30])\n",
      "self.tok_embed(x):  torch.Size([6, 30, 768])\n",
      "self.pos_embed(pos):  torch.Size([6, 30, 768])\n",
      "self.seg_embed(seg):  torch.Size([6, 30, 768])\n",
      "embedding:  torch.Size([6, 30, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-9.9661e-02, -6.5247e-01,  4.9522e-02,  ...,  1.6345e-01,\n",
       "          -1.3146e+00,  6.7911e-01],\n",
       "         [-1.3974e+00,  1.1710e+00, -9.8288e-01,  ..., -1.4408e+00,\n",
       "          -4.0601e-02,  5.5455e-01],\n",
       "         [-3.5131e-01,  1.0788e+00, -7.0177e-01,  ...,  1.4450e-01,\n",
       "          -5.9342e-01, -1.1547e+00],\n",
       "         ...,\n",
       "         [ 6.0104e-01, -1.6132e-01,  7.4835e-01,  ...,  5.0660e-01,\n",
       "          -6.5927e-01, -5.4013e-02],\n",
       "         [-4.1610e-02, -8.9943e-01,  5.9076e-01,  ...,  6.1654e-01,\n",
       "          -9.6809e-01,  1.0547e+00],\n",
       "         [-4.2931e-01, -5.0186e-01,  1.0174e+00,  ...,  6.7673e-01,\n",
       "          -1.0043e+00,  8.1259e-01]],\n",
       "\n",
       "        [[-9.9661e-02, -6.5247e-01,  4.9522e-02,  ...,  1.6345e-01,\n",
       "          -1.3146e+00,  6.7911e-01],\n",
       "         [-1.1510e+00,  2.5594e-01, -4.5643e-01,  ..., -1.7168e-01,\n",
       "          -5.8113e-01,  1.3377e+00],\n",
       "         [-2.3490e-01,  1.0712e+00, -6.1190e-02,  ..., -1.8848e-01,\n",
       "          -1.4327e+00,  1.4820e-01],\n",
       "         ...,\n",
       "         [ 6.0104e-01, -1.6132e-01,  7.4835e-01,  ...,  5.0660e-01,\n",
       "          -6.5927e-01, -5.4013e-02],\n",
       "         [-4.1610e-02, -8.9943e-01,  5.9076e-01,  ...,  6.1654e-01,\n",
       "          -9.6809e-01,  1.0547e+00],\n",
       "         [-4.2931e-01, -5.0186e-01,  1.0174e+00,  ...,  6.7673e-01,\n",
       "          -1.0043e+00,  8.1259e-01]],\n",
       "\n",
       "        [[-9.9661e-02, -6.5247e-01,  4.9522e-02,  ...,  1.6345e-01,\n",
       "          -1.3146e+00,  6.7911e-01],\n",
       "         [-1.1510e+00,  2.5594e-01, -4.5643e-01,  ..., -1.7168e-01,\n",
       "          -5.8113e-01,  1.3377e+00],\n",
       "         [-1.0194e+00,  6.7800e-01, -1.3185e+00,  ...,  2.7778e-01,\n",
       "          -9.5511e-01,  5.8014e-02],\n",
       "         ...,\n",
       "         [ 6.0104e-01, -1.6132e-01,  7.4835e-01,  ...,  5.0660e-01,\n",
       "          -6.5927e-01, -5.4013e-02],\n",
       "         [-4.1610e-02, -8.9943e-01,  5.9076e-01,  ...,  6.1654e-01,\n",
       "          -9.6809e-01,  1.0547e+00],\n",
       "         [-4.2931e-01, -5.0186e-01,  1.0174e+00,  ...,  6.7673e-01,\n",
       "          -1.0043e+00,  8.1259e-01]],\n",
       "\n",
       "        [[-9.9661e-02, -6.5247e-01,  4.9522e-02,  ...,  1.6345e-01,\n",
       "          -1.3146e+00,  6.7911e-01],\n",
       "         [-1.1510e+00,  2.5594e-01, -4.5643e-01,  ..., -1.7168e-01,\n",
       "          -5.8113e-01,  1.3377e+00],\n",
       "         [-1.0194e+00,  6.7800e-01, -1.3185e+00,  ...,  2.7778e-01,\n",
       "          -9.5511e-01,  5.8014e-02],\n",
       "         ...,\n",
       "         [ 6.0104e-01, -1.6132e-01,  7.4835e-01,  ...,  5.0660e-01,\n",
       "          -6.5927e-01, -5.4013e-02],\n",
       "         [-4.1610e-02, -8.9943e-01,  5.9076e-01,  ...,  6.1654e-01,\n",
       "          -9.6809e-01,  1.0547e+00],\n",
       "         [-4.2931e-01, -5.0186e-01,  1.0174e+00,  ...,  6.7673e-01,\n",
       "          -1.0043e+00,  8.1259e-01]],\n",
       "\n",
       "        [[-9.9661e-02, -6.5247e-01,  4.9522e-02,  ...,  1.6345e-01,\n",
       "          -1.3146e+00,  6.7911e-01],\n",
       "         [-1.1510e+00,  2.5594e-01, -4.5643e-01,  ..., -1.7168e-01,\n",
       "          -5.8113e-01,  1.3377e+00],\n",
       "         [-1.6725e+00,  1.6169e+00, -6.6699e-01,  ..., -3.5127e-06,\n",
       "           7.1366e-01, -9.3940e-01],\n",
       "         ...,\n",
       "         [ 6.0104e-01, -1.6132e-01,  7.4835e-01,  ...,  5.0660e-01,\n",
       "          -6.5927e-01, -5.4013e-02],\n",
       "         [-4.1610e-02, -8.9943e-01,  5.9076e-01,  ...,  6.1654e-01,\n",
       "          -9.6809e-01,  1.0547e+00],\n",
       "         [-4.2931e-01, -5.0186e-01,  1.0174e+00,  ...,  6.7673e-01,\n",
       "          -1.0043e+00,  8.1259e-01]],\n",
       "\n",
       "        [[-9.9661e-02, -6.5247e-01,  4.9522e-02,  ...,  1.6345e-01,\n",
       "          -1.3146e+00,  6.7911e-01],\n",
       "         [-8.6923e-01, -4.8206e-01, -6.5738e-01,  ..., -1.3414e+00,\n",
       "          -3.1662e-01, -5.0531e-01],\n",
       "         [-1.1995e+00,  1.0281e+00, -1.2160e+00,  ...,  1.1540e+00,\n",
       "          -3.7912e-01, -2.2393e-01],\n",
       "         ...,\n",
       "         [ 6.0104e-01, -1.6132e-01,  7.4835e-01,  ...,  5.0660e-01,\n",
       "          -6.5927e-01, -5.4013e-02],\n",
       "         [-4.1610e-02, -8.9943e-01,  5.9076e-01,  ...,  6.1654e-01,\n",
       "          -9.6809e-01,  1.0547e+00],\n",
       "         [-4.2931e-01, -5.0186e-01,  1.0174e+00,  ...,  6.7673e-01,\n",
       "          -1.0043e+00,  8.1259e-01]]], grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Embedding()(input_ids, segment_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "912a04a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.tok_embed = nn.Embedding(vocab_size, d_model)  # token embedding\n",
    "        self.pos_embed = nn.Embedding(maxlen, d_model)  # position embedding\n",
    "        self.seg_embed = nn.Embedding(n_segments, d_model)  # segment(token type) embedding\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, seg):\n",
    "        seq_len = x.size(1)\n",
    "        pos = torch.arange(seq_len, dtype=torch.long)\n",
    "        pos = pos.unsqueeze(0).expand_as(x)  # (seq_len,) -> (batch_size, seq_len)\n",
    "        embedding = self.tok_embed(x) + self.pos_embed(pos) + self.seg_embed(seg)\n",
    "        return self.norm(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94032549",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2e8504b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k) # scores : [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n",
    "        # bnqd * bndk -> bnqk\n",
    "        scores.masked_fill_(attn_mask, -1e9) # Fills elements of self tensor with value where mask is one.\n",
    "        attn = nn.Softmax(dim=-1)(scores) #bnqk\n",
    "        context = torch.matmul(attn, V)\n",
    "        # bnqk * bnvd -> bnqd (k=v)\n",
    "        return context, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a07cc93b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1, 12, 26, 15,  2, 25, 15, 23,  3,  4, 11, 18, 14,  4, 26,  2,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1, 25,  3, 20, 26,  6, 17, 15,  2, 12, 26,  3,  2,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1, 25, 15, 23, 21, 13,  3, 18, 14,  4, 26,  2, 25, 15, 23, 21, 13,  3,\n",
       "         18, 14,  4,  3,  2,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1, 25, 15, 23,  3, 13, 11, 18, 14,  3, 26,  2,  3,  4, 26,  7, 22, 20,\n",
       "         26,  9,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1, 25, 22, 20,  3,  3,  3, 15,  2, 25, 15, 23, 21, 13, 11, 18, 14,  4,\n",
       "         26,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1, 19, 23,  3, 16, 24, 28,  8,  2, 10,  3, 11,  2,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "547e781c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 30, 30])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_attn_pad_mask(input_ids, input_ids).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61f64859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_attn_pad_mask(input_ids, input_ids)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096af62b",
   "metadata": {},
   "source": [
    "### A contiguous tensor is a tensor whose elements are stored in a contiguous order without leaving any empty space between them. A tensor created originally is always a contiguous tensor. A tensor can be viewed with different dimensions in contiguous manner.\n",
    "\n",
    "A transpose of a tensor creates a view of the original tensor which follows non-contiguous order. The transpose of a tensor is non-contiguous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c921a267",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.W_Q = nn.Linear(d_model, d_k * n_heads) # project to 12 heads\n",
    "        self.W_K = nn.Linear(d_model, d_k * n_heads)\n",
    "        self.W_V = nn.Linear(d_model, d_v * n_heads)\n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        # q: [batch_size x len_q x d_model], k: [batch_size x len_k x d_model], v: [batch_size x len_k x d_model]\n",
    "        residual, batch_size = Q, Q.size(0)\n",
    "        # (B, S, D) -proj-> (B, S, D) -split-> (B, S, H, W) -trans-> (B, H, S, W)\n",
    "        q_s = self.W_Q(Q).view(batch_size, -1, n_heads, d_k).transpose(1,2)  \n",
    "        # q_s: [batch_size x n_heads x len_q x d_k] [6, 12, 30, 64]\n",
    "        k_s = self.W_K(K).view(batch_size, -1, n_heads, d_k).transpose(1,2)  \n",
    "        # k_s: [batch_size x n_heads x len_k x d_k]\n",
    "        v_s = self.W_V(V).view(batch_size, -1, n_heads, d_v).transpose(1,2)  \n",
    "        # v_s: [batch_size x n_heads x len_k x d_v]\n",
    "\n",
    "        attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1) \n",
    "        # attn_mask : [batch_size x n_heads x len_q x len_k]\n",
    "\n",
    "        # context: [batch_size x n_heads x len_q x d_v], \n",
    "        # attn: [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n",
    "        context, attn = ScaledDotProductAttention()(q_s, k_s, v_s, attn_mask)\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, n_heads * d_v) \n",
    "        # context: [batch_size x len_q x n_heads * d_v]\n",
    "        # bnqd -> bqnd -> bq(n*d)\n",
    "        output = nn.Linear(n_heads * d_v, d_model)(context)\n",
    "        return nn.LayerNorm(d_model)(output + residual), attn # output: [batch_size x len_q x d_model]\n",
    "        # attn is the score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "764fc6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForwardNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (batch_size, len_seq, d_model) -> (batch_size, len_seq, d_ff) -> (batch_size, len_seq, d_model)\n",
    "        return self.fc2(gelu(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c195baf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.enc_self_attn = MultiHeadAttention()\n",
    "        self.pos_ffn = PoswiseFeedForwardNet()\n",
    "\n",
    "    def forward(self, enc_inputs, enc_self_attn_mask):\n",
    "        enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask) # enc_inputs to same Q,K,V\n",
    "        enc_outputs = self.pos_ffn(enc_outputs) # enc_outputs: [batch_size x len_q x d_model]\n",
    "        return enc_outputs, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4ce83d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[EncoderLayer(\n",
       "   (enc_self_attn): MultiHeadAttention(\n",
       "     (W_Q): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (W_K): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (W_V): Linear(in_features=768, out_features=768, bias=True)\n",
       "   )\n",
       "   (pos_ffn): PoswiseFeedForwardNet(\n",
       "     (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   )\n",
       " ),\n",
       " EncoderLayer(\n",
       "   (enc_self_attn): MultiHeadAttention(\n",
       "     (W_Q): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (W_K): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (W_V): Linear(in_features=768, out_features=768, bias=True)\n",
       "   )\n",
       "   (pos_ffn): PoswiseFeedForwardNet(\n",
       "     (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   )\n",
       " ),\n",
       " EncoderLayer(\n",
       "   (enc_self_attn): MultiHeadAttention(\n",
       "     (W_Q): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (W_K): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (W_V): Linear(in_features=768, out_features=768, bias=True)\n",
       "   )\n",
       "   (pos_ffn): PoswiseFeedForwardNet(\n",
       "     (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   )\n",
       " ),\n",
       " EncoderLayer(\n",
       "   (enc_self_attn): MultiHeadAttention(\n",
       "     (W_Q): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (W_K): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (W_V): Linear(in_features=768, out_features=768, bias=True)\n",
       "   )\n",
       "   (pos_ffn): PoswiseFeedForwardNet(\n",
       "     (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   )\n",
       " ),\n",
       " EncoderLayer(\n",
       "   (enc_self_attn): MultiHeadAttention(\n",
       "     (W_Q): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (W_K): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (W_V): Linear(in_features=768, out_features=768, bias=True)\n",
       "   )\n",
       "   (pos_ffn): PoswiseFeedForwardNet(\n",
       "     (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   )\n",
       " ),\n",
       " EncoderLayer(\n",
       "   (enc_self_attn): MultiHeadAttention(\n",
       "     (W_Q): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (W_K): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (W_V): Linear(in_features=768, out_features=768, bias=True)\n",
       "   )\n",
       "   (pos_ffn): PoswiseFeedForwardNet(\n",
       "     (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   )\n",
       " )]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[EncoderLayer() for _ in range(n_layers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "59b2c7a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(\n",
       "  (tok_embed): Embedding(29, 768)\n",
       "  (pos_embed): Embedding(30, 768)\n",
       "  (seg_embed): Embedding(2, 768)\n",
       "  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9ee3fb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(29, 768)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Embedding().tok_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "19e33710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-1.0918,  1.3855, -1.7424,  ..., -0.0512,  0.9755,  0.3623],\n",
       "        [-1.0756, -0.2863, -0.9207,  ..., -2.1330,  0.0410, -0.3889],\n",
       "        [ 0.5531, -0.7208,  0.4380,  ...,  0.2942, -0.1436,  0.5685],\n",
       "        ...,\n",
       "        [ 0.7188,  0.9811, -0.9178,  ...,  0.1899,  0.3802,  1.6373],\n",
       "        [-0.4209, -0.6946, -0.5199,  ..., -0.8769, -1.7347, -0.7922],\n",
       "        [-0.3904,  0.7730, -1.3695,  ..., -0.4987,  1.1214, -0.3514]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Embedding().tok_embed.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb78b67a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8,  9,  0,  0,  0],\n",
       "        [ 2, 11,  0,  0,  0],\n",
       "        [ 6, 21, 17,  0,  0],\n",
       "        [12,  4,  9,  0,  0],\n",
       "        [ 4,  6,  5,  0,  0],\n",
       "        [10,  3,  0,  0,  0]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c6f315a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 8],\n",
       "         [ 9],\n",
       "         [ 0],\n",
       "         [ 0],\n",
       "         [ 0]],\n",
       "\n",
       "        [[ 2],\n",
       "         [11],\n",
       "         [ 0],\n",
       "         [ 0],\n",
       "         [ 0]],\n",
       "\n",
       "        [[ 6],\n",
       "         [21],\n",
       "         [17],\n",
       "         [ 0],\n",
       "         [ 0]],\n",
       "\n",
       "        [[12],\n",
       "         [ 4],\n",
       "         [ 9],\n",
       "         [ 0],\n",
       "         [ 0]],\n",
       "\n",
       "        [[ 4],\n",
       "         [ 6],\n",
       "         [ 5],\n",
       "         [ 0],\n",
       "         [ 0]],\n",
       "\n",
       "        [[10],\n",
       "         [ 3],\n",
       "         [ 0],\n",
       "         [ 0],\n",
       "         [ 0]]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_pos[:, :, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3bcd0a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 8,  8,  8,  ...,  8,  8,  8],\n",
       "         [ 9,  9,  9,  ...,  9,  9,  9],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]],\n",
       "\n",
       "        [[ 2,  2,  2,  ...,  2,  2,  2],\n",
       "         [11, 11, 11,  ..., 11, 11, 11],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]],\n",
       "\n",
       "        [[ 6,  6,  6,  ...,  6,  6,  6],\n",
       "         [21, 21, 21,  ..., 21, 21, 21],\n",
       "         [17, 17, 17,  ..., 17, 17, 17],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]],\n",
       "\n",
       "        [[12, 12, 12,  ..., 12, 12, 12],\n",
       "         [ 4,  4,  4,  ...,  4,  4,  4],\n",
       "         [ 9,  9,  9,  ...,  9,  9,  9],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]],\n",
       "\n",
       "        [[ 4,  4,  4,  ...,  4,  4,  4],\n",
       "         [ 6,  6,  6,  ...,  6,  6,  6],\n",
       "         [ 5,  5,  5,  ...,  5,  5,  5],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]],\n",
       "\n",
       "        [[10, 10, 10,  ..., 10, 10, 10],\n",
       "         [ 3,  3,  3,  ...,  3,  3,  3],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_pos[:, :, None].expand(-1, -1, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eea8d5bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 5, 768])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_pos[:, :, None].expand(-1, -1, 768).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0be3abd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1],\n",
       "        [4, 3]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([[1, 2], [3, 4]])\n",
    "print(t)\n",
    "torch.gather(t, 1, torch.tensor([[0, 0], [1, 0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "da02d601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 5, 768])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Linear(768, 768)(torch.rand(size=(6,5,768))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "441164fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERT, self).__init__()\n",
    "        self.embedding = Embedding()\n",
    "        self.layers = nn.ModuleList([EncoderLayer() for _ in range(n_layers)])\n",
    "        self.fc = nn.Linear(d_model, d_model)\n",
    "        self.activ1 = nn.Tanh()\n",
    "        self.linear = nn.Linear(d_model, d_model)\n",
    "        self.activ2 = gelu\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.classifier = nn.Linear(d_model, 2)\n",
    "        # decoder is shared with embedding layer\n",
    "        embed_weight = self.embedding.tok_embed.weight # [29,768]\n",
    "        n_vocab, n_dim = embed_weight.size()\n",
    "        self.decoder = nn.Linear(n_dim, n_vocab, bias=False) # nn.Linear(768, 29)\n",
    "        self.decoder.weight = embed_weight\n",
    "        self.decoder_bias = nn.Parameter(torch.zeros(n_vocab)) # nn.Parameter(zeros(29))\n",
    "\n",
    "    def forward(self, input_ids, segment_ids, masked_pos):\n",
    "        output = self.embedding(input_ids, segment_ids)\n",
    "        enc_self_attn_mask = get_attn_pad_mask(input_ids, input_ids)\n",
    "        for layer in self.layers:\n",
    "            output, enc_self_attn = layer(output, enc_self_attn_mask)\n",
    "        # output : [batch_size, len, d_model], attn : [batch_size, n_heads, d_mode, d_model]\n",
    "        # it will be decided by first token(CLS)\n",
    "        h_pooled = self.activ1(self.fc(output[:, 0])) \n",
    "        # [batch_size, len, d_model] -> [batch_size, d_model] -> [batch_size, d_model]\n",
    "        logits_clsf = self.classifier(h_pooled) \n",
    "        # [batch_size, d_model] -> [batch_size, 2] IsNext or NotNext \n",
    "        # Next Sentence Prediction\n",
    "\n",
    "        masked_pos = masked_pos[:, :, None].expand(-1, -1, output.size(-1)) \n",
    "        # [batch_size, max_pred, d_model] [6, 5] -> [6, 5, 1] -> [6, 5, 768]\n",
    "        \n",
    "        # get masked position from final output of transformer.\n",
    "        h_masked = torch.gather(output, 1, masked_pos) \n",
    "        # masking position [batch_size, max_pred, d_model] \n",
    "        # [6, 30, 768] gather [6, 5] -> [6, 5, 768]\n",
    "        h_masked = self.norm(self.activ2(self.linear(h_masked)))\n",
    "        # [6, 5, 768] -> [6, 5, 768]\n",
    "        logits_lm = self.decoder(h_masked) + self.decoder_bias # [batch_size, max_pred, n_vocab]\n",
    "        # [6, 5, 768] -> [6, 5, 29]\n",
    "\n",
    "        return logits_lm, logits_clsf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9a7690",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2d680b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERT()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ea26bb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = make_batch()\n",
    "input_ids, segment_ids, masked_tokens, masked_pos, isNext = map(torch.LongTensor, zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "048c55af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_lm:  torch.Size([6, 5, 29])\n",
      "logits_clsf:  torch.Size([6, 2])\n",
      "logits_lm:  torch.Size([6, 5, 29])\n",
      "logits_lm:  torch.Size([6, 5, 29])\n",
      "Epoch: 0010 cost = 57.128986\n",
      "Epoch: 0020 cost = 38.771671\n",
      "Epoch: 0030 cost = 25.818384\n",
      "Epoch: 0040 cost = 15.286547\n",
      "Epoch: 0050 cost = 12.659238\n",
      "Epoch: 0060 cost = 10.557425\n",
      "Epoch: 0070 cost = 9.461622\n",
      "Epoch: 0080 cost = 8.764488\n",
      "Epoch: 0090 cost = 8.010417\n",
      "Epoch: 0100 cost = 7.274577\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    logits_lm, logits_clsf = model(input_ids, segment_ids, masked_pos) # MLM & NSP\n",
    "    if epoch == 0:\n",
    "        print('logits_lm: ',logits_lm.shape)\n",
    "        print('logits_clsf: ',logits_clsf.shape)\n",
    "    loss_lm = criterion(logits_lm.transpose(1, 2), masked_tokens) # for masked LM\n",
    "    if epoch == 0:\n",
    "        print('logits_lm: ',logits_lm.shape)\n",
    "    loss_lm = (loss_lm.float()).mean()\n",
    "    if epoch == 0:\n",
    "        print('logits_lm: ',logits_lm.shape)\n",
    "    loss_clsf = criterion(logits_clsf, isNext) # for sentence classification\n",
    "    loss = loss_lm + loss_clsf\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "742ccd7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '[PAD]',\n",
       " 1: '[CLS]',\n",
       " 2: '[SEP]',\n",
       " 3: '[MASK]',\n",
       " 4: 'meet',\n",
       " 5: 'baseball',\n",
       " 6: 'i',\n",
       " 7: 'too',\n",
       " 8: 'competition',\n",
       " 9: 'today',\n",
       " 10: 'oh',\n",
       " 11: 'juliet',\n",
       " 12: 'thanks',\n",
       " 13: 'is',\n",
       " 14: 'to',\n",
       " 15: 'romeo',\n",
       " 16: 'team',\n",
       " 17: 'am',\n",
       " 18: 'nice',\n",
       " 19: 'great',\n",
       " 20: 'are',\n",
       " 21: 'name',\n",
       " 22: 'how',\n",
       " 23: 'my',\n",
       " 24: 'won',\n",
       " 25: 'hello',\n",
       " 26: 'you',\n",
       " 27: 'congratulations',\n",
       " 28: 'the'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "87f43b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, how are you? I am Romeo.\n",
      "Hello, Romeo My name is Juliet. Nice to meet you.\n",
      "Nice meet you too. How are you today?\n",
      "Great. My baseball team won the competition.\n",
      "Oh Congratulations, Juliet\n",
      "Thanks you Romeo\n",
      "['[CLS]', 'hello', '[MASK]', 'are', 'you', 'name', 'am', 'romeo', '[SEP]', 'oh', 'congratulations', 'juliet', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "input_ids, segment_ids, masked_tokens, masked_pos, isNext = map(torch.LongTensor, zip(batch[0]))\n",
    "print(text)\n",
    "print([number_dict[w.item()] for w in input_ids[0] if number_dict[w.item()] != '[PAD]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "05b45273",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_lm, logits_clsf = model(input_ids, segment_ids, masked_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "276ac516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  19.4711,   -0.4004,   12.4680,  -14.0396,    4.6071,   11.7006,\n",
       "            17.1605,  -15.2496,  -10.6696,   17.4949,    6.0434,   -4.6534,\n",
       "             8.8767,   16.2571,    8.7028,   16.7239,  -67.0431,   17.9637,\n",
       "            -6.5010,  -74.5477,   17.7200,  -26.0919, -121.6428,    5.0577,\n",
       "             2.4529,   17.5209,   14.9354,   17.7845,   18.0313],\n",
       "         [  19.4762,   -0.3987,   12.4685,  -14.0417,    4.6062,   11.6996,\n",
       "            17.1626,  -15.2510,  -10.6721,   17.4949,    6.0416,   -4.6557,\n",
       "             8.8750,   16.2597,    8.7023,   16.7282,  -67.0418,   17.9609,\n",
       "            -6.4989,  -74.5493,   17.7228,  -26.0881, -121.6462,    5.0563,\n",
       "             2.4545,   17.5210,   14.9338,   17.7816,   18.0284],\n",
       "         [  19.6477,   -0.3452,   12.4838,  -14.1073,    4.5732,   11.6716,\n",
       "            17.2234,  -15.2846,  -10.7528,   17.4903,    5.9910,   -4.7248,\n",
       "             8.8163,   16.3370,    8.6900,   16.8766,  -66.9971,   17.8893,\n",
       "            -6.4307,  -74.5935,   17.8180,  -25.9599, -121.7677,    5.0084,\n",
       "             2.5091,   17.5185,   14.8842,   17.6826,   17.9380],\n",
       "         [  19.6477,   -0.3452,   12.4838,  -14.1073,    4.5732,   11.6716,\n",
       "            17.2234,  -15.2846,  -10.7528,   17.4903,    5.9910,   -4.7248,\n",
       "             8.8163,   16.3370,    8.6900,   16.8766,  -66.9971,   17.8893,\n",
       "            -6.4307,  -74.5935,   17.8180,  -25.9599, -121.7677,    5.0084,\n",
       "             2.5091,   17.5185,   14.8842,   17.6826,   17.9380],\n",
       "         [  19.6477,   -0.3452,   12.4838,  -14.1073,    4.5732,   11.6716,\n",
       "            17.2234,  -15.2846,  -10.7528,   17.4903,    5.9910,   -4.7248,\n",
       "             8.8163,   16.3370,    8.6900,   16.8766,  -66.9971,   17.8893,\n",
       "            -6.4307,  -74.5935,   17.8180,  -25.9599, -121.7677,    5.0084,\n",
       "             2.5091,   17.5185,   14.8842,   17.6826,   17.9380]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2cf9f1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 29])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_lm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c3bb5c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([[19.4711, 19.4762, 19.6477, 19.6477, 19.6477]]),\n",
       "indices=tensor([[0, 0, 0, 0, 0]]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_lm.data.max(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5c8f1628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_lm.data.max(2)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "124646ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_lm.data.max(2)[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "792f19b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6, 22,  0,  0,  0]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d8e75ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 22,  0,  0,  0])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "234d3815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masked tokens list :  [6, 22]\n",
      "predict masked tokens list :  []\n"
     ]
    }
   ],
   "source": [
    "logits_lm_re = logits_lm.data.max(2)[1][0].data.numpy()\n",
    "print('masked tokens list : ',[pos.item() for pos in masked_tokens[0] if pos.item() != 0])\n",
    "print('predict masked tokens list : ',[pos for pos in logits_lm_re if pos != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1f9599bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1726, -0.1726]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_clsf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b6f48d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([-0.1726]),\n",
       "indices=tensor([1]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_clsf.data.max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7c8c4b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_clsf.data.max(1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "69e263a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_clsf.data.max(1)[1].data.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "25e316e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isNext :  False\n",
      "predict isNext :  True\n"
     ]
    }
   ],
   "source": [
    "logits_clsf_re = logits_clsf.data.max(1)[1].data.numpy()[0]\n",
    "print('isNext : ', True if isNext else False)\n",
    "print('predict isNext : ',True if logits_clsf_re else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c1fff7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
