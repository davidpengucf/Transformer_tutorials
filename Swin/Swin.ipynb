{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94843551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: timm in /geode2/home/u070/qupeng/Carbonate/.local/lib/python3.9/site-packages (0.5.4)\n",
      "Requirement already satisfied: torchvision in /geode2/soft/hps/rhel7/deeplearning/Python-3.9.8/lib/python3.9/site-packages (from timm) (0.11.3)\n",
      "Requirement already satisfied: torch>=1.4 in /geode2/soft/hps/rhel7/deeplearning/Python-3.9.8/lib/python3.9/site-packages (from timm) (1.10.2)\n",
      "Requirement already satisfied: typing-extensions in /geode2/soft/hps/rhel7/deeplearning/Python-3.9.8/lib/python3.9/site-packages (from torch>=1.4->timm) (4.0.1)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /geode2/soft/hps/rhel7/deeplearning/Python-3.9.8/lib/python3.9/site-packages (from torchvision->timm) (9.0.1)\n",
      "Requirement already satisfied: numpy in /geode2/soft/hps/rhel7/deeplearning/Python-3.9.8/lib/python3.9/site-packages (from torchvision->timm) (1.22.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/N/soft/rhel7/deeplearning/Python-3.9.8/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dff691d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "from timm.models.layers import DropPath, to_2tuple, trunc_normal_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6c42fb",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62d644f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mlp(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcd02f7",
   "metadata": {},
   "source": [
    "# Window Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a86da27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 224, 224, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(size=(1,224,224,3))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19a7e7dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 7, 32, 7, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.view(1, 224 // 7, 7, 224 // 7, 7, 3)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ab390ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 32, 7, 7, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.permute(0, 1, 3, 2, 4, 5)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc46e9d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 7, 7, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.contiguous().view(-1, 7, 7, 3)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f84771b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_partition(x, window_size):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x: (B, H, W, C)\n",
    "        window_size (int): window size\n",
    "    Returns:\n",
    "        windows: (num_windows*B, window_size, window_size, C)\n",
    "    \"\"\"\n",
    "    B, H, W, C = x.shape # [B, 224, 224, 3]\n",
    "    x = x.view(B, H // window_size, window_size, W // window_size, window_size, C) # [B, 32, 7, 32, 7, 3]\n",
    "    windows = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, window_size, window_size, C) \n",
    "    # [B, 32, 7, 32, 7, 3] -> [B, 32, 32, 7, 7, 3] -> [(B*32*32),7,7,3]\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9794a3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 32, 7, 7, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.view(1, 224 // 7, 224 // 7, 7, 7, -1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f061a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 7, 32, 7, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.permute(0, 1, 3, 2, 4, 5)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8bbaebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_reverse(windows, window_size, H, W):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        windows: (num_windows*B, window_size, window_size, C)\n",
    "        window_size (int): Window size\n",
    "        H (int): Height of image\n",
    "        W (int): Width of image\n",
    "    Returns:\n",
    "        x: (B, H, W, C)\n",
    "    \"\"\"\n",
    "    B = int(windows.shape[0] / (H * W / window_size / window_size)) \n",
    "    x = windows.view(B, H // window_size,  W // window_size, window_size, window_size, -1)\n",
    "    # [(B*32*32),7,7,3] -> [B, 32, 32, 7, 7, 3]\n",
    "    x = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(B, H, W, -1)\n",
    "    # [B, 32, 32, 7, 7, 3] -> [B, 32, 7, 32, 7, 3] -> [B, 224, 224, 3]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cdd25f",
   "metadata": {},
   "source": [
    "# Relative Position Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef29d00d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21db6fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowAttention(nn.Module):\n",
    "    r\"\"\" Window based multi-head self attention (W-MSA) module with relative position bias.\n",
    "    It supports both of shifted and non-shifted window.\n",
    "    Args:\n",
    "        dim (int): Number of input channels.\n",
    "        window_size (tuple[int]): The height and width of the window.\n",
    "        num_heads (int): Number of attention heads.\n",
    "        qkv_bias (bool, optional):  If True, add a learnable bias to query, key, value. Default: True\n",
    "        qk_scale (float | None, optional): Override default qk scale of head_dim ** -0.5 if set\n",
    "        attn_drop (float, optional): Dropout ratio of attention weight. Default: 0.0\n",
    "        proj_drop (float, optional): Dropout ratio of output. Default: 0.0\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim, window_size, num_heads, qkv_bias=True, qk_scale=None, attn_drop=0., proj_drop=0.):\n",
    "\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.window_size = window_size  # Wh, Ww\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "\n",
    "        # define a parameter table of relative position bias\n",
    "        self.relative_position_bias_table = nn.Parameter(\n",
    "            torch.zeros((2 * window_size[0] - 1) * (2 * window_size[1] - 1), num_heads))  # 2*Wh-1 * 2*Ww-1, nH\n",
    "        # [13, 13, 12]\n",
    "\n",
    "        # get pair-wise relative position index for each token inside the window\n",
    "        coords_h = torch.arange(self.window_size[0])\n",
    "        #print('coords_h: ',coords_h) #7\n",
    "        coords_w = torch.arange(self.window_size[1])\n",
    "        #print('coords_w: ',coords_w) #7\n",
    "        coords = torch.stack(torch.meshgrid([coords_h, coords_w]))  # 2, Wh, Ww\n",
    "        #print('meshgrid: ',torch.meshgrid([coords_h, coords_w]))\n",
    "        #print('coords: ',coords.shape) #[2,7,7]\n",
    "        #print('coords: ',coords)\n",
    "        \n",
    "        coords_flatten = torch.flatten(coords, 1)  # 2, Wh*Ww\n",
    "        #print('coords_flatten: ',coords_flatten.shape) [2, 49]\n",
    "        #print('coords_flatten: ',coords_flatten)\n",
    "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]  # 2, Wh*Ww, Wh*Ww\n",
    "        #print('coords_flatten_1: ',coords_flatten[:, :, None].shape) #[2,49,1]\n",
    "        #print('coords_flatten_1: ',coords_flatten[:, :, None])\n",
    "        #print('coords_flatten_2: ',coords_flatten[:, None, :].shape) #[2,1,49]\n",
    "        #print('coords_flatten_2: ',coords_flatten[:, None, :])\n",
    "        #print('relative_coords_1: ',relative_coords.shape) #[2,49,49]\n",
    "        #print('relative_coords_1: ',relative_coords)\n",
    "        relative_coords = relative_coords.permute(1, 2, 0).contiguous()  # Wh*Ww, Wh*Ww, 2\n",
    "        #print('relative_coords_2: ',relative_coords.shape) # [49,49,2] \n",
    "        #print('relative_coords_2: ',relative_coords)\n",
    "        relative_coords[:, :, 0] += self.window_size[0] - 1  # shift to start from 0\n",
    "        #print('relative_coords_3: ',relative_coords) # add 6 to row\n",
    "        relative_coords[:, :, 1] += self.window_size[1] - 1\n",
    "        #print('relative_coords_4: ',relative_coords) # add 6 to column\n",
    "        relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n",
    "        #print('relative_coords_5: ',relative_coords) # multiply 13 to rwo \n",
    "        relative_position_index = relative_coords.sum(-1)  # Wh*Ww, Wh*Ww\n",
    "        #print('relative_index: ',relative_position_index.shape) [49,49]\n",
    "        #print('relative_index: ',relative_position_index)\n",
    "        self.register_buffer(\"relative_position_index\", relative_position_index)\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "        trunc_normal_(self.relative_position_bias_table, std=.02)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: input features with shape of (num_windows*B, N, C)\n",
    "            mask: (0/-inf) mask with shape of (num_windows, Wh*Ww, Wh*Ww) or None\n",
    "        \"\"\"\n",
    "        B_, N, C = x.shape #[B_=(B*32*32), 49, 96]\n",
    "        qkv = self.qkv(x).reshape(B_, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        #print('qkv: ',qkv.shape)\n",
    "        #[B*1024, 49, 96*3] -> [B*1024,49,3,12,8] -> [3,B*1024,12,49,8]\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]  # make torchscript happy (cannot use tensor as tuple)\n",
    "        #[B*1024, 12, 49, 8]\n",
    "\n",
    "        q = q * self.scale\n",
    "        attn = (q @ k.transpose(-2, -1))\n",
    "        #[B*1024, 12, 49, 8] * [B*1024, 12, 8, 49] -> [B*1024, 12, 49, 49]\n",
    "        #print('attn_0: ',attn.shape)\n",
    "\n",
    "        relative_position_bias = self.relative_position_bias_table[self.relative_position_index.view(-1)].view(\n",
    "            self.window_size[0] * self.window_size[1], self.window_size[0] * self.window_size[1], -1)  \n",
    "        # Wh*Ww,Wh*Ww,nH\n",
    "        #print('self.relative_position_index_0: ',self.relative_position_index.shape) #[49, 49]\n",
    "        #print('self.relative_position_index_1: ',self.relative_position_index.view(-1).shape) #[49*49=2401]\n",
    "        #print('self.relative_position_bias_table_0: ', \\\n",
    "              #self.relative_position_bias_table[self.relative_position_index.view(-1)].shape)#[2401, 12]\n",
    "        #print('relative_position_bias_0: ',relative_position_bias.shape) #[49, 49, 12]\n",
    "        relative_position_bias = relative_position_bias.permute(2, 0, 1).contiguous()  # nH, Wh*Ww, Wh*Ww\n",
    "        #print('relative_position_bias_1: ',relative_position_bias.shape) #[12, 49, 49] \n",
    "        attn = attn + relative_position_bias.unsqueeze(0)\n",
    "        #print('attn_1: ',attn.shape) [B*1024, 12, 49, 49]\n",
    "\n",
    "        if mask is not None:\n",
    "            nW = mask.shape[0] # mask [1024, 49, 49] -> [1024,1,49,49] -> [1,1024,1,49,49]\n",
    "            attn = attn.view(B_ // nW, nW, self.num_heads, N, N) + mask.unsqueeze(1).unsqueeze(0)\n",
    "            #[B*1024, 12, 49, 49] -> [B,1024,12,49,49]\n",
    "            attn = attn.view(-1, self.num_heads, N, N) # [B,1024,12,49,49]->[B*1024,12,49,49]\n",
    "            attn = self.softmax(attn)\n",
    "        else:\n",
    "            attn = self.softmax(attn)\n",
    "\n",
    "        attn = self.attn_drop(attn)\n",
    "        #print('attn_2: ',attn.shape) #[B*1024, 12, 49, 49]\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B_, N, C)\n",
    "        #print('attn @ v 1: ',(attn @ v).shape) #[B*1024, 12, 49, 8]\n",
    "        #print('attn @ v 2: ',(attn @ v).transpose(1, 2).shape) #[B*1024, 49, 12, 8]\n",
    "        #print('x: ',x.shape) #[B*1024, 49, 96]\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f'dim={self.dim}, window_size={self.window_size}, num_heads={self.num_heads}'\n",
    "\n",
    "    def flops(self, N):\n",
    "        # calculate flops for 1 window with token length of N\n",
    "        flops = 0\n",
    "        # qkv = self.qkv(x)\n",
    "        flops += N * self.dim * 3 * self.dim\n",
    "        # attn = (q @ k.transpose(-2, -1))\n",
    "        flops += self.num_heads * N * (self.dim // self.num_heads) * N\n",
    "        #  x = (attn @ v)\n",
    "        flops += self.num_heads * N * N * (self.dim // self.num_heads)\n",
    "        # x = self.proj(x)\n",
    "        flops += N * self.dim * self.dim\n",
    "        return flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afac4440",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/N/soft/rhel7/deeplearning/Python-3.9.8/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "o = WindowAttention(dim=96, window_size=(7,7), num_heads=12, qkv_bias=True, qk_scale=None, attn_drop=0., proj_drop=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "507eb0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = torch.rand(size=(1024,49,96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3c4cb65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1074,  0.3787, -0.0495,  ..., -0.1143,  0.0556, -0.1832],\n",
       "         [ 0.1077,  0.3795, -0.0492,  ..., -0.1151,  0.0564, -0.1845],\n",
       "         [ 0.1077,  0.3785, -0.0491,  ..., -0.1154,  0.0560, -0.1842],\n",
       "         ...,\n",
       "         [ 0.1078,  0.3795, -0.0494,  ..., -0.1147,  0.0559, -0.1839],\n",
       "         [ 0.1065,  0.3793, -0.0491,  ..., -0.1146,  0.0563, -0.1842],\n",
       "         [ 0.1069,  0.3795, -0.0492,  ..., -0.1144,  0.0557, -0.1845]],\n",
       "\n",
       "        [[ 0.1038,  0.3915, -0.0428,  ..., -0.1079,  0.0811, -0.1960],\n",
       "         [ 0.1037,  0.3900, -0.0431,  ..., -0.1085,  0.0816, -0.1974],\n",
       "         [ 0.1034,  0.3910, -0.0430,  ..., -0.1085,  0.0806, -0.1968],\n",
       "         ...,\n",
       "         [ 0.1037,  0.3898, -0.0429,  ..., -0.1079,  0.0811, -0.1961],\n",
       "         [ 0.1026,  0.3912, -0.0433,  ..., -0.1070,  0.0824, -0.1954],\n",
       "         [ 0.1048,  0.3908, -0.0430,  ..., -0.1082,  0.0806, -0.1965]],\n",
       "\n",
       "        [[ 0.1098,  0.4013, -0.0395,  ..., -0.1147,  0.0772, -0.1957],\n",
       "         [ 0.1107,  0.4000, -0.0392,  ..., -0.1159,  0.0766, -0.1964],\n",
       "         [ 0.1110,  0.4017, -0.0408,  ..., -0.1162,  0.0760, -0.1962],\n",
       "         ...,\n",
       "         [ 0.1112,  0.4013, -0.0404,  ..., -0.1156,  0.0764, -0.1957],\n",
       "         [ 0.1103,  0.4006, -0.0404,  ..., -0.1157,  0.0762, -0.1968],\n",
       "         [ 0.1101,  0.4012, -0.0394,  ..., -0.1148,  0.0764, -0.1953]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.1279,  0.3511, -0.0570,  ..., -0.1158,  0.0324, -0.2111],\n",
       "         [ 0.1275,  0.3515, -0.0576,  ..., -0.1155,  0.0346, -0.2113],\n",
       "         [ 0.1273,  0.3506, -0.0578,  ..., -0.1171,  0.0325, -0.2119],\n",
       "         ...,\n",
       "         [ 0.1254,  0.3506, -0.0580,  ..., -0.1162,  0.0334, -0.2118],\n",
       "         [ 0.1280,  0.3515, -0.0576,  ..., -0.1162,  0.0338, -0.2121],\n",
       "         [ 0.1274,  0.3515, -0.0566,  ..., -0.1157,  0.0339, -0.2117]],\n",
       "\n",
       "        [[ 0.1133,  0.3608, -0.0515,  ..., -0.1198,  0.0497, -0.1750],\n",
       "         [ 0.1129,  0.3613, -0.0515,  ..., -0.1213,  0.0495, -0.1758],\n",
       "         [ 0.1131,  0.3616, -0.0516,  ..., -0.1205,  0.0494, -0.1763],\n",
       "         ...,\n",
       "         [ 0.1121,  0.3611, -0.0510,  ..., -0.1212,  0.0488, -0.1758],\n",
       "         [ 0.1127,  0.3611, -0.0514,  ..., -0.1205,  0.0490, -0.1754],\n",
       "         [ 0.1133,  0.3608, -0.0511,  ..., -0.1203,  0.0495, -0.1750]],\n",
       "\n",
       "        [[ 0.1082,  0.3791, -0.0504,  ..., -0.1057,  0.0429, -0.2131],\n",
       "         [ 0.1080,  0.3788, -0.0509,  ..., -0.1068,  0.0437, -0.2134],\n",
       "         [ 0.1080,  0.3796, -0.0504,  ..., -0.1066,  0.0429, -0.2142],\n",
       "         ...,\n",
       "         [ 0.1080,  0.3792, -0.0501,  ..., -0.1073,  0.0426, -0.2131],\n",
       "         [ 0.1076,  0.3785, -0.0496,  ..., -0.1068,  0.0432, -0.2132],\n",
       "         [ 0.1082,  0.3787, -0.0505,  ..., -0.1069,  0.0431, -0.2134]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o(t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72e44233",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowAttention(nn.Module):\n",
    "    r\"\"\" Window based multi-head self attention (W-MSA) module with relative position bias.\n",
    "    It supports both of shifted and non-shifted window.\n",
    "    Args:\n",
    "        dim (int): Number of input channels.\n",
    "        window_size (tuple[int]): The height and width of the window.\n",
    "        num_heads (int): Number of attention heads.\n",
    "        qkv_bias (bool, optional):  If True, add a learnable bias to query, key, value. Default: True\n",
    "        qk_scale (float | None, optional): Override default qk scale of head_dim ** -0.5 if set\n",
    "        attn_drop (float, optional): Dropout ratio of attention weight. Default: 0.0\n",
    "        proj_drop (float, optional): Dropout ratio of output. Default: 0.0\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim, window_size, num_heads, qkv_bias=True, qk_scale=None, attn_drop=0., proj_drop=0.):\n",
    "\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.window_size = window_size  # Wh, Ww\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "\n",
    "        # define a parameter table of relative position bias\n",
    "        self.relative_position_bias_table = nn.Parameter(\n",
    "            torch.zeros((2 * window_size[0] - 1) * (2 * window_size[1] - 1), num_heads))  # 2*Wh-1 * 2*Ww-1, nH\n",
    "\n",
    "        # get pair-wise relative position index for each token inside the window\n",
    "        coords_h = torch.arange(self.window_size[0])\n",
    "        coords_w = torch.arange(self.window_size[1])\n",
    "        coords = torch.stack(torch.meshgrid([coords_h, coords_w]))  # 2, Wh, Ww\n",
    "        coords_flatten = torch.flatten(coords, 1)  # 2, Wh*Ww\n",
    "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]  # 2, Wh*Ww, Wh*Ww\n",
    "        relative_coords = relative_coords.permute(1, 2, 0).contiguous()  # Wh*Ww, Wh*Ww, 2\n",
    "        relative_coords[:, :, 0] += self.window_size[0] - 1  # shift to start from 0\n",
    "        relative_coords[:, :, 1] += self.window_size[1] - 1\n",
    "        relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n",
    "        relative_position_index = relative_coords.sum(-1)  # Wh*Ww, Wh*Ww\n",
    "        self.register_buffer(\"relative_position_index\", relative_position_index)\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "        trunc_normal_(self.relative_position_bias_table, std=.02)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: input features with shape of (num_windows*B, N, C)\n",
    "            mask: (0/-inf) mask with shape of (num_windows, Wh*Ww, Wh*Ww) or None\n",
    "        \"\"\"\n",
    "        B_, N, C = x.shape\n",
    "        qkv = self.qkv(x).reshape(B_, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]  # make torchscript happy (cannot use tensor as tuple)\n",
    "\n",
    "        q = q * self.scale\n",
    "        attn = (q @ k.transpose(-2, -1))\n",
    "\n",
    "        relative_position_bias = self.relative_position_bias_table[self.relative_position_index.view(-1)].view(\n",
    "            self.window_size[0] * self.window_size[1], self.window_size[0] * self.window_size[1], -1)  # Wh*Ww,Wh*Ww,nH\n",
    "        relative_position_bias = relative_position_bias.permute(2, 0, 1).contiguous()  # nH, Wh*Ww, Wh*Ww\n",
    "        attn = attn + relative_position_bias.unsqueeze(0)\n",
    "\n",
    "        if mask is not None:\n",
    "            nW = mask.shape[0]\n",
    "            attn = attn.view(B_ // nW, nW, self.num_heads, N, N) + mask.unsqueeze(1).unsqueeze(0)\n",
    "            attn = attn.view(-1, self.num_heads, N, N)\n",
    "            attn = self.softmax(attn)\n",
    "        else:\n",
    "            attn = self.softmax(attn)\n",
    "\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B_, N, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f'dim={self.dim}, window_size={self.window_size}, num_heads={self.num_heads}'\n",
    "\n",
    "    def flops(self, N):\n",
    "        # calculate flops for 1 window with token length of N\n",
    "        flops = 0\n",
    "        # qkv = self.qkv(x)\n",
    "        flops += N * self.dim * 3 * self.dim\n",
    "        # attn = (q @ k.transpose(-2, -1))\n",
    "        flops += self.num_heads * N * (self.dim // self.num_heads) * N\n",
    "        #  x = (attn @ v)\n",
    "        flops += self.num_heads * N * N * (self.dim // self.num_heads)\n",
    "        # x = self.proj(x)\n",
    "        flops += N * self.dim * self.dim\n",
    "        return flops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945b7056",
   "metadata": {},
   "source": [
    "# Shifted Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10985951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P', 'y']\n",
      "('o', 'n')\n"
     ]
    }
   ],
   "source": [
    "py_list = ['P', 'y', 't', 'h', 'o', 'n']\n",
    "py_tuple = ('P', 'y', 't', 'h', 'o', 'n')\n",
    "\n",
    "# contains indices -1, -2 and -3\n",
    "slice_object = slice(0, -4) \n",
    "\n",
    "print(py_list[slice_object])  # ['n', 'o', 'h']\n",
    "\n",
    "# contains indices -1 and -3\n",
    "slice_object = slice(-2,None)\n",
    "\n",
    "print(py_tuple[slice_object]) # ('n', 'h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "410f4bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_mask:  tensor([[[[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.]]]])\n",
      "h_slices:  slice(0, -4, None)\n",
      "w_slices:  slice(0, -4, None)\n",
      "cnt:  0\n",
      "img_mask:  tensor([[[[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.]]]])\n",
      "h_slices:  slice(0, -4, None)\n",
      "w_slices:  slice(-4, -2, None)\n",
      "cnt:  1\n",
      "img_mask:  tensor([[[[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [0.],\n",
      "          [0.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [0.],\n",
      "          [0.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [0.],\n",
      "          [0.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [0.],\n",
      "          [0.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.]]]])\n",
      "h_slices:  slice(0, -4, None)\n",
      "w_slices:  slice(-2, None, None)\n",
      "cnt:  2\n",
      "img_mask:  tensor([[[[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [2.],\n",
      "          [2.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [2.],\n",
      "          [2.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [2.],\n",
      "          [2.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [2.],\n",
      "          [2.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.]]]])\n",
      "h_slices:  slice(-4, -2, None)\n",
      "w_slices:  slice(0, -4, None)\n",
      "cnt:  3\n",
      "img_mask:  tensor([[[[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [2.],\n",
      "          [2.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [2.],\n",
      "          [2.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [2.],\n",
      "          [2.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [2.],\n",
      "          [2.]],\n",
      "\n",
      "         [[3.],\n",
      "          [3.],\n",
      "          [3.],\n",
      "          [3.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.]],\n",
      "\n",
      "         [[3.],\n",
      "          [3.],\n",
      "          [3.],\n",
      "          [3.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.]]]])\n",
      "h_slices:  slice(-4, -2, None)\n",
      "w_slices:  slice(-4, -2, None)\n",
      "cnt:  4\n",
      "img_mask:  tensor([[[[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [2.],\n",
      "          [2.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [2.],\n",
      "          [2.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [2.],\n",
      "          [2.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [2.],\n",
      "          [2.]],\n",
      "\n",
      "         [[3.],\n",
      "          [3.],\n",
      "          [3.],\n",
      "          [3.],\n",
      "          [4.],\n",
      "          [4.],\n",
      "          [0.],\n",
      "          [0.]],\n",
      "\n",
      "         [[3.],\n",
      "          [3.],\n",
      "          [3.],\n",
      "          [3.],\n",
      "          [4.],\n",
      "          [4.],\n",
      "          [0.],\n",
      "          [0.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.]]]])\n",
      "h_slices:  slice(-4, -2, None)\n",
      "w_slices:  slice(-2, None, None)\n",
      "cnt:  5\n",
      "img_mask:  tensor([[[[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [2.],\n",
      "          [2.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [2.],\n",
      "          [2.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [2.],\n",
      "          [2.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [2.],\n",
      "          [2.]],\n",
      "\n",
      "         [[3.],\n",
      "          [3.],\n",
      "          [3.],\n",
      "          [3.],\n",
      "          [4.],\n",
      "          [4.],\n",
      "          [5.],\n",
      "          [5.]],\n",
      "\n",
      "         [[3.],\n",
      "          [3.],\n",
      "          [3.],\n",
      "          [3.],\n",
      "          [4.],\n",
      "          [4.],\n",
      "          [5.],\n",
      "          [5.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.]]]])\n",
      "h_slices:  slice(-2, None, None)\n",
      "w_slices:  slice(0, -4, None)\n",
      "cnt:  6\n",
      "img_mask:  tensor([[[[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [2.],\n",
      "          [2.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [2.],\n",
      "          [2.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [2.],\n",
      "          [2.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [2.],\n",
      "          [2.]],\n",
      "\n",
      "         [[3.],\n",
      "          [3.],\n",
      "          [3.],\n",
      "          [3.],\n",
      "          [4.],\n",
      "          [4.],\n",
      "          [5.],\n",
      "          [5.]],\n",
      "\n",
      "         [[3.],\n",
      "          [3.],\n",
      "          [3.],\n",
      "          [3.],\n",
      "          [4.],\n",
      "          [4.],\n",
      "          [5.],\n",
      "          [5.]],\n",
      "\n",
      "         [[6.],\n",
      "          [6.],\n",
      "          [6.],\n",
      "          [6.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.]],\n",
      "\n",
      "         [[6.],\n",
      "          [6.],\n",
      "          [6.],\n",
      "          [6.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.]]]])\n",
      "h_slices:  slice(-2, None, None)\n",
      "w_slices:  slice(-4, -2, None)\n",
      "cnt:  7\n",
      "img_mask:  tensor([[[[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [2.],\n",
      "          [2.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [2.],\n",
      "          [2.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [2.],\n",
      "          [2.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [2.],\n",
      "          [2.]],\n",
      "\n",
      "         [[3.],\n",
      "          [3.],\n",
      "          [3.],\n",
      "          [3.],\n",
      "          [4.],\n",
      "          [4.],\n",
      "          [5.],\n",
      "          [5.]],\n",
      "\n",
      "         [[3.],\n",
      "          [3.],\n",
      "          [3.],\n",
      "          [3.],\n",
      "          [4.],\n",
      "          [4.],\n",
      "          [5.],\n",
      "          [5.]],\n",
      "\n",
      "         [[6.],\n",
      "          [6.],\n",
      "          [6.],\n",
      "          [6.],\n",
      "          [7.],\n",
      "          [7.],\n",
      "          [0.],\n",
      "          [0.]],\n",
      "\n",
      "         [[6.],\n",
      "          [6.],\n",
      "          [6.],\n",
      "          [6.],\n",
      "          [7.],\n",
      "          [7.],\n",
      "          [0.],\n",
      "          [0.]]]])\n",
      "h_slices:  slice(-2, None, None)\n",
      "w_slices:  slice(-2, None, None)\n",
      "cnt:  8\n",
      "img_mask:  tensor([[[[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [2.],\n",
      "          [2.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [2.],\n",
      "          [2.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [2.],\n",
      "          [2.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [2.],\n",
      "          [2.]],\n",
      "\n",
      "         [[3.],\n",
      "          [3.],\n",
      "          [3.],\n",
      "          [3.],\n",
      "          [4.],\n",
      "          [4.],\n",
      "          [5.],\n",
      "          [5.]],\n",
      "\n",
      "         [[3.],\n",
      "          [3.],\n",
      "          [3.],\n",
      "          [3.],\n",
      "          [4.],\n",
      "          [4.],\n",
      "          [5.],\n",
      "          [5.]],\n",
      "\n",
      "         [[6.],\n",
      "          [6.],\n",
      "          [6.],\n",
      "          [6.],\n",
      "          [7.],\n",
      "          [7.],\n",
      "          [8.],\n",
      "          [8.]],\n",
      "\n",
      "         [[6.],\n",
      "          [6.],\n",
      "          [6.],\n",
      "          [6.],\n",
      "          [7.],\n",
      "          [7.],\n",
      "          [8.],\n",
      "          [8.]]]])\n"
     ]
    }
   ],
   "source": [
    "img_mask = torch.zeros((1, 8, 8, 1))\n",
    "h_slices = (slice(0, -4),slice(-4, -2),slice(-2, None))\n",
    "w_slices = (slice(0, -4),slice(-4, -2),slice(-2, None))\n",
    "print('img_mask: ',img_mask)\n",
    "\n",
    "cnt = 0\n",
    "for h in h_slices:\n",
    "    for w in w_slices:\n",
    "        print('h_slices: ',h)\n",
    "        print('w_slices: ',w)\n",
    "        print('cnt: ',cnt)\n",
    "        img_mask[:, h, w, :] = cnt\n",
    "                    #torch.set_printoptions(profile=\"full\")\n",
    "        print('img_mask: ',img_mask)\n",
    "        cnt += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57b84a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0],\n",
      "        [1, 2]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  0],\n",
       "         [ 0,  0]],\n",
       "\n",
       "        [[ 0,  1],\n",
       "         [-1,  0]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test0 = torch.tensor([[0,0],\n",
    "                     [1,2]])\n",
    "print(test0)\n",
    "test0.unsqueeze(1)-test0.unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40c04e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_windows_0:  tensor([[[[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.]]],\n",
      "\n",
      "\n",
      "        [[[1.],\n",
      "          [1.],\n",
      "          [2.],\n",
      "          [2.]],\n",
      "\n",
      "         [[1.],\n",
      "          [1.],\n",
      "          [2.],\n",
      "          [2.]],\n",
      "\n",
      "         [[1.],\n",
      "          [1.],\n",
      "          [2.],\n",
      "          [2.]],\n",
      "\n",
      "         [[1.],\n",
      "          [1.],\n",
      "          [2.],\n",
      "          [2.]]],\n",
      "\n",
      "\n",
      "        [[[3.],\n",
      "          [3.],\n",
      "          [3.],\n",
      "          [3.]],\n",
      "\n",
      "         [[3.],\n",
      "          [3.],\n",
      "          [3.],\n",
      "          [3.]],\n",
      "\n",
      "         [[6.],\n",
      "          [6.],\n",
      "          [6.],\n",
      "          [6.]],\n",
      "\n",
      "         [[6.],\n",
      "          [6.],\n",
      "          [6.],\n",
      "          [6.]]],\n",
      "\n",
      "\n",
      "        [[[4.],\n",
      "          [4.],\n",
      "          [5.],\n",
      "          [5.]],\n",
      "\n",
      "         [[4.],\n",
      "          [4.],\n",
      "          [5.],\n",
      "          [5.]],\n",
      "\n",
      "         [[7.],\n",
      "          [7.],\n",
      "          [8.],\n",
      "          [8.]],\n",
      "\n",
      "         [[7.],\n",
      "          [7.],\n",
      "          [8.],\n",
      "          [8.]]]])\n",
      "mask_windows_0:  torch.Size([4, 4, 4, 1])\n",
      "mask_windows_1:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 2., 2., 1., 1., 2., 2., 1., 1., 2., 2., 1., 1., 2., 2.],\n",
      "        [3., 3., 3., 3., 3., 3., 3., 3., 6., 6., 6., 6., 6., 6., 6., 6.],\n",
      "        [4., 4., 5., 5., 4., 4., 5., 5., 7., 7., 8., 8., 7., 7., 8., 8.]])\n",
      "mask_windows_1:  torch.Size([4, 16])\n",
      "mask_windows.unsqueeze(1):  tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 2., 2., 1., 1., 2., 2., 1., 1., 2., 2., 1., 1., 2., 2.]],\n",
      "\n",
      "        [[3., 3., 3., 3., 3., 3., 3., 3., 6., 6., 6., 6., 6., 6., 6., 6.]],\n",
      "\n",
      "        [[4., 4., 5., 5., 4., 4., 5., 5., 7., 7., 8., 8., 7., 7., 8., 8.]]])\n",
      "mask_windows.unsqueeze(2):  tensor([[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [2.],\n",
      "         [2.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [2.],\n",
      "         [2.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [2.],\n",
      "         [2.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [2.],\n",
      "         [2.]],\n",
      "\n",
      "        [[3.],\n",
      "         [3.],\n",
      "         [3.],\n",
      "         [3.],\n",
      "         [3.],\n",
      "         [3.],\n",
      "         [3.],\n",
      "         [3.],\n",
      "         [6.],\n",
      "         [6.],\n",
      "         [6.],\n",
      "         [6.],\n",
      "         [6.],\n",
      "         [6.],\n",
      "         [6.],\n",
      "         [6.]],\n",
      "\n",
      "        [[4.],\n",
      "         [4.],\n",
      "         [5.],\n",
      "         [5.],\n",
      "         [4.],\n",
      "         [4.],\n",
      "         [5.],\n",
      "         [5.],\n",
      "         [7.],\n",
      "         [7.],\n",
      "         [8.],\n",
      "         [8.],\n",
      "         [7.],\n",
      "         [7.],\n",
      "         [8.],\n",
      "         [8.]]])\n",
      "attn_mask_0:  tensor([[[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.]],\n",
      "\n",
      "        [[ 0.,  0.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,\n",
      "           1.,  1.],\n",
      "         [ 0.,  0.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,\n",
      "           1.,  1.],\n",
      "         [-1., -1.,  0.,  0., -1., -1.,  0.,  0., -1., -1.,  0.,  0., -1., -1.,\n",
      "           0.,  0.],\n",
      "         [-1., -1.,  0.,  0., -1., -1.,  0.,  0., -1., -1.,  0.,  0., -1., -1.,\n",
      "           0.,  0.],\n",
      "         [ 0.,  0.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,\n",
      "           1.,  1.],\n",
      "         [ 0.,  0.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,\n",
      "           1.,  1.],\n",
      "         [-1., -1.,  0.,  0., -1., -1.,  0.,  0., -1., -1.,  0.,  0., -1., -1.,\n",
      "           0.,  0.],\n",
      "         [-1., -1.,  0.,  0., -1., -1.,  0.,  0., -1., -1.,  0.,  0., -1., -1.,\n",
      "           0.,  0.],\n",
      "         [ 0.,  0.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,\n",
      "           1.,  1.],\n",
      "         [ 0.,  0.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,\n",
      "           1.,  1.],\n",
      "         [-1., -1.,  0.,  0., -1., -1.,  0.,  0., -1., -1.,  0.,  0., -1., -1.,\n",
      "           0.,  0.],\n",
      "         [-1., -1.,  0.,  0., -1., -1.,  0.,  0., -1., -1.,  0.,  0., -1., -1.,\n",
      "           0.,  0.],\n",
      "         [ 0.,  0.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,\n",
      "           1.,  1.],\n",
      "         [ 0.,  0.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,\n",
      "           1.,  1.],\n",
      "         [-1., -1.,  0.,  0., -1., -1.,  0.,  0., -1., -1.,  0.,  0., -1., -1.,\n",
      "           0.,  0.],\n",
      "         [-1., -1.,  0.,  0., -1., -1.,  0.,  0., -1., -1.,  0.,  0., -1., -1.,\n",
      "           0.,  0.]],\n",
      "\n",
      "        [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  3.,  3.,  3.,  3.,  3.,  3.,\n",
      "           3.,  3.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  3.,  3.,  3.,  3.,  3.,  3.,\n",
      "           3.,  3.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  3.,  3.,  3.,  3.,  3.,  3.,\n",
      "           3.,  3.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  3.,  3.,  3.,  3.,  3.,  3.,\n",
      "           3.,  3.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  3.,  3.,  3.,  3.,  3.,  3.,\n",
      "           3.,  3.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  3.,  3.,  3.,  3.,  3.,  3.,\n",
      "           3.,  3.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  3.,  3.,  3.,  3.,  3.,  3.,\n",
      "           3.,  3.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  3.,  3.,  3.,  3.,  3.,  3.,\n",
      "           3.,  3.],\n",
      "         [-3., -3., -3., -3., -3., -3., -3., -3.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.],\n",
      "         [-3., -3., -3., -3., -3., -3., -3., -3.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.],\n",
      "         [-3., -3., -3., -3., -3., -3., -3., -3.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.],\n",
      "         [-3., -3., -3., -3., -3., -3., -3., -3.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.],\n",
      "         [-3., -3., -3., -3., -3., -3., -3., -3.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.],\n",
      "         [-3., -3., -3., -3., -3., -3., -3., -3.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.],\n",
      "         [-3., -3., -3., -3., -3., -3., -3., -3.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.],\n",
      "         [-3., -3., -3., -3., -3., -3., -3., -3.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.]],\n",
      "\n",
      "        [[ 0.,  0.,  1.,  1.,  0.,  0.,  1.,  1.,  3.,  3.,  4.,  4.,  3.,  3.,\n",
      "           4.,  4.],\n",
      "         [ 0.,  0.,  1.,  1.,  0.,  0.,  1.,  1.,  3.,  3.,  4.,  4.,  3.,  3.,\n",
      "           4.,  4.],\n",
      "         [-1., -1.,  0.,  0., -1., -1.,  0.,  0.,  2.,  2.,  3.,  3.,  2.,  2.,\n",
      "           3.,  3.],\n",
      "         [-1., -1.,  0.,  0., -1., -1.,  0.,  0.,  2.,  2.,  3.,  3.,  2.,  2.,\n",
      "           3.,  3.],\n",
      "         [ 0.,  0.,  1.,  1.,  0.,  0.,  1.,  1.,  3.,  3.,  4.,  4.,  3.,  3.,\n",
      "           4.,  4.],\n",
      "         [ 0.,  0.,  1.,  1.,  0.,  0.,  1.,  1.,  3.,  3.,  4.,  4.,  3.,  3.,\n",
      "           4.,  4.],\n",
      "         [-1., -1.,  0.,  0., -1., -1.,  0.,  0.,  2.,  2.,  3.,  3.,  2.,  2.,\n",
      "           3.,  3.],\n",
      "         [-1., -1.,  0.,  0., -1., -1.,  0.,  0.,  2.,  2.,  3.,  3.,  2.,  2.,\n",
      "           3.,  3.],\n",
      "         [-3., -3., -2., -2., -3., -3., -2., -2.,  0.,  0.,  1.,  1.,  0.,  0.,\n",
      "           1.,  1.],\n",
      "         [-3., -3., -2., -2., -3., -3., -2., -2.,  0.,  0.,  1.,  1.,  0.,  0.,\n",
      "           1.,  1.],\n",
      "         [-4., -4., -3., -3., -4., -4., -3., -3., -1., -1.,  0.,  0., -1., -1.,\n",
      "           0.,  0.],\n",
      "         [-4., -4., -3., -3., -4., -4., -3., -3., -1., -1.,  0.,  0., -1., -1.,\n",
      "           0.,  0.],\n",
      "         [-3., -3., -2., -2., -3., -3., -2., -2.,  0.,  0.,  1.,  1.,  0.,  0.,\n",
      "           1.,  1.],\n",
      "         [-3., -3., -2., -2., -3., -3., -2., -2.,  0.,  0.,  1.,  1.,  0.,  0.,\n",
      "           1.,  1.],\n",
      "         [-4., -4., -3., -3., -4., -4., -3., -3., -1., -1.,  0.,  0., -1., -1.,\n",
      "           0.,  0.],\n",
      "         [-4., -4., -3., -3., -4., -4., -3., -3., -1., -1.,  0.,  0., -1., -1.,\n",
      "           0.,  0.]]])\n",
      "attn_mask_0:  torch.Size([4, 16, 16])\n",
      "attn_mask_1:  tensor([[[   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "             0.,    0.,    0.,    0.,    0.,    0.],\n",
      "         [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "             0.,    0.,    0.,    0.,    0.,    0.],\n",
      "         [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "             0.,    0.,    0.,    0.,    0.,    0.],\n",
      "         [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "             0.,    0.,    0.,    0.,    0.,    0.],\n",
      "         [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "             0.,    0.,    0.,    0.,    0.,    0.],\n",
      "         [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "             0.,    0.,    0.,    0.,    0.,    0.],\n",
      "         [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "             0.,    0.,    0.,    0.,    0.,    0.],\n",
      "         [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "             0.,    0.,    0.,    0.,    0.,    0.],\n",
      "         [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "             0.,    0.,    0.,    0.,    0.,    0.],\n",
      "         [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "             0.,    0.,    0.,    0.,    0.,    0.],\n",
      "         [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "             0.,    0.,    0.,    0.,    0.,    0.],\n",
      "         [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "             0.,    0.,    0.,    0.,    0.,    0.],\n",
      "         [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "             0.,    0.,    0.,    0.,    0.,    0.],\n",
      "         [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "             0.,    0.,    0.,    0.,    0.,    0.],\n",
      "         [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "             0.,    0.,    0.,    0.,    0.,    0.],\n",
      "         [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "             0.,    0.,    0.,    0.,    0.,    0.]],\n",
      "\n",
      "        [[   0.,    0., -100., -100.,    0.,    0., -100., -100.,    0.,    0.,\n",
      "          -100., -100.,    0.,    0., -100., -100.],\n",
      "         [   0.,    0., -100., -100.,    0.,    0., -100., -100.,    0.,    0.,\n",
      "          -100., -100.,    0.,    0., -100., -100.],\n",
      "         [-100., -100.,    0.,    0., -100., -100.,    0.,    0., -100., -100.,\n",
      "             0.,    0., -100., -100.,    0.,    0.],\n",
      "         [-100., -100.,    0.,    0., -100., -100.,    0.,    0., -100., -100.,\n",
      "             0.,    0., -100., -100.,    0.,    0.],\n",
      "         [   0.,    0., -100., -100.,    0.,    0., -100., -100.,    0.,    0.,\n",
      "          -100., -100.,    0.,    0., -100., -100.],\n",
      "         [   0.,    0., -100., -100.,    0.,    0., -100., -100.,    0.,    0.,\n",
      "          -100., -100.,    0.,    0., -100., -100.],\n",
      "         [-100., -100.,    0.,    0., -100., -100.,    0.,    0., -100., -100.,\n",
      "             0.,    0., -100., -100.,    0.,    0.],\n",
      "         [-100., -100.,    0.,    0., -100., -100.,    0.,    0., -100., -100.,\n",
      "             0.,    0., -100., -100.,    0.,    0.],\n",
      "         [   0.,    0., -100., -100.,    0.,    0., -100., -100.,    0.,    0.,\n",
      "          -100., -100.,    0.,    0., -100., -100.],\n",
      "         [   0.,    0., -100., -100.,    0.,    0., -100., -100.,    0.,    0.,\n",
      "          -100., -100.,    0.,    0., -100., -100.],\n",
      "         [-100., -100.,    0.,    0., -100., -100.,    0.,    0., -100., -100.,\n",
      "             0.,    0., -100., -100.,    0.,    0.],\n",
      "         [-100., -100.,    0.,    0., -100., -100.,    0.,    0., -100., -100.,\n",
      "             0.,    0., -100., -100.,    0.,    0.],\n",
      "         [   0.,    0., -100., -100.,    0.,    0., -100., -100.,    0.,    0.,\n",
      "          -100., -100.,    0.,    0., -100., -100.],\n",
      "         [   0.,    0., -100., -100.,    0.,    0., -100., -100.,    0.,    0.,\n",
      "          -100., -100.,    0.,    0., -100., -100.],\n",
      "         [-100., -100.,    0.,    0., -100., -100.,    0.,    0., -100., -100.,\n",
      "             0.,    0., -100., -100.,    0.,    0.],\n",
      "         [-100., -100.,    0.,    0., -100., -100.,    0.,    0., -100., -100.,\n",
      "             0.,    0., -100., -100.,    0.,    0.]],\n",
      "\n",
      "        [[   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0., -100., -100.,\n",
      "          -100., -100., -100., -100., -100., -100.],\n",
      "         [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0., -100., -100.,\n",
      "          -100., -100., -100., -100., -100., -100.],\n",
      "         [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0., -100., -100.,\n",
      "          -100., -100., -100., -100., -100., -100.],\n",
      "         [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0., -100., -100.,\n",
      "          -100., -100., -100., -100., -100., -100.],\n",
      "         [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0., -100., -100.,\n",
      "          -100., -100., -100., -100., -100., -100.],\n",
      "         [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0., -100., -100.,\n",
      "          -100., -100., -100., -100., -100., -100.],\n",
      "         [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0., -100., -100.,\n",
      "          -100., -100., -100., -100., -100., -100.],\n",
      "         [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0., -100., -100.,\n",
      "          -100., -100., -100., -100., -100., -100.],\n",
      "         [-100., -100., -100., -100., -100., -100., -100., -100.,    0.,    0.,\n",
      "             0.,    0.,    0.,    0.,    0.,    0.],\n",
      "         [-100., -100., -100., -100., -100., -100., -100., -100.,    0.,    0.,\n",
      "             0.,    0.,    0.,    0.,    0.,    0.],\n",
      "         [-100., -100., -100., -100., -100., -100., -100., -100.,    0.,    0.,\n",
      "             0.,    0.,    0.,    0.,    0.,    0.],\n",
      "         [-100., -100., -100., -100., -100., -100., -100., -100.,    0.,    0.,\n",
      "             0.,    0.,    0.,    0.,    0.,    0.],\n",
      "         [-100., -100., -100., -100., -100., -100., -100., -100.,    0.,    0.,\n",
      "             0.,    0.,    0.,    0.,    0.,    0.],\n",
      "         [-100., -100., -100., -100., -100., -100., -100., -100.,    0.,    0.,\n",
      "             0.,    0.,    0.,    0.,    0.,    0.],\n",
      "         [-100., -100., -100., -100., -100., -100., -100., -100.,    0.,    0.,\n",
      "             0.,    0.,    0.,    0.,    0.,    0.],\n",
      "         [-100., -100., -100., -100., -100., -100., -100., -100.,    0.,    0.,\n",
      "             0.,    0.,    0.,    0.,    0.,    0.]],\n",
      "\n",
      "        [[   0.,    0., -100., -100.,    0.,    0., -100., -100., -100., -100.,\n",
      "          -100., -100., -100., -100., -100., -100.],\n",
      "         [   0.,    0., -100., -100.,    0.,    0., -100., -100., -100., -100.,\n",
      "          -100., -100., -100., -100., -100., -100.],\n",
      "         [-100., -100.,    0.,    0., -100., -100.,    0.,    0., -100., -100.,\n",
      "          -100., -100., -100., -100., -100., -100.],\n",
      "         [-100., -100.,    0.,    0., -100., -100.,    0.,    0., -100., -100.,\n",
      "          -100., -100., -100., -100., -100., -100.],\n",
      "         [   0.,    0., -100., -100.,    0.,    0., -100., -100., -100., -100.,\n",
      "          -100., -100., -100., -100., -100., -100.],\n",
      "         [   0.,    0., -100., -100.,    0.,    0., -100., -100., -100., -100.,\n",
      "          -100., -100., -100., -100., -100., -100.],\n",
      "         [-100., -100.,    0.,    0., -100., -100.,    0.,    0., -100., -100.,\n",
      "          -100., -100., -100., -100., -100., -100.],\n",
      "         [-100., -100.,    0.,    0., -100., -100.,    0.,    0., -100., -100.,\n",
      "          -100., -100., -100., -100., -100., -100.],\n",
      "         [-100., -100., -100., -100., -100., -100., -100., -100.,    0.,    0.,\n",
      "          -100., -100.,    0.,    0., -100., -100.],\n",
      "         [-100., -100., -100., -100., -100., -100., -100., -100.,    0.,    0.,\n",
      "          -100., -100.,    0.,    0., -100., -100.],\n",
      "         [-100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n",
      "             0.,    0., -100., -100.,    0.,    0.],\n",
      "         [-100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n",
      "             0.,    0., -100., -100.,    0.,    0.],\n",
      "         [-100., -100., -100., -100., -100., -100., -100., -100.,    0.,    0.,\n",
      "          -100., -100.,    0.,    0., -100., -100.],\n",
      "         [-100., -100., -100., -100., -100., -100., -100., -100.,    0.,    0.,\n",
      "          -100., -100.,    0.,    0., -100., -100.],\n",
      "         [-100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n",
      "             0.,    0., -100., -100.,    0.,    0.],\n",
      "         [-100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n",
      "             0.,    0., -100., -100.,    0.,    0.]]])\n"
     ]
    }
   ],
   "source": [
    "mask_windows = window_partition(img_mask, 4)  # nW, window_size, window_size, 1\n",
    "print('mask_windows_0: ',mask_windows)\n",
    "print('mask_windows_0: ',mask_windows.shape) #[1,8,8,1]->[4, 4, 4, 1]\n",
    "mask_windows = mask_windows.view(-1, 16)\n",
    "print('mask_windows_1: ',mask_windows)\n",
    "print('mask_windows_1: ',mask_windows.shape) #[4,16]\n",
    "attn_mask = mask_windows.unsqueeze(1) - mask_windows.unsqueeze(2)\n",
    "print('mask_windows.unsqueeze(1): ',mask_windows.unsqueeze(1)) #[4,1,16]\n",
    "print('mask_windows.unsqueeze(2): ',mask_windows.unsqueeze(2)) #[4,16,1]\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "print('attn_mask_0: ',attn_mask)\n",
    "print('attn_mask_0: ',attn_mask.shape) #[4, 16, 16]\n",
    "attn_mask = attn_mask.masked_fill(attn_mask != 0, float(-100.0)).masked_fill(attn_mask == 0, float(0.0))\n",
    "print('attn_mask_1: ',attn_mask)\n",
    "torch.set_printoptions(profile=\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e7ff9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#o1 = SwinTransformerBlock(dim=96, input_resolution=(224,224), num_heads=12, window_size=7, shift_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d77e1e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0,  1,  2],\n",
      "          [ 3,  4,  5],\n",
      "          [ 6,  7,  8],\n",
      "          [ 9, 10, 11],\n",
      "          [12, 13, 14]],\n",
      "\n",
      "         [[15, 16, 17],\n",
      "          [18, 19, 20],\n",
      "          [21, 22, 23],\n",
      "          [24, 25, 26],\n",
      "          [27, 28, 29]],\n",
      "\n",
      "         [[30, 31, 32],\n",
      "          [33, 34, 35],\n",
      "          [36, 37, 38],\n",
      "          [39, 40, 41],\n",
      "          [42, 43, 44]],\n",
      "\n",
      "         [[45, 46, 47],\n",
      "          [48, 49, 50],\n",
      "          [51, 52, 53],\n",
      "          [54, 55, 56],\n",
      "          [57, 58, 59]],\n",
      "\n",
      "         [[60, 61, 62],\n",
      "          [63, 64, 65],\n",
      "          [66, 67, 68],\n",
      "          [69, 70, 71],\n",
      "          [72, 73, 74]]]])\n",
      "tensor([[[[36, 37, 38],\n",
      "          [39, 40, 41],\n",
      "          [42, 43, 44],\n",
      "          [30, 31, 32],\n",
      "          [33, 34, 35]],\n",
      "\n",
      "         [[51, 52, 53],\n",
      "          [54, 55, 56],\n",
      "          [57, 58, 59],\n",
      "          [45, 46, 47],\n",
      "          [48, 49, 50]],\n",
      "\n",
      "         [[66, 67, 68],\n",
      "          [69, 70, 71],\n",
      "          [72, 73, 74],\n",
      "          [60, 61, 62],\n",
      "          [63, 64, 65]],\n",
      "\n",
      "         [[ 6,  7,  8],\n",
      "          [ 9, 10, 11],\n",
      "          [12, 13, 14],\n",
      "          [ 0,  1,  2],\n",
      "          [ 3,  4,  5]],\n",
      "\n",
      "         [[21, 22, 23],\n",
      "          [24, 25, 26],\n",
      "          [27, 28, 29],\n",
      "          [15, 16, 17],\n",
      "          [18, 19, 20]]]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.arange(25*3).view(1, 5, 5, 3)\n",
    "print(t1)\n",
    "shifted_t1 = torch.roll(t1, shifts=(-2, -2), dims=(1, 2))\n",
    "print(shifted_t1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d21b852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwinTransformerBlock(nn.Module):\n",
    "    r\"\"\" Swin Transformer Block.\n",
    "    Args:\n",
    "        dim (int): Number of input channels.\n",
    "        input_resolution (tuple[int]): Input resolution.\n",
    "        num_heads (int): Number of attention heads.\n",
    "        window_size (int): Window size.\n",
    "        shift_size (int): Shift size for SW-MSA.\n",
    "        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.\n",
    "        qkv_bias (bool, optional): If True, add a learnable bias to query, key, value. Default: True\n",
    "        qk_scale (float | None, optional): Override default qk scale of head_dim ** -0.5 if set.\n",
    "        drop (float, optional): Dropout rate. Default: 0.0\n",
    "        attn_drop (float, optional): Attention dropout rate. Default: 0.0\n",
    "        drop_path (float, optional): Stochastic depth rate. Default: 0.0\n",
    "        act_layer (nn.Module, optional): Activation layer. Default: nn.GELU\n",
    "        norm_layer (nn.Module, optional): Normalization layer.  Default: nn.LayerNorm\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim, input_resolution, num_heads, window_size=7, shift_size=0,\n",
    "                 mlp_ratio=4., qkv_bias=True, qk_scale=None, drop=0., attn_drop=0., drop_path=0.,\n",
    "                 act_layer=nn.GELU, norm_layer=nn.LayerNorm):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.input_resolution = input_resolution\n",
    "        self.num_heads = num_heads\n",
    "        self.window_size = window_size\n",
    "        self.shift_size = shift_size\n",
    "        self.mlp_ratio = mlp_ratio\n",
    "        if min(self.input_resolution) <= self.window_size:\n",
    "            # if window size is larger than input resolution, we don't partition windows\n",
    "            self.shift_size = 0\n",
    "            self.window_size = min(self.input_resolution)\n",
    "        assert 0 <= self.shift_size < self.window_size, \"shift_size must in 0-window_size\"\n",
    "        \n",
    "        #print('self.window_size: ',self.window_size) #7\n",
    "        #print('self.shift_size: ',self.shift_size) #2\n",
    "\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = WindowAttention(\n",
    "            dim, window_size=to_2tuple(self.window_size), num_heads=num_heads,\n",
    "            qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop)\n",
    "        #print('self.attn: ',self.attn)\n",
    "\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        #print('mlp_hidden_dim: ',mlp_hidden_dim) # 96*4=284\n",
    "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
    "\n",
    "        if self.shift_size > 0:\n",
    "            # calculate attention mask for SW-MSA\n",
    "            H, W = self.input_resolution\n",
    "            img_mask = torch.zeros((1, H, W, 1))  # 1 H W 1\n",
    "            #print('img_mask: ',img_mask.shape) [1, 224, 224, 1]\n",
    "            h_slices = (slice(0, -self.window_size),\n",
    "                        slice(-self.window_size, -self.shift_size),\n",
    "                        slice(-self.shift_size, None))\n",
    "            #print('slice(0, -self.window_size): ',slice(0, -self.window_size))\n",
    "            #print('slice(-self.window_size, -self.shift_size): ',slice(-self.window_size, -self.shift_size))\n",
    "            #print('slice(-self.shift_size, None): ',slice(-self.shift_size, None))\n",
    "            #print('h_slices: ',h_slices)\n",
    "           \n",
    "            w_slices = (slice(0, -self.window_size),\n",
    "                        slice(-self.window_size, -self.shift_size),\n",
    "                        slice(-self.shift_size, None))\n",
    "            #print('w_slices: ',w_slices)\n",
    "            \n",
    "            cnt = 0\n",
    "            for h in h_slices:\n",
    "                for w in w_slices:\n",
    "                    img_mask[:, h, w, :] = cnt\n",
    "                    #torch.set_printoptions(profile=\"full\")\n",
    "                    #print('img_mask: ',img_mask) #[1, 224, 224, 1]\n",
    "                    cnt += 1\n",
    "                    #print('cnt: ',cnt)\n",
    "\n",
    "            mask_windows = window_partition(img_mask, self.window_size)  # nW, window_size, window_size, 1\n",
    "            #print('mask_windows_0: ',mask_windows)\n",
    "            #print('mask_windows_0: ',mask_windows.shape) #[1024, 7, 7, 1]\n",
    "            mask_windows = mask_windows.view(-1, self.window_size * self.window_size)\n",
    "            #print('mask_windows_1: ',mask_windows)\n",
    "            #print('mask_windows_1: ',mask_windows.shape) #[1024, 49]\n",
    "            attn_mask = mask_windows.unsqueeze(1) - mask_windows.unsqueeze(2)\n",
    "            #print('mask_windows.unsqueeze(1): ',mask_windows.unsqueeze(1).shape) #[1024,1,49]\n",
    "            #print('mask_windows.unsqueeze(2): ',mask_windows.unsqueeze(2).shape) #[1024,49,1]\n",
    "            #print('attn_mask_0: ',attn_mask)\n",
    "            #print('attn_mask_0: ',attn_mask.shape) #[1024, 49, 49]\n",
    "            attn_mask = attn_mask.masked_fill(attn_mask != 0, float(-100.0)).masked_fill(attn_mask == 0, float(0.0))\n",
    "            #print('attn_mask_1: ',attn_mask)\n",
    "            #print('attn_mask_1: ',attn_mask.shape)\n",
    "        else:\n",
    "            attn_mask = None\n",
    "\n",
    "        self.register_buffer(\"attn_mask\", attn_mask)\n",
    "\n",
    "    def forward(self, x):\n",
    "        H, W = self.input_resolution\n",
    "        B, L, C = x.shape #[B, 224*224, C]\n",
    "        assert L == H * W, \"input feature has wrong size\"\n",
    "\n",
    "        shortcut = x #[B, 224*224, C]\n",
    "        x = self.norm1(x)\n",
    "        x = x.view(B, H, W, C) #[B, 224, 224, C]\n",
    "\n",
    "        # cyclic shift\n",
    "        if self.shift_size > 0:\n",
    "            shifted_x = torch.roll(x, shifts=(-self.shift_size, -self.shift_size), dims=(1, 2))\n",
    "            #[B, 224, 224, C]\n",
    "        else:\n",
    "            shifted_x = x\n",
    "\n",
    "        # partition windows\n",
    "        x_windows = window_partition(shifted_x, self.window_size)  # nW*B, window_size, window_size, C\n",
    "        #[B, 224, 224, C] -> [(B*32*32), 7, 7, C]\n",
    "        x_windows = x_windows.view(-1, self.window_size * self.window_size, C)  # nW*B, window_size*window_size, C\n",
    "        #[(B*32*32),7,7,C] -> [(B*32*32),49,C]\n",
    "        \n",
    "        # W-MSA/SW-MSA\n",
    "        attn_windows = self.attn(x_windows, mask=self.attn_mask)  # nW*B, window_size*window_size, C\n",
    "        #[(B*1024),49,C]\n",
    "\n",
    "        # merge windows\n",
    "        attn_windows = attn_windows.view(-1, self.window_size, self.window_size, C)\n",
    "        #[(B*1024),49,C] -> [(B*1024),7,7,C]\n",
    "        shifted_x = window_reverse(attn_windows, self.window_size, H, W)  # B H' W' C\n",
    "        #[(B*1024),7,7,C] -> [B, 224, 224, C]\n",
    "\n",
    "        # reverse cyclic shift\n",
    "        if self.shift_size > 0:\n",
    "            x = torch.roll(shifted_x, shifts=(self.shift_size, self.shift_size), dims=(1, 2))\n",
    "        else:\n",
    "            x = shifted_x\n",
    "        x = x.view(B, H * W, C) #[B, 224*224, C]\n",
    "\n",
    "        # FFN\n",
    "        x = shortcut + self.drop_path(x)\n",
    "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "\n",
    "        return x\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f\"dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, \" \\\n",
    "               f\"window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}\"\n",
    "\n",
    "    def flops(self):\n",
    "        flops = 0\n",
    "        H, W = self.input_resolution\n",
    "        # norm1\n",
    "        flops += self.dim * H * W\n",
    "        # W-MSA/SW-MSA\n",
    "        nW = H * W / self.window_size / self.window_size\n",
    "        flops += nW * self.attn.flops(self.window_size * self.window_size)\n",
    "        # mlp\n",
    "        flops += 2 * H * W * self.dim * self.dim * self.mlp_ratio\n",
    "        # norm2\n",
    "        flops += self.dim * H * W\n",
    "        return flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df528fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwinTransformerBlock(nn.Module):\n",
    "    r\"\"\" Swin Transformer Block.\n",
    "    Args:\n",
    "        dim (int): Number of input channels.\n",
    "        input_resolution (tuple[int]): Input resulotion.\n",
    "        num_heads (int): Number of attention heads.\n",
    "        window_size (int): Window size.\n",
    "        shift_size (int): Shift size for SW-MSA.\n",
    "        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.\n",
    "        qkv_bias (bool, optional): If True, add a learnable bias to query, key, value. Default: True\n",
    "        qk_scale (float | None, optional): Override default qk scale of head_dim ** -0.5 if set.\n",
    "        drop (float, optional): Dropout rate. Default: 0.0\n",
    "        attn_drop (float, optional): Attention dropout rate. Default: 0.0\n",
    "        drop_path (float, optional): Stochastic depth rate. Default: 0.0\n",
    "        act_layer (nn.Module, optional): Activation layer. Default: nn.GELU\n",
    "        norm_layer (nn.Module, optional): Normalization layer.  Default: nn.LayerNorm\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim, input_resolution, num_heads, window_size=7, shift_size=0,\n",
    "                 mlp_ratio=4., qkv_bias=True, qk_scale=None, drop=0., attn_drop=0., drop_path=0.,\n",
    "                 act_layer=nn.GELU, norm_layer=nn.LayerNorm):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.input_resolution = input_resolution\n",
    "        self.num_heads = num_heads\n",
    "        self.window_size = window_size\n",
    "        self.shift_size = shift_size\n",
    "        self.mlp_ratio = mlp_ratio\n",
    "        if min(self.input_resolution) <= self.window_size:\n",
    "            # if window size is larger than input resolution, we don't partition windows\n",
    "            self.shift_size = 0\n",
    "            self.window_size = min(self.input_resolution)\n",
    "        assert 0 <= self.shift_size < self.window_size, \"shift_size must in 0-window_size\"\n",
    "\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = WindowAttention(\n",
    "            dim, window_size=to_2tuple(self.window_size), num_heads=num_heads,\n",
    "            qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop)\n",
    "\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
    "\n",
    "        if self.shift_size > 0:\n",
    "            # calculate attention mask for SW-MSA\n",
    "            H, W = self.input_resolution\n",
    "            img_mask = torch.zeros((1, H, W, 1))  # 1 H W 1\n",
    "            h_slices = (slice(0, -self.window_size),\n",
    "                        slice(-self.window_size, -self.shift_size),\n",
    "                        slice(-self.shift_size, None))\n",
    "            w_slices = (slice(0, -self.window_size),\n",
    "                        slice(-self.window_size, -self.shift_size),\n",
    "                        slice(-self.shift_size, None))\n",
    "            cnt = 0\n",
    "            for h in h_slices:\n",
    "                for w in w_slices:\n",
    "                    img_mask[:, h, w, :] = cnt\n",
    "                    cnt += 1\n",
    "\n",
    "            mask_windows = window_partition(img_mask, self.window_size)  # nW, window_size, window_size, 1\n",
    "            mask_windows = mask_windows.view(-1, self.window_size * self.window_size)\n",
    "            attn_mask = mask_windows.unsqueeze(1) - mask_windows.unsqueeze(2)\n",
    "            attn_mask = attn_mask.masked_fill(attn_mask != 0, float(-100.0)).masked_fill(attn_mask == 0, float(0.0))\n",
    "        else:\n",
    "            attn_mask = None\n",
    "\n",
    "        self.register_buffer(\"attn_mask\", attn_mask)\n",
    "\n",
    "    def forward(self, x):\n",
    "        H, W = self.input_resolution\n",
    "        B, L, C = x.shape\n",
    "        assert L == H * W, \"input feature has wrong size\"\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = x.view(B, H, W, C)\n",
    "\n",
    "        # cyclic shift\n",
    "        if self.shift_size > 0:\n",
    "            shifted_x = torch.roll(x, shifts=(-self.shift_size, -self.shift_size), dims=(1, 2))\n",
    "        else:\n",
    "            shifted_x = x\n",
    "\n",
    "        # partition windows\n",
    "        x_windows = window_partition(shifted_x, self.window_size)  # nW*B, window_size, window_size, C\n",
    "        x_windows = x_windows.view(-1, self.window_size * self.window_size, C)  # nW*B, window_size*window_size, C\n",
    "\n",
    "        # W-MSA/SW-MSA\n",
    "        attn_windows = self.attn(x_windows, mask=self.attn_mask)  # nW*B, window_size*window_size, C\n",
    "\n",
    "        # merge windows\n",
    "        attn_windows = attn_windows.view(-1, self.window_size, self.window_size, C)\n",
    "        shifted_x = window_reverse(attn_windows, self.window_size, H, W)  # B H' W' C\n",
    "\n",
    "        # reverse cyclic shift\n",
    "        if self.shift_size > 0:\n",
    "            x = torch.roll(shifted_x, shifts=(self.shift_size, self.shift_size), dims=(1, 2))\n",
    "        else:\n",
    "            x = shifted_x\n",
    "        x = x.view(B, H * W, C)\n",
    "\n",
    "        # FFN\n",
    "        x = shortcut + self.drop_path(x)\n",
    "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "\n",
    "        return x\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f\"dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, \" \\\n",
    "               f\"window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}\"\n",
    "\n",
    "    def flops(self):\n",
    "        flops = 0\n",
    "        H, W = self.input_resolution\n",
    "        # norm1\n",
    "        flops += self.dim * H * W\n",
    "        # W-MSA/SW-MSA\n",
    "        nW = H * W / self.window_size / self.window_size\n",
    "        flops += nW * self.attn.flops(self.window_size * self.window_size)\n",
    "        # mlp\n",
    "        flops += 2 * H * W * self.dim * self.dim * self.mlp_ratio\n",
    "        # norm2\n",
    "        flops += self.dim * H * W\n",
    "        return flops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd694dc",
   "metadata": {},
   "source": [
    "# Patch Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d0d7cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchMerging(nn.Module):\n",
    "    r\"\"\" Patch Merging Layer.\n",
    "    Args:\n",
    "        input_resolution (tuple[int]): Resolution of input feature.\n",
    "        dim (int): Number of input channels.\n",
    "        norm_layer (nn.Module, optional): Normalization layer.  Default: nn.LayerNorm\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_resolution, dim, norm_layer=nn.LayerNorm):\n",
    "        super().__init__()\n",
    "        self.input_resolution = input_resolution\n",
    "        self.dim = dim\n",
    "        self.reduction = nn.Linear(4 * dim, 2 * dim, bias=False)\n",
    "        self.norm = norm_layer(4 * dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: B, H*W, C\n",
    "        \"\"\"\n",
    "        H, W = self.input_resolution\n",
    "        B, L, C = x.shape\n",
    "        assert L == H * W, \"input feature has wrong size\"\n",
    "        assert H % 2 == 0 and W % 2 == 0, f\"x size ({H}*{W}) are not even.\"\n",
    "\n",
    "        x = x.view(B, H, W, C)\n",
    "\n",
    "        x0 = x[:, 0::2, 0::2, :]  # B H/2 W/2 C\n",
    "        x1 = x[:, 1::2, 0::2, :]  # B H/2 W/2 C\n",
    "        x2 = x[:, 0::2, 1::2, :]  # B H/2 W/2 C\n",
    "        x3 = x[:, 1::2, 1::2, :]  # B H/2 W/2 C\n",
    "        x = torch.cat([x0, x1, x2, x3], -1)  # B H/2 W/2 4*C\n",
    "        x = x.view(B, -1, 4 * C)  # B H/2*W/2 4*C\n",
    "\n",
    "        x = self.norm(x)\n",
    "        x = self.reduction(x) # B H/2*W/2 2C\n",
    "\n",
    "        return x\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f\"input_resolution={self.input_resolution}, dim={self.dim}\"\n",
    "\n",
    "    def flops(self):\n",
    "        H, W = self.input_resolution\n",
    "        flops = H * W * self.dim\n",
    "        flops += (H // 2) * (W // 2) * 4 * self.dim * 2 * self.dim\n",
    "        return flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "526a506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicLayer(nn.Module):\n",
    "    \"\"\" A basic Swin Transformer layer for one stage.\n",
    "    Args:\n",
    "        dim (int): Number of input channels.\n",
    "        input_resolution (tuple[int]): Input resolution.\n",
    "        depth (int): Number of blocks.\n",
    "        num_heads (int): Number of attention heads.\n",
    "        window_size (int): Local window size.\n",
    "        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.\n",
    "        qkv_bias (bool, optional): If True, add a learnable bias to query, key, value. Default: True\n",
    "        qk_scale (float | None, optional): Override default qk scale of head_dim ** -0.5 if set.\n",
    "        drop (float, optional): Dropout rate. Default: 0.0\n",
    "        attn_drop (float, optional): Attention dropout rate. Default: 0.0\n",
    "        drop_path (float | tuple[float], optional): Stochastic depth rate. Default: 0.0\n",
    "        norm_layer (nn.Module, optional): Normalization layer. Default: nn.LayerNorm\n",
    "        downsample (nn.Module | None, optional): Downsample layer at the end of the layer. Default: None\n",
    "        use_checkpoint (bool): Whether to use checkpointing to save memory. Default: False.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim, input_resolution, depth, num_heads, window_size,\n",
    "                 mlp_ratio=4., qkv_bias=True, qk_scale=None, drop=0., attn_drop=0.,\n",
    "                 drop_path=0., norm_layer=nn.LayerNorm, downsample=None, use_checkpoint=False):\n",
    "\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.input_resolution = input_resolution\n",
    "        self.depth = depth\n",
    "        self.use_checkpoint = use_checkpoint\n",
    "\n",
    "        # build blocks\n",
    "        self.blocks = nn.ModuleList([\n",
    "            SwinTransformerBlock(dim=dim, input_resolution=input_resolution,\n",
    "                                 num_heads=num_heads, window_size=window_size,\n",
    "                                 shift_size=0 if (i % 2 == 0) else window_size // 2,\n",
    "                                 mlp_ratio=mlp_ratio,\n",
    "                                 qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                                 drop=drop, attn_drop=attn_drop,\n",
    "                                 drop_path=drop_path[i] if isinstance(drop_path, list) else drop_path,\n",
    "                                 norm_layer=norm_layer)\n",
    "            for i in range(depth)])\n",
    "\n",
    "        # patch merging layer\n",
    "        if downsample is not None:\n",
    "            self.downsample = downsample(input_resolution, dim=dim, norm_layer=norm_layer)\n",
    "        else:\n",
    "            self.downsample = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        for blk in self.blocks:\n",
    "            print('basic-layer: ')\n",
    "            print(x.shape)\n",
    "            if self.use_checkpoint:\n",
    "                x = checkpoint.checkpoint(blk, x)\n",
    "            else:\n",
    "                x = blk(x)\n",
    "        if self.downsample is not None:\n",
    "            \n",
    "            x = self.downsample(x)\n",
    "            print('basic-layer-downsample: ')\n",
    "            print(x.shape)\n",
    "        return x\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f\"dim={self.dim}, input_resolution={self.input_resolution}, depth={self.depth}\"\n",
    "\n",
    "    def flops(self):\n",
    "        flops = 0\n",
    "        for blk in self.blocks:\n",
    "            flops += blk.flops()\n",
    "        if self.downsample is not None:\n",
    "            flops += self.downsample.flops()\n",
    "        return flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "910c1f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEmbed(nn.Module):\n",
    "    r\"\"\" Image to Patch Embedding\n",
    "    Args:\n",
    "        img_size (int): Image size.  Default: 224.\n",
    "        patch_size (int): Patch token size. Default: 4.\n",
    "        in_chans (int): Number of input image channels. Default: 3.\n",
    "        embed_dim (int): Number of linear projection output channels. Default: 96.\n",
    "        norm_layer (nn.Module, optional): Normalization layer. Default: None\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, img_size=224, patch_size=4, in_chans=3, embed_dim=96, norm_layer=None):\n",
    "        super().__init__()\n",
    "        img_size = to_2tuple(img_size)\n",
    "        patch_size = to_2tuple(patch_size)\n",
    "        patches_resolution = [img_size[0] // patch_size[0], img_size[1] // patch_size[1]]\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.patches_resolution = patches_resolution #[56, 56]\n",
    "        self.num_patches = patches_resolution[0] * patches_resolution[1] #[56*56]\n",
    "\n",
    "        self.in_chans = in_chans\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        if norm_layer is not None:\n",
    "            self.norm = norm_layer(embed_dim)\n",
    "        else:\n",
    "            self.norm = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        print('patch-emd-0: ',x.shape)\n",
    "        # FIXME look at relaxing size constraints\n",
    "        assert H == self.img_size[0] and W == self.img_size[1], \\\n",
    "            f\"Input image size ({H}*{W}) doesn't match model ({self.img_size[0]}*{self.img_size[1]}).\"\n",
    "        print('patch-emd-1: ',self.proj(x).shape)\n",
    "        print('patch-emd-2: ',self.proj(x).flatten(2).shape)\n",
    "        x = self.proj(x).flatten(2).transpose(1, 2)  # B Ph*Pw C\n",
    "        print('patch-emd-3: ',x.shape)\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "        return x\n",
    "\n",
    "    def flops(self):\n",
    "        Ho, Wo = self.patches_resolution\n",
    "        flops = Ho * Wo * self.embed_dim * self.in_chans * (self.patch_size[0] * self.patch_size[1])\n",
    "        if self.norm is not None:\n",
    "            flops += Ho * Wo * self.embed_dim\n",
    "        return flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5e6f736",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwinTransformer(nn.Module):\n",
    "    r\"\"\" Swin Transformer\n",
    "        A PyTorch impl of : `Swin Transformer: Hierarchical Vision Transformer using Shifted Windows`  -\n",
    "          https://arxiv.org/pdf/2103.14030\n",
    "    Args:\n",
    "        img_size (int | tuple(int)): Input image size. Default 224\n",
    "        patch_size (int | tuple(int)): Patch size. Default: 4\n",
    "        in_chans (int): Number of input image channels. Default: 3\n",
    "        num_classes (int): Number of classes for classification head. Default: 1000\n",
    "        embed_dim (int): Patch embedding dimension. Default: 96\n",
    "        depths (tuple(int)): Depth of each Swin Transformer layer.\n",
    "        num_heads (tuple(int)): Number of attention heads in different layers.\n",
    "        window_size (int): Window size. Default: 7\n",
    "        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim. Default: 4\n",
    "        qkv_bias (bool): If True, add a learnable bias to query, key, value. Default: True\n",
    "        qk_scale (float): Override default qk scale of head_dim ** -0.5 if set. Default: None\n",
    "        drop_rate (float): Dropout rate. Default: 0\n",
    "        attn_drop_rate (float): Attention dropout rate. Default: 0\n",
    "        drop_path_rate (float): Stochastic depth rate. Default: 0.1\n",
    "        norm_layer (nn.Module): Normalization layer. Default: nn.LayerNorm.\n",
    "        ape (bool): If True, add absolute position embedding to the patch embedding. Default: False\n",
    "        patch_norm (bool): If True, add normalization after patch embedding. Default: True\n",
    "        use_checkpoint (bool): Whether to use checkpointing to save memory. Default: False\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, img_size=224, patch_size=4, in_chans=3, num_classes=1000,\n",
    "                 embed_dim=96, depths=[2, 2, 6, 2], num_heads=[3, 6, 12, 24],\n",
    "                 window_size=7, mlp_ratio=4., qkv_bias=True, qk_scale=None,\n",
    "                 drop_rate=0., attn_drop_rate=0., drop_path_rate=0.1,\n",
    "                 norm_layer=nn.LayerNorm, ape=False, patch_norm=True,\n",
    "                 use_checkpoint=False, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = len(depths)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.ape = ape\n",
    "        self.patch_norm = patch_norm\n",
    "        self.num_features = int(embed_dim * 2 ** (self.num_layers - 1))\n",
    "        self.mlp_ratio = mlp_ratio\n",
    "\n",
    "        # split image into non-overlapping patches\n",
    "        self.patch_embed = PatchEmbed(\n",
    "            img_size=img_size, patch_size=patch_size, in_chans=in_chans, embed_dim=embed_dim,\n",
    "            norm_layer=norm_layer if self.patch_norm else None)\n",
    "        num_patches = self.patch_embed.num_patches\n",
    "        patches_resolution = self.patch_embed.patches_resolution\n",
    "        self.patches_resolution = patches_resolution\n",
    "\n",
    "        # absolute position embedding\n",
    "        if self.ape:\n",
    "            self.absolute_pos_embed = nn.Parameter(torch.zeros(1, num_patches, embed_dim))\n",
    "            trunc_normal_(self.absolute_pos_embed, std=.02)\n",
    "\n",
    "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
    "\n",
    "        # stochastic depth\n",
    "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))]  # stochastic depth decay rule\n",
    "        print('SwinTransformer-dpr: ',dpr)\n",
    "\n",
    "        # build layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i_layer in range(self.num_layers):\n",
    "            \n",
    "            layer = BasicLayer(dim=int(embed_dim * 2 ** i_layer),\n",
    "                               input_resolution=(patches_resolution[0] // (2 ** i_layer),\n",
    "                                                 patches_resolution[1] // (2 ** i_layer)),\n",
    "                               depth=depths[i_layer],\n",
    "                               num_heads=num_heads[i_layer],\n",
    "                               window_size=window_size,\n",
    "                               mlp_ratio=self.mlp_ratio,\n",
    "                               qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                               drop=drop_rate, attn_drop=attn_drop_rate,\n",
    "                               drop_path=dpr[sum(depths[:i_layer]):sum(depths[:i_layer + 1])],\n",
    "                               norm_layer=norm_layer,\n",
    "                               downsample=PatchMerging if (i_layer < self.num_layers - 1) else None,\n",
    "                               use_checkpoint=use_checkpoint)\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        self.norm = norm_layer(self.num_features)\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.head = nn.Linear(self.num_features, num_classes) if num_classes > 0 else nn.Identity()\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay(self):\n",
    "        return {'absolute_pos_embed'}\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay_keywords(self):\n",
    "        return {'relative_position_bias_table'}\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        print('SwinTransformer-x0: ',x.shape)\n",
    "        x = self.patch_embed(x)\n",
    "        print('SwinTransformer-x1-after_emb: ',x.shape)\n",
    "        if self.ape:\n",
    "            x = x + self.absolute_pos_embed\n",
    "        x = self.pos_drop(x)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "            print('SwinTransformer-x2-after_basic_layer: ',x.shape)\n",
    "\n",
    "        x = self.norm(x)  # B L C\n",
    "        x = self.avgpool(x.transpose(1, 2))  # B C 1\n",
    "        print('SwinTransformer-x3-after_avgpool: ',x.shape)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        print('SwinTransformer-x4-after_flatten: ',x.shape)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "    def flops(self):\n",
    "        flops = 0\n",
    "        flops += self.patch_embed.flops()\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            flops += layer.flops()\n",
    "        flops += self.num_features * self.patches_resolution[0] * self.patches_resolution[1] // (2 ** self.num_layers)\n",
    "        flops += self.num_features * self.num_classes\n",
    "        return flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "515f397f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "231996f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SwinTransformer-dpr:  [0.0, 0.00909090880304575, 0.0181818176060915, 0.027272727340459824, 0.036363635212183, 0.045454543083906174, 0.054545458406209946, 0.06363636255264282, 0.0727272778749466, 0.08181818574666977, 0.09090909361839294, 0.10000000149011612]\n"
     ]
    }
   ],
   "source": [
    "swin = SwinTransformer(img_size=224, patch_size=4, in_chans=3, num_classes=1000,\n",
    "                 embed_dim=96, depths=[2, 2, 6, 2], num_heads=[3, 6, 12, 24],\n",
    "                 window_size=7, mlp_ratio=4., qkv_bias=True, qk_scale=None,\n",
    "                 drop_rate=0., attn_drop_rate=0., drop_path_rate=0.1,\n",
    "                 norm_layer=nn.LayerNorm, ape=False, patch_norm=True,\n",
    "                 use_checkpoint=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e5d7e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SwinTransformer-x0:  torch.Size([2, 3, 224, 224])\n",
      "patch-emd-0:  torch.Size([2, 3, 224, 224])\n",
      "patch-emd-1:  torch.Size([2, 96, 56, 56])\n",
      "patch-emd-2:  torch.Size([2, 96, 3136])\n",
      "patch-emd-3:  torch.Size([2, 3136, 96])\n",
      "SwinTransformer-x1-after_emb:  torch.Size([2, 3136, 96])\n",
      "basic-layer: \n",
      "torch.Size([2, 3136, 96])\n",
      "basic-layer: \n",
      "torch.Size([2, 3136, 96])\n",
      "basic-layer-downsample: \n",
      "torch.Size([2, 784, 192])\n",
      "SwinTransformer-x2-after_basic_layer:  torch.Size([2, 784, 192])\n",
      "basic-layer: \n",
      "torch.Size([2, 784, 192])\n",
      "basic-layer: \n",
      "torch.Size([2, 784, 192])\n",
      "basic-layer-downsample: \n",
      "torch.Size([2, 196, 384])\n",
      "SwinTransformer-x2-after_basic_layer:  torch.Size([2, 196, 384])\n",
      "basic-layer: \n",
      "torch.Size([2, 196, 384])\n",
      "basic-layer: \n",
      "torch.Size([2, 196, 384])\n",
      "basic-layer: \n",
      "torch.Size([2, 196, 384])\n",
      "basic-layer: \n",
      "torch.Size([2, 196, 384])\n",
      "basic-layer: \n",
      "torch.Size([2, 196, 384])\n",
      "basic-layer: \n",
      "torch.Size([2, 196, 384])\n",
      "basic-layer-downsample: \n",
      "torch.Size([2, 49, 768])\n",
      "SwinTransformer-x2-after_basic_layer:  torch.Size([2, 49, 768])\n",
      "basic-layer: \n",
      "torch.Size([2, 49, 768])\n",
      "basic-layer: \n",
      "torch.Size([2, 49, 768])\n",
      "SwinTransformer-x2-after_basic_layer:  torch.Size([2, 49, 768])\n",
      "SwinTransformer-x3-after_avgpool:  torch.Size([2, 768, 1])\n",
      "SwinTransformer-x4-after_flatten:  torch.Size([2, 768])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 96, 56, 56]           4,704\n",
      "            Conv2d-2           [-1, 96, 56, 56]           4,704\n",
      "            Conv2d-3           [-1, 96, 56, 56]           4,704\n",
      "         LayerNorm-4             [-1, 3136, 96]             192\n",
      "        PatchEmbed-5             [-1, 3136, 96]               0\n",
      "           Dropout-6             [-1, 3136, 96]               0\n",
      "         LayerNorm-7             [-1, 3136, 96]             192\n",
      "            Linear-8              [-1, 49, 288]          27,936\n",
      "           Softmax-9            [-1, 3, 49, 49]               0\n",
      "          Dropout-10            [-1, 3, 49, 49]               0\n",
      "           Linear-11               [-1, 49, 96]           9,312\n",
      "          Dropout-12               [-1, 49, 96]               0\n",
      "  WindowAttention-13               [-1, 49, 96]               0\n",
      "         Identity-14             [-1, 3136, 96]               0\n",
      "        LayerNorm-15             [-1, 3136, 96]             192\n",
      "           Linear-16            [-1, 3136, 384]          37,248\n",
      "             GELU-17            [-1, 3136, 384]               0\n",
      "          Dropout-18            [-1, 3136, 384]               0\n",
      "           Linear-19             [-1, 3136, 96]          36,960\n",
      "          Dropout-20             [-1, 3136, 96]               0\n",
      "              Mlp-21             [-1, 3136, 96]               0\n",
      "         Identity-22             [-1, 3136, 96]               0\n",
      "SwinTransformerBlock-23             [-1, 3136, 96]               0\n",
      "        LayerNorm-24             [-1, 3136, 96]             192\n",
      "           Linear-25              [-1, 49, 288]          27,936\n",
      "          Softmax-26            [-1, 3, 49, 49]               0\n",
      "          Dropout-27            [-1, 3, 49, 49]               0\n",
      "           Linear-28               [-1, 49, 96]           9,312\n",
      "          Dropout-29               [-1, 49, 96]               0\n",
      "  WindowAttention-30               [-1, 49, 96]               0\n",
      "         DropPath-31             [-1, 3136, 96]               0\n",
      "        LayerNorm-32             [-1, 3136, 96]             192\n",
      "           Linear-33            [-1, 3136, 384]          37,248\n",
      "             GELU-34            [-1, 3136, 384]               0\n",
      "          Dropout-35            [-1, 3136, 384]               0\n",
      "           Linear-36             [-1, 3136, 96]          36,960\n",
      "          Dropout-37             [-1, 3136, 96]               0\n",
      "              Mlp-38             [-1, 3136, 96]               0\n",
      "         DropPath-39             [-1, 3136, 96]               0\n",
      "SwinTransformerBlock-40             [-1, 3136, 96]               0\n",
      "        LayerNorm-41             [-1, 784, 384]             768\n",
      "           Linear-42             [-1, 784, 192]          73,728\n",
      "     PatchMerging-43             [-1, 784, 192]               0\n",
      "       BasicLayer-44             [-1, 784, 192]               0\n",
      "        LayerNorm-45             [-1, 784, 192]             384\n",
      "           Linear-46              [-1, 49, 576]         111,168\n",
      "          Softmax-47            [-1, 6, 49, 49]               0\n",
      "          Dropout-48            [-1, 6, 49, 49]               0\n",
      "           Linear-49              [-1, 49, 192]          37,056\n",
      "          Dropout-50              [-1, 49, 192]               0\n",
      "  WindowAttention-51              [-1, 49, 192]               0\n",
      "         DropPath-52             [-1, 784, 192]               0\n",
      "        LayerNorm-53             [-1, 784, 192]             384\n",
      "           Linear-54             [-1, 784, 768]         148,224\n",
      "             GELU-55             [-1, 784, 768]               0\n",
      "          Dropout-56             [-1, 784, 768]               0\n",
      "           Linear-57             [-1, 784, 192]         147,648\n",
      "          Dropout-58             [-1, 784, 192]               0\n",
      "              Mlp-59             [-1, 784, 192]               0\n",
      "         DropPath-60             [-1, 784, 192]               0\n",
      "SwinTransformerBlock-61             [-1, 784, 192]               0\n",
      "        LayerNorm-62             [-1, 784, 192]             384\n",
      "           Linear-63              [-1, 49, 576]         111,168\n",
      "          Softmax-64            [-1, 6, 49, 49]               0\n",
      "          Dropout-65            [-1, 6, 49, 49]               0\n",
      "           Linear-66              [-1, 49, 192]          37,056\n",
      "          Dropout-67              [-1, 49, 192]               0\n",
      "  WindowAttention-68              [-1, 49, 192]               0\n",
      "         DropPath-69             [-1, 784, 192]               0\n",
      "        LayerNorm-70             [-1, 784, 192]             384\n",
      "           Linear-71             [-1, 784, 768]         148,224\n",
      "             GELU-72             [-1, 784, 768]               0\n",
      "          Dropout-73             [-1, 784, 768]               0\n",
      "           Linear-74             [-1, 784, 192]         147,648\n",
      "          Dropout-75             [-1, 784, 192]               0\n",
      "              Mlp-76             [-1, 784, 192]               0\n",
      "         DropPath-77             [-1, 784, 192]               0\n",
      "SwinTransformerBlock-78             [-1, 784, 192]               0\n",
      "        LayerNorm-79             [-1, 196, 768]           1,536\n",
      "           Linear-80             [-1, 196, 384]         294,912\n",
      "     PatchMerging-81             [-1, 196, 384]               0\n",
      "       BasicLayer-82             [-1, 196, 384]               0\n",
      "        LayerNorm-83             [-1, 196, 384]             768\n",
      "           Linear-84             [-1, 49, 1152]         443,520\n",
      "          Softmax-85           [-1, 12, 49, 49]               0\n",
      "          Dropout-86           [-1, 12, 49, 49]               0\n",
      "           Linear-87              [-1, 49, 384]         147,840\n",
      "          Dropout-88              [-1, 49, 384]               0\n",
      "  WindowAttention-89              [-1, 49, 384]               0\n",
      "         DropPath-90             [-1, 196, 384]               0\n",
      "        LayerNorm-91             [-1, 196, 384]             768\n",
      "           Linear-92            [-1, 196, 1536]         591,360\n",
      "             GELU-93            [-1, 196, 1536]               0\n",
      "          Dropout-94            [-1, 196, 1536]               0\n",
      "           Linear-95             [-1, 196, 384]         590,208\n",
      "          Dropout-96             [-1, 196, 384]               0\n",
      "              Mlp-97             [-1, 196, 384]               0\n",
      "         DropPath-98             [-1, 196, 384]               0\n",
      "SwinTransformerBlock-99             [-1, 196, 384]               0\n",
      "       LayerNorm-100             [-1, 196, 384]             768\n",
      "          Linear-101             [-1, 49, 1152]         443,520\n",
      "         Softmax-102           [-1, 12, 49, 49]               0\n",
      "         Dropout-103           [-1, 12, 49, 49]               0\n",
      "          Linear-104              [-1, 49, 384]         147,840\n",
      "         Dropout-105              [-1, 49, 384]               0\n",
      " WindowAttention-106              [-1, 49, 384]               0\n",
      "        DropPath-107             [-1, 196, 384]               0\n",
      "       LayerNorm-108             [-1, 196, 384]             768\n",
      "          Linear-109            [-1, 196, 1536]         591,360\n",
      "            GELU-110            [-1, 196, 1536]               0\n",
      "         Dropout-111            [-1, 196, 1536]               0\n",
      "          Linear-112             [-1, 196, 384]         590,208\n",
      "         Dropout-113             [-1, 196, 384]               0\n",
      "             Mlp-114             [-1, 196, 384]               0\n",
      "        DropPath-115             [-1, 196, 384]               0\n",
      "SwinTransformerBlock-116             [-1, 196, 384]               0\n",
      "       LayerNorm-117             [-1, 196, 384]             768\n",
      "          Linear-118             [-1, 49, 1152]         443,520\n",
      "         Softmax-119           [-1, 12, 49, 49]               0\n",
      "         Dropout-120           [-1, 12, 49, 49]               0\n",
      "          Linear-121              [-1, 49, 384]         147,840\n",
      "         Dropout-122              [-1, 49, 384]               0\n",
      " WindowAttention-123              [-1, 49, 384]               0\n",
      "        DropPath-124             [-1, 196, 384]               0\n",
      "       LayerNorm-125             [-1, 196, 384]             768\n",
      "          Linear-126            [-1, 196, 1536]         591,360\n",
      "            GELU-127            [-1, 196, 1536]               0\n",
      "         Dropout-128            [-1, 196, 1536]               0\n",
      "          Linear-129             [-1, 196, 384]         590,208\n",
      "         Dropout-130             [-1, 196, 384]               0\n",
      "             Mlp-131             [-1, 196, 384]               0\n",
      "        DropPath-132             [-1, 196, 384]               0\n",
      "SwinTransformerBlock-133             [-1, 196, 384]               0\n",
      "       LayerNorm-134             [-1, 196, 384]             768\n",
      "          Linear-135             [-1, 49, 1152]         443,520\n",
      "         Softmax-136           [-1, 12, 49, 49]               0\n",
      "         Dropout-137           [-1, 12, 49, 49]               0\n",
      "          Linear-138              [-1, 49, 384]         147,840\n",
      "         Dropout-139              [-1, 49, 384]               0\n",
      " WindowAttention-140              [-1, 49, 384]               0\n",
      "        DropPath-141             [-1, 196, 384]               0\n",
      "       LayerNorm-142             [-1, 196, 384]             768\n",
      "          Linear-143            [-1, 196, 1536]         591,360\n",
      "            GELU-144            [-1, 196, 1536]               0\n",
      "         Dropout-145            [-1, 196, 1536]               0\n",
      "          Linear-146             [-1, 196, 384]         590,208\n",
      "         Dropout-147             [-1, 196, 384]               0\n",
      "             Mlp-148             [-1, 196, 384]               0\n",
      "        DropPath-149             [-1, 196, 384]               0\n",
      "SwinTransformerBlock-150             [-1, 196, 384]               0\n",
      "       LayerNorm-151             [-1, 196, 384]             768\n",
      "          Linear-152             [-1, 49, 1152]         443,520\n",
      "         Softmax-153           [-1, 12, 49, 49]               0\n",
      "         Dropout-154           [-1, 12, 49, 49]               0\n",
      "          Linear-155              [-1, 49, 384]         147,840\n",
      "         Dropout-156              [-1, 49, 384]               0\n",
      " WindowAttention-157              [-1, 49, 384]               0\n",
      "        DropPath-158             [-1, 196, 384]               0\n",
      "       LayerNorm-159             [-1, 196, 384]             768\n",
      "          Linear-160            [-1, 196, 1536]         591,360\n",
      "            GELU-161            [-1, 196, 1536]               0\n",
      "         Dropout-162            [-1, 196, 1536]               0\n",
      "          Linear-163             [-1, 196, 384]         590,208\n",
      "         Dropout-164             [-1, 196, 384]               0\n",
      "             Mlp-165             [-1, 196, 384]               0\n",
      "        DropPath-166             [-1, 196, 384]               0\n",
      "SwinTransformerBlock-167             [-1, 196, 384]               0\n",
      "       LayerNorm-168             [-1, 196, 384]             768\n",
      "          Linear-169             [-1, 49, 1152]         443,520\n",
      "         Softmax-170           [-1, 12, 49, 49]               0\n",
      "         Dropout-171           [-1, 12, 49, 49]               0\n",
      "          Linear-172              [-1, 49, 384]         147,840\n",
      "         Dropout-173              [-1, 49, 384]               0\n",
      " WindowAttention-174              [-1, 49, 384]               0\n",
      "        DropPath-175             [-1, 196, 384]               0\n",
      "       LayerNorm-176             [-1, 196, 384]             768\n",
      "          Linear-177            [-1, 196, 1536]         591,360\n",
      "            GELU-178            [-1, 196, 1536]               0\n",
      "         Dropout-179            [-1, 196, 1536]               0\n",
      "          Linear-180             [-1, 196, 384]         590,208\n",
      "         Dropout-181             [-1, 196, 384]               0\n",
      "             Mlp-182             [-1, 196, 384]               0\n",
      "        DropPath-183             [-1, 196, 384]               0\n",
      "SwinTransformerBlock-184             [-1, 196, 384]               0\n",
      "       LayerNorm-185             [-1, 49, 1536]           3,072\n",
      "          Linear-186              [-1, 49, 768]       1,179,648\n",
      "    PatchMerging-187              [-1, 49, 768]               0\n",
      "      BasicLayer-188              [-1, 49, 768]               0\n",
      "       LayerNorm-189              [-1, 49, 768]           1,536\n",
      "          Linear-190             [-1, 49, 2304]       1,771,776\n",
      "         Softmax-191           [-1, 24, 49, 49]               0\n",
      "         Dropout-192           [-1, 24, 49, 49]               0\n",
      "          Linear-193              [-1, 49, 768]         590,592\n",
      "         Dropout-194              [-1, 49, 768]               0\n",
      " WindowAttention-195              [-1, 49, 768]               0\n",
      "        DropPath-196              [-1, 49, 768]               0\n",
      "       LayerNorm-197              [-1, 49, 768]           1,536\n",
      "          Linear-198             [-1, 49, 3072]       2,362,368\n",
      "            GELU-199             [-1, 49, 3072]               0\n",
      "         Dropout-200             [-1, 49, 3072]               0\n",
      "          Linear-201              [-1, 49, 768]       2,360,064\n",
      "         Dropout-202              [-1, 49, 768]               0\n",
      "             Mlp-203              [-1, 49, 768]               0\n",
      "        DropPath-204              [-1, 49, 768]               0\n",
      "SwinTransformerBlock-205              [-1, 49, 768]               0\n",
      "       LayerNorm-206              [-1, 49, 768]           1,536\n",
      "          Linear-207             [-1, 49, 2304]       1,771,776\n",
      "         Softmax-208           [-1, 24, 49, 49]               0\n",
      "         Dropout-209           [-1, 24, 49, 49]               0\n",
      "          Linear-210              [-1, 49, 768]         590,592\n",
      "         Dropout-211              [-1, 49, 768]               0\n",
      " WindowAttention-212              [-1, 49, 768]               0\n",
      "        DropPath-213              [-1, 49, 768]               0\n",
      "       LayerNorm-214              [-1, 49, 768]           1,536\n",
      "          Linear-215             [-1, 49, 3072]       2,362,368\n",
      "            GELU-216             [-1, 49, 3072]               0\n",
      "         Dropout-217             [-1, 49, 3072]               0\n",
      "          Linear-218              [-1, 49, 768]       2,360,064\n",
      "         Dropout-219              [-1, 49, 768]               0\n",
      "             Mlp-220              [-1, 49, 768]               0\n",
      "        DropPath-221              [-1, 49, 768]               0\n",
      "SwinTransformerBlock-222              [-1, 49, 768]               0\n",
      "      BasicLayer-223              [-1, 49, 768]               0\n",
      "       LayerNorm-224              [-1, 49, 768]           1,536\n",
      "AdaptiveAvgPool1d-225               [-1, 768, 1]               0\n",
      "          Linear-226                 [-1, 1000]         769,000\n",
      "================================================================\n",
      "Total params: 28,274,440\n",
      "Trainable params: 28,274,440\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 257.58\n",
      "Params size (MB): 107.86\n",
      "Estimated Total Size (MB): 366.01\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(swin, (3, 224, 224), device='cpu')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
