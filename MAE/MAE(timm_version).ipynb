{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c077f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from functools import partial\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ed4b80",
   "metadata": {},
   "source": [
    "# Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20b4940f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import repeat\n",
    "import collections.abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52bf73e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From PyTorch internals\n",
    "def _ntuple(n):\n",
    "    def parse(x):\n",
    "        if isinstance(x, collections.abc.Iterable):\n",
    "            return x\n",
    "        return tuple(repeat(x, n))\n",
    "    return parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0b95460",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_1tuple = _ntuple(1)\n",
    "to_2tuple = _ntuple(2)\n",
    "to_3tuple = _ntuple(3)\n",
    "to_4tuple = _ntuple(4)\n",
    "to_ntuple = _ntuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb8aaadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import _assert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6e82045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "815dfee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _no_grad_trunc_normal_(tensor, mean, std, a, b):\n",
    "    # Cut & paste from PyTorch official master until it's in a few official releases - RW\n",
    "    # Method based on https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf\n",
    "    def norm_cdf(x):\n",
    "        # Computes standard normal cumulative distribution function\n",
    "        return (1. + math.erf(x / math.sqrt(2.))) / 2.\n",
    "\n",
    "    if (mean < a - 2 * std) or (mean > b + 2 * std):\n",
    "        warnings.warn(\"mean is more than 2 std from [a, b] in nn.init.trunc_normal_. \"\n",
    "                      \"The distribution of values may be incorrect.\",\n",
    "                      stacklevel=2)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Values are generated by using a truncated uniform distribution and\n",
    "        # then using the inverse CDF for the normal distribution.\n",
    "        # Get upper and lower cdf values\n",
    "        l = norm_cdf((a - mean) / std)\n",
    "        u = norm_cdf((b - mean) / std)\n",
    "\n",
    "        # Uniformly fill tensor with values from [l, u], then translate to\n",
    "        # [2l-1, 2u-1].\n",
    "        tensor.uniform_(2 * l - 1, 2 * u - 1)\n",
    "\n",
    "        # Use inverse cdf transform for normal distribution to get truncated\n",
    "        # standard normal\n",
    "        tensor.erfinv_()\n",
    "\n",
    "        # Transform to proper mean, std\n",
    "        tensor.mul_(std * math.sqrt(2.))\n",
    "        tensor.add_(mean)\n",
    "\n",
    "        # Clamp to ensure it's in the proper range\n",
    "        tensor.clamp_(min=a, max=b)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89a3c8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trunc_normal_(tensor, mean=0., std=1., a=-2., b=2.):\n",
    "    # type: (Tensor, float, float, float, float) -> Tensor\n",
    "    r\"\"\"Fills the input Tensor with values drawn from a truncated\n",
    "    normal distribution. The values are effectively drawn from the\n",
    "    normal distribution :math:`\\mathcal{N}(\\text{mean}, \\text{std}^2)`\n",
    "    with values outside :math:`[a, b]` redrawn until they are within\n",
    "    the bounds. The method used for generating the random values works\n",
    "    best when :math:`a \\leq \\text{mean} \\leq b`.\n",
    "    Args:\n",
    "        tensor: an n-dimensional `torch.Tensor`\n",
    "        mean: the mean of the normal distribution\n",
    "        std: the standard deviation of the normal distribution\n",
    "        a: the minimum cutoff value\n",
    "        b: the maximum cutoff value\n",
    "    Examples:\n",
    "        >>> w = torch.empty(3, 5)\n",
    "        >>> nn.init.trunc_normal_(w)\n",
    "    \"\"\"\n",
    "    return _no_grad_trunc_normal_(tensor, mean, std, a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1a226ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_vit_weights(module: nn.Module, name: str = '', head_bias: float = 0., jax_impl: bool = False):\n",
    "    \"\"\" ViT weight initialization\n",
    "    * When called without n, head_bias, jax_impl args it will behave exactly the same\n",
    "      as my original init for compatibility with prev hparam / downstream use cases (ie DeiT).\n",
    "    * When called w/ valid n (module name) and jax_impl=True, will (hopefully) match JAX impl\n",
    "    \"\"\"\n",
    "    if isinstance(module, nn.Linear):\n",
    "        if name.startswith('head'):\n",
    "            nn.init.zeros_(module.weight)\n",
    "            nn.init.constant_(module.bias, head_bias)\n",
    "        elif name.startswith('pre_logits'):\n",
    "            lecun_normal_(module.weight)\n",
    "            nn.init.zeros_(module.bias)\n",
    "        else:\n",
    "            if jax_impl:\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    if 'mlp' in name:\n",
    "                        nn.init.normal_(module.bias, std=1e-6)\n",
    "                    else:\n",
    "                        nn.init.zeros_(module.bias)\n",
    "            else:\n",
    "                trunc_normal_(module.weight, std=.02)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "    elif jax_impl and isinstance(module, nn.Conv2d):\n",
    "        # NOTE conv was left to pytorch default in my original init\n",
    "        lecun_normal_(module.weight)\n",
    "        if module.bias is not None:\n",
    "            nn.init.zeros_(module.bias)\n",
    "    elif isinstance(module, (nn.LayerNorm, nn.GroupNorm, nn.BatchNorm2d)):\n",
    "        nn.init.zeros_(module.bias)\n",
    "        nn.init.ones_(module.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0545a44",
   "metadata": {},
   "source": [
    "# Network Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7992fdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEmbed(nn.Module):\n",
    "    \"\"\" 2D Image to Patch Embedding\n",
    "    \"\"\"\n",
    "    def __init__(self, img_size=224, patch_size=16, in_chans=3, embed_dim=768, norm_layer=None, flatten=True):\n",
    "        super().__init__()\n",
    "        img_size = to_2tuple(img_size) # 224 -> (224,224)\n",
    "        patch_size = to_2tuple(patch_size) # 16 -> (16,16)\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.grid_size = (img_size[0] // patch_size[0], img_size[1] // patch_size[1])\n",
    "        self.num_patches = self.grid_size[0] * self.grid_size[1]\n",
    "        self.flatten = flatten\n",
    "\n",
    "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        self.norm = norm_layer(embed_dim) if norm_layer else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        _assert(H == self.img_size[0], f\"Input image height ({H}) doesn't match model ({self.img_size[0]}).\")\n",
    "        _assert(W == self.img_size[1], f\"Input image width ({W}) doesn't match model ({self.img_size[1]}).\")\n",
    "        x = self.proj(x)\n",
    "        if self.flatten:\n",
    "            x = x.flatten(2).transpose(1, 2)  # BCHW -> BNC\n",
    "        x = self.norm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1b5e7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mlp(nn.Module):\n",
    "    \"\"\" MLP as used in Vision Transformer, MLP-Mixer and related networks\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        drop_probs = to_2tuple(drop)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.drop1 = nn.Dropout(drop_probs[0])\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop2 = nn.Dropout(drop_probs[1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "852fbfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_path(x, drop_prob: float = 0., training: bool = False, scale_by_keep: bool = True):\n",
    "    \"\"\"Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks).\n",
    "    This is the same as the DropConnect impl I created for EfficientNet, etc networks, however,\n",
    "    the original name is misleading as 'Drop Connect' is a different form of dropout in a separate paper...\n",
    "    See discussion: https://github.com/tensorflow/tpu/issues/494#issuecomment-532968956 ... I've opted for\n",
    "    changing the layer and argument names to 'drop path' rather than mix DropConnect as a layer name and use\n",
    "    'survival rate' as the argument.\n",
    "    \"\"\"\n",
    "    if drop_prob == 0. or not training:\n",
    "        return x\n",
    "    keep_prob = 1 - drop_prob\n",
    "    shape = (x.shape[0],) + (1,) * (x.ndim - 1)  # work with diff dim tensors, not just 2D ConvNets\n",
    "    random_tensor = x.new_empty(shape).bernoulli_(keep_prob)\n",
    "    if keep_prob > 0.0 and scale_by_keep:\n",
    "        random_tensor.div_(keep_prob)\n",
    "    return x * random_tensor\n",
    "\n",
    "\n",
    "class DropPath(nn.Module):\n",
    "    \"\"\"Drop paths (Stochastic Depth) per sample  (when applied in main path of residual blocks).\n",
    "    \"\"\"\n",
    "    def __init__(self, drop_prob=None, scale_by_keep=True):\n",
    "        super(DropPath, self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.scale_by_keep = scale_by_keep\n",
    "\n",
    "    def forward(self, x):\n",
    "        return drop_path(x, self.drop_prob, self.training, self.scale_by_keep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faa94da",
   "metadata": {},
   "source": [
    "# ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdf8cf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, num_heads=8, qkv_bias=False, attn_drop=0., proj_drop=0.):\n",
    "        super().__init__()\n",
    "        assert dim % num_heads == 0, 'dim should be divisible by num_heads'\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = head_dim ** -0.5\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, C = x.shape\n",
    "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv.unbind(0)   # make torchscript happy (cannot use tensor as tuple)\n",
    "\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3624fc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop=0., attn_drop=0.,\n",
    "                 drop_path=0., act_layer=nn.GELU, norm_layer=nn.LayerNorm):\n",
    "        super().__init__()\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = Attention(dim, num_heads=num_heads, qkv_bias=qkv_bias, attn_drop=attn_drop, proj_drop=drop)\n",
    "        # NOTE: drop path for stochastic depth, we shall see if this is better than dropout here\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.drop_path(self.attn(self.norm1(x)))\n",
    "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "510aaaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisionTransformerTimm(nn.Module):\n",
    "    \"\"\" Vision Transformer Timm Version\n",
    "    A PyTorch impl of : `An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale`\n",
    "        - https://arxiv.org/abs/2010.11929\n",
    "    Includes distillation token & head support for `DeiT: Data-efficient Image Transformers`\n",
    "        - https://arxiv.org/abs/2012.12877\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, img_size=224, patch_size=16, in_chans=3, num_classes=1000, embed_dim=768, depth=12,\n",
    "                 num_heads=12, mlp_ratio=4., qkv_bias=True, representation_size=None, distilled=False,\n",
    "                 drop_rate=0., attn_drop_rate=0., drop_path_rate=0., embed_layer=PatchEmbed, norm_layer=None,\n",
    "                 act_layer=None, weight_init=''):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img_size (int, tuple): input image size\n",
    "            patch_size (int, tuple): patch size\n",
    "            in_chans (int): number of input channels\n",
    "            num_classes (int): number of classes for classification head\n",
    "            embed_dim (int): embedding dimension\n",
    "            depth (int): depth of transformer\n",
    "            num_heads (int): number of attention heads\n",
    "            mlp_ratio (int): ratio of mlp hidden dim to embedding dim\n",
    "            qkv_bias (bool): enable bias for qkv if True\n",
    "            representation_size (Optional[int]): enable and set representation layer (pre-logits) to this value if set\n",
    "            distilled (bool): model includes a distillation token and head as in DeiT models\n",
    "            drop_rate (float): dropout rate\n",
    "            attn_drop_rate (float): attention dropout rate\n",
    "            drop_path_rate (float): stochastic depth rate\n",
    "            embed_layer (nn.Module): patch embedding layer\n",
    "            norm_layer: (nn.Module): normalization layer\n",
    "            weight_init: (str): weight init scheme\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_features = self.embed_dim = embed_dim  # num_features for consistency with other models\n",
    "        self.num_tokens = 2 if distilled else 1\n",
    "        norm_layer = norm_layer or partial(nn.LayerNorm, eps=1e-6)\n",
    "        act_layer = act_layer or nn.GELU\n",
    "\n",
    "        self.patch_embed = embed_layer(\n",
    "            img_size=img_size, patch_size=patch_size, in_chans=in_chans, embed_dim=embed_dim)\n",
    "        num_patches = self.patch_embed.num_patches\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        self.dist_token = nn.Parameter(torch.zeros(1, 1, embed_dim)) if distilled else None\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + self.num_tokens, embed_dim))\n",
    "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
    "\n",
    "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, depth)]  # stochastic depth decay rule\n",
    "        self.blocks = nn.Sequential(*[\n",
    "            Block(\n",
    "                dim=embed_dim, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, drop=drop_rate,\n",
    "                attn_drop=attn_drop_rate, drop_path=dpr[i], norm_layer=norm_layer, act_layer=act_layer)\n",
    "            for i in range(depth)])\n",
    "        self.norm = norm_layer(embed_dim)\n",
    "\n",
    "        # Representation layer\n",
    "        if representation_size and not distilled:\n",
    "            self.num_features = representation_size\n",
    "            self.pre_logits = nn.Sequential(OrderedDict([\n",
    "                ('fc', nn.Linear(embed_dim, representation_size)),\n",
    "                ('act', nn.Tanh())\n",
    "            ]))\n",
    "        else:\n",
    "            self.pre_logits = nn.Identity()\n",
    "\n",
    "        # Classifier head(s)\n",
    "        self.head = nn.Linear(self.num_features, num_classes) if num_classes > 0 else nn.Identity()\n",
    "        self.head_dist = None\n",
    "        if distilled:\n",
    "            self.head_dist = nn.Linear(self.embed_dim, self.num_classes) if num_classes > 0 else nn.Identity()\n",
    "\n",
    "        self.init_weights(weight_init)\n",
    "\n",
    "    def init_weights(self, mode=''):\n",
    "        assert mode in ('jax', 'jax_nlhb', 'nlhb', '')\n",
    "        head_bias = -math.log(self.num_classes) if 'nlhb' in mode else 0.\n",
    "        trunc_normal_(self.pos_embed, std=.02)\n",
    "        if self.dist_token is not None:\n",
    "            trunc_normal_(self.dist_token, std=.02)\n",
    "        if mode.startswith('jax'):\n",
    "            # leave cls token as zeros to match jax impl\n",
    "            named_apply(partial(_init_vit_weights, head_bias=head_bias, jax_impl=True), self)\n",
    "        else:\n",
    "            trunc_normal_(self.cls_token, std=.02)\n",
    "            self.apply(_init_vit_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        # this fn left here for compat with downstream users\n",
    "        _init_vit_weights(m)\n",
    "\n",
    "    @torch.jit.ignore()\n",
    "    def load_pretrained(self, checkpoint_path, prefix=''):\n",
    "        _load_weights(self, checkpoint_path, prefix)\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay(self):\n",
    "        return {'pos_embed', 'cls_token', 'dist_token'}\n",
    "\n",
    "    def get_classifier(self):\n",
    "        if self.dist_token is None:\n",
    "            return self.head\n",
    "        else:\n",
    "            return self.head, self.head_dist\n",
    "\n",
    "    def reset_classifier(self, num_classes, global_pool=''):\n",
    "        self.num_classes = num_classes\n",
    "        self.head = nn.Linear(self.embed_dim, num_classes) if num_classes > 0 else nn.Identity()\n",
    "        if self.num_tokens == 2:\n",
    "            self.head_dist = nn.Linear(self.embed_dim, self.num_classes) if num_classes > 0 else nn.Identity()\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "        cls_token = self.cls_token.expand(x.shape[0], -1, -1)  # stole cls_tokens impl from Phil Wang, thanks\n",
    "        if self.dist_token is None:\n",
    "            x = torch.cat((cls_token, x), dim=1)\n",
    "        else:\n",
    "            x = torch.cat((cls_token, self.dist_token.expand(x.shape[0], -1, -1), x), dim=1)\n",
    "        x = self.pos_drop(x + self.pos_embed)\n",
    "        x = self.blocks(x)\n",
    "        x = self.norm(x)\n",
    "        if self.dist_token is None:\n",
    "            return self.pre_logits(x[:, 0])\n",
    "        else:\n",
    "            return x[:, 0], x[:, 1]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        if self.head_dist is not None:\n",
    "            x, x_dist = self.head(x[0]), self.head_dist(x[1])  # x must be a tuple\n",
    "            if self.training and not torch.jit.is_scripting():\n",
    "                # during inference, return the average of both classifier predictions\n",
    "                return x, x_dist\n",
    "            else:\n",
    "                return (x + x_dist) / 2\n",
    "        else:\n",
    "            x = self.head(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e514ba47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59cfd268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 768, 14, 14]         590,592\n",
      "          Identity-2             [-1, 196, 768]               0\n",
      "        PatchEmbed-3             [-1, 196, 768]               0\n",
      "           Dropout-4             [-1, 197, 768]               0\n",
      "         LayerNorm-5             [-1, 197, 768]           1,536\n",
      "            Linear-6            [-1, 197, 2304]       1,771,776\n",
      "           Dropout-7         [-1, 12, 197, 197]               0\n",
      "            Linear-8             [-1, 197, 768]         590,592\n",
      "           Dropout-9             [-1, 197, 768]               0\n",
      "        Attention-10             [-1, 197, 768]               0\n",
      "         Identity-11             [-1, 197, 768]               0\n",
      "        LayerNorm-12             [-1, 197, 768]           1,536\n",
      "           Linear-13            [-1, 197, 3072]       2,362,368\n",
      "             GELU-14            [-1, 197, 3072]               0\n",
      "          Dropout-15            [-1, 197, 3072]               0\n",
      "           Linear-16             [-1, 197, 768]       2,360,064\n",
      "          Dropout-17             [-1, 197, 768]               0\n",
      "              Mlp-18             [-1, 197, 768]               0\n",
      "         Identity-19             [-1, 197, 768]               0\n",
      "            Block-20             [-1, 197, 768]               0\n",
      "        LayerNorm-21             [-1, 197, 768]           1,536\n",
      "           Linear-22            [-1, 197, 2304]       1,771,776\n",
      "          Dropout-23         [-1, 12, 197, 197]               0\n",
      "           Linear-24             [-1, 197, 768]         590,592\n",
      "          Dropout-25             [-1, 197, 768]               0\n",
      "        Attention-26             [-1, 197, 768]               0\n",
      "         Identity-27             [-1, 197, 768]               0\n",
      "        LayerNorm-28             [-1, 197, 768]           1,536\n",
      "           Linear-29            [-1, 197, 3072]       2,362,368\n",
      "             GELU-30            [-1, 197, 3072]               0\n",
      "          Dropout-31            [-1, 197, 3072]               0\n",
      "           Linear-32             [-1, 197, 768]       2,360,064\n",
      "          Dropout-33             [-1, 197, 768]               0\n",
      "              Mlp-34             [-1, 197, 768]               0\n",
      "         Identity-35             [-1, 197, 768]               0\n",
      "            Block-36             [-1, 197, 768]               0\n",
      "        LayerNorm-37             [-1, 197, 768]           1,536\n",
      "           Linear-38            [-1, 197, 2304]       1,771,776\n",
      "          Dropout-39         [-1, 12, 197, 197]               0\n",
      "           Linear-40             [-1, 197, 768]         590,592\n",
      "          Dropout-41             [-1, 197, 768]               0\n",
      "        Attention-42             [-1, 197, 768]               0\n",
      "         Identity-43             [-1, 197, 768]               0\n",
      "        LayerNorm-44             [-1, 197, 768]           1,536\n",
      "           Linear-45            [-1, 197, 3072]       2,362,368\n",
      "             GELU-46            [-1, 197, 3072]               0\n",
      "          Dropout-47            [-1, 197, 3072]               0\n",
      "           Linear-48             [-1, 197, 768]       2,360,064\n",
      "          Dropout-49             [-1, 197, 768]               0\n",
      "              Mlp-50             [-1, 197, 768]               0\n",
      "         Identity-51             [-1, 197, 768]               0\n",
      "            Block-52             [-1, 197, 768]               0\n",
      "        LayerNorm-53             [-1, 197, 768]           1,536\n",
      "           Linear-54            [-1, 197, 2304]       1,771,776\n",
      "          Dropout-55         [-1, 12, 197, 197]               0\n",
      "           Linear-56             [-1, 197, 768]         590,592\n",
      "          Dropout-57             [-1, 197, 768]               0\n",
      "        Attention-58             [-1, 197, 768]               0\n",
      "         Identity-59             [-1, 197, 768]               0\n",
      "        LayerNorm-60             [-1, 197, 768]           1,536\n",
      "           Linear-61            [-1, 197, 3072]       2,362,368\n",
      "             GELU-62            [-1, 197, 3072]               0\n",
      "          Dropout-63            [-1, 197, 3072]               0\n",
      "           Linear-64             [-1, 197, 768]       2,360,064\n",
      "          Dropout-65             [-1, 197, 768]               0\n",
      "              Mlp-66             [-1, 197, 768]               0\n",
      "         Identity-67             [-1, 197, 768]               0\n",
      "            Block-68             [-1, 197, 768]               0\n",
      "        LayerNorm-69             [-1, 197, 768]           1,536\n",
      "           Linear-70            [-1, 197, 2304]       1,771,776\n",
      "          Dropout-71         [-1, 12, 197, 197]               0\n",
      "           Linear-72             [-1, 197, 768]         590,592\n",
      "          Dropout-73             [-1, 197, 768]               0\n",
      "        Attention-74             [-1, 197, 768]               0\n",
      "         Identity-75             [-1, 197, 768]               0\n",
      "        LayerNorm-76             [-1, 197, 768]           1,536\n",
      "           Linear-77            [-1, 197, 3072]       2,362,368\n",
      "             GELU-78            [-1, 197, 3072]               0\n",
      "          Dropout-79            [-1, 197, 3072]               0\n",
      "           Linear-80             [-1, 197, 768]       2,360,064\n",
      "          Dropout-81             [-1, 197, 768]               0\n",
      "              Mlp-82             [-1, 197, 768]               0\n",
      "         Identity-83             [-1, 197, 768]               0\n",
      "            Block-84             [-1, 197, 768]               0\n",
      "        LayerNorm-85             [-1, 197, 768]           1,536\n",
      "           Linear-86            [-1, 197, 2304]       1,771,776\n",
      "          Dropout-87         [-1, 12, 197, 197]               0\n",
      "           Linear-88             [-1, 197, 768]         590,592\n",
      "          Dropout-89             [-1, 197, 768]               0\n",
      "        Attention-90             [-1, 197, 768]               0\n",
      "         Identity-91             [-1, 197, 768]               0\n",
      "        LayerNorm-92             [-1, 197, 768]           1,536\n",
      "           Linear-93            [-1, 197, 3072]       2,362,368\n",
      "             GELU-94            [-1, 197, 3072]               0\n",
      "          Dropout-95            [-1, 197, 3072]               0\n",
      "           Linear-96             [-1, 197, 768]       2,360,064\n",
      "          Dropout-97             [-1, 197, 768]               0\n",
      "              Mlp-98             [-1, 197, 768]               0\n",
      "         Identity-99             [-1, 197, 768]               0\n",
      "           Block-100             [-1, 197, 768]               0\n",
      "       LayerNorm-101             [-1, 197, 768]           1,536\n",
      "          Linear-102            [-1, 197, 2304]       1,771,776\n",
      "         Dropout-103         [-1, 12, 197, 197]               0\n",
      "          Linear-104             [-1, 197, 768]         590,592\n",
      "         Dropout-105             [-1, 197, 768]               0\n",
      "       Attention-106             [-1, 197, 768]               0\n",
      "        Identity-107             [-1, 197, 768]               0\n",
      "       LayerNorm-108             [-1, 197, 768]           1,536\n",
      "          Linear-109            [-1, 197, 3072]       2,362,368\n",
      "            GELU-110            [-1, 197, 3072]               0\n",
      "         Dropout-111            [-1, 197, 3072]               0\n",
      "          Linear-112             [-1, 197, 768]       2,360,064\n",
      "         Dropout-113             [-1, 197, 768]               0\n",
      "             Mlp-114             [-1, 197, 768]               0\n",
      "        Identity-115             [-1, 197, 768]               0\n",
      "           Block-116             [-1, 197, 768]               0\n",
      "       LayerNorm-117             [-1, 197, 768]           1,536\n",
      "          Linear-118            [-1, 197, 2304]       1,771,776\n",
      "         Dropout-119         [-1, 12, 197, 197]               0\n",
      "          Linear-120             [-1, 197, 768]         590,592\n",
      "         Dropout-121             [-1, 197, 768]               0\n",
      "       Attention-122             [-1, 197, 768]               0\n",
      "        Identity-123             [-1, 197, 768]               0\n",
      "       LayerNorm-124             [-1, 197, 768]           1,536\n",
      "          Linear-125            [-1, 197, 3072]       2,362,368\n",
      "            GELU-126            [-1, 197, 3072]               0\n",
      "         Dropout-127            [-1, 197, 3072]               0\n",
      "          Linear-128             [-1, 197, 768]       2,360,064\n",
      "         Dropout-129             [-1, 197, 768]               0\n",
      "             Mlp-130             [-1, 197, 768]               0\n",
      "        Identity-131             [-1, 197, 768]               0\n",
      "           Block-132             [-1, 197, 768]               0\n",
      "       LayerNorm-133             [-1, 197, 768]           1,536\n",
      "          Linear-134            [-1, 197, 2304]       1,771,776\n",
      "         Dropout-135         [-1, 12, 197, 197]               0\n",
      "          Linear-136             [-1, 197, 768]         590,592\n",
      "         Dropout-137             [-1, 197, 768]               0\n",
      "       Attention-138             [-1, 197, 768]               0\n",
      "        Identity-139             [-1, 197, 768]               0\n",
      "       LayerNorm-140             [-1, 197, 768]           1,536\n",
      "          Linear-141            [-1, 197, 3072]       2,362,368\n",
      "            GELU-142            [-1, 197, 3072]               0\n",
      "         Dropout-143            [-1, 197, 3072]               0\n",
      "          Linear-144             [-1, 197, 768]       2,360,064\n",
      "         Dropout-145             [-1, 197, 768]               0\n",
      "             Mlp-146             [-1, 197, 768]               0\n",
      "        Identity-147             [-1, 197, 768]               0\n",
      "           Block-148             [-1, 197, 768]               0\n",
      "       LayerNorm-149             [-1, 197, 768]           1,536\n",
      "          Linear-150            [-1, 197, 2304]       1,771,776\n",
      "         Dropout-151         [-1, 12, 197, 197]               0\n",
      "          Linear-152             [-1, 197, 768]         590,592\n",
      "         Dropout-153             [-1, 197, 768]               0\n",
      "       Attention-154             [-1, 197, 768]               0\n",
      "        Identity-155             [-1, 197, 768]               0\n",
      "       LayerNorm-156             [-1, 197, 768]           1,536\n",
      "          Linear-157            [-1, 197, 3072]       2,362,368\n",
      "            GELU-158            [-1, 197, 3072]               0\n",
      "         Dropout-159            [-1, 197, 3072]               0\n",
      "          Linear-160             [-1, 197, 768]       2,360,064\n",
      "         Dropout-161             [-1, 197, 768]               0\n",
      "             Mlp-162             [-1, 197, 768]               0\n",
      "        Identity-163             [-1, 197, 768]               0\n",
      "           Block-164             [-1, 197, 768]               0\n",
      "       LayerNorm-165             [-1, 197, 768]           1,536\n",
      "          Linear-166            [-1, 197, 2304]       1,771,776\n",
      "         Dropout-167         [-1, 12, 197, 197]               0\n",
      "          Linear-168             [-1, 197, 768]         590,592\n",
      "         Dropout-169             [-1, 197, 768]               0\n",
      "       Attention-170             [-1, 197, 768]               0\n",
      "        Identity-171             [-1, 197, 768]               0\n",
      "       LayerNorm-172             [-1, 197, 768]           1,536\n",
      "          Linear-173            [-1, 197, 3072]       2,362,368\n",
      "            GELU-174            [-1, 197, 3072]               0\n",
      "         Dropout-175            [-1, 197, 3072]               0\n",
      "          Linear-176             [-1, 197, 768]       2,360,064\n",
      "         Dropout-177             [-1, 197, 768]               0\n",
      "             Mlp-178             [-1, 197, 768]               0\n",
      "        Identity-179             [-1, 197, 768]               0\n",
      "           Block-180             [-1, 197, 768]               0\n",
      "       LayerNorm-181             [-1, 197, 768]           1,536\n",
      "          Linear-182            [-1, 197, 2304]       1,771,776\n",
      "         Dropout-183         [-1, 12, 197, 197]               0\n",
      "          Linear-184             [-1, 197, 768]         590,592\n",
      "         Dropout-185             [-1, 197, 768]               0\n",
      "       Attention-186             [-1, 197, 768]               0\n",
      "        Identity-187             [-1, 197, 768]               0\n",
      "       LayerNorm-188             [-1, 197, 768]           1,536\n",
      "          Linear-189            [-1, 197, 3072]       2,362,368\n",
      "            GELU-190            [-1, 197, 3072]               0\n",
      "         Dropout-191            [-1, 197, 3072]               0\n",
      "          Linear-192             [-1, 197, 768]       2,360,064\n",
      "         Dropout-193             [-1, 197, 768]               0\n",
      "             Mlp-194             [-1, 197, 768]               0\n",
      "        Identity-195             [-1, 197, 768]               0\n",
      "           Block-196             [-1, 197, 768]               0\n",
      "       LayerNorm-197             [-1, 197, 768]           1,536\n",
      "        Identity-198                  [-1, 768]               0\n",
      "          Linear-199                 [-1, 1000]         769,000\n",
      "================================================================\n",
      "Total params: 86,415,592\n",
      "Trainable params: 86,415,592\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 408.54\n",
      "Params size (MB): 329.65\n",
      "Estimated Total Size (MB): 738.77\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(VisionTransformerTimm(), (3, 224, 224), device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9564b2",
   "metadata": {},
   "source": [
    "# ViT(Kaiming's Version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "daf12e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisionTransformer(VisionTransformerTimm):\n",
    "    \"\"\" Vision Transformer with support for global average pooling\n",
    "    \"\"\"\n",
    "    def __init__(self, global_pool=False, **kwargs):\n",
    "        super(VisionTransformer, self).__init__(**kwargs)\n",
    "\n",
    "        self.global_pool = global_pool\n",
    "        if self.global_pool:\n",
    "            norm_layer = kwargs['norm_layer']\n",
    "            embed_dim = kwargs['embed_dim']\n",
    "            self.fc_norm = norm_layer(embed_dim)\n",
    "\n",
    "            del self.norm  # remove the original norm\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        B = x.shape[0]\n",
    "        x = self.patch_embed(x)\n",
    "\n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1)  # stole cls_tokens impl from Phil Wang, thanks\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x = x + self.pos_embed\n",
    "        x = self.pos_drop(x)\n",
    "\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "\n",
    "        if self.global_pool:\n",
    "            x = x[:, 1:, :].mean(dim=1)  # global pool without cls token\n",
    "            outcome = self.fc_norm(x)\n",
    "        else:\n",
    "            x = self.norm(x)\n",
    "            outcome = x[:, 0]\n",
    "\n",
    "        return outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c48eb2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vit_base_patch16(**kwargs):\n",
    "    model = VisionTransformer(\n",
    "        patch_size=16, embed_dim=768, depth=12, num_heads=12, mlp_ratio=4, qkv_bias=True,\n",
    "        norm_layer=partial(nn.LayerNorm, eps=1e-6), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vit_large_patch16(**kwargs):\n",
    "    model = VisionTransformer(\n",
    "        patch_size=16, embed_dim=1024, depth=24, num_heads=16, mlp_ratio=4, qkv_bias=True,\n",
    "        norm_layer=partial(nn.LayerNorm, eps=1e-6), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vit_huge_patch14(**kwargs):\n",
    "    model = VisionTransformer(\n",
    "        patch_size=14, embed_dim=1280, depth=32, num_heads=16, mlp_ratio=4, qkv_bias=True,\n",
    "        norm_layer=partial(nn.LayerNorm, eps=1e-6), **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19841b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 768, 14, 14]         590,592\n",
      "          Identity-2             [-1, 196, 768]               0\n",
      "        PatchEmbed-3             [-1, 196, 768]               0\n",
      "           Dropout-4             [-1, 197, 768]               0\n",
      "         LayerNorm-5             [-1, 197, 768]           1,536\n",
      "            Linear-6            [-1, 197, 2304]       1,771,776\n",
      "           Dropout-7         [-1, 12, 197, 197]               0\n",
      "            Linear-8             [-1, 197, 768]         590,592\n",
      "           Dropout-9             [-1, 197, 768]               0\n",
      "        Attention-10             [-1, 197, 768]               0\n",
      "         Identity-11             [-1, 197, 768]               0\n",
      "        LayerNorm-12             [-1, 197, 768]           1,536\n",
      "           Linear-13            [-1, 197, 3072]       2,362,368\n",
      "             GELU-14            [-1, 197, 3072]               0\n",
      "          Dropout-15            [-1, 197, 3072]               0\n",
      "           Linear-16             [-1, 197, 768]       2,360,064\n",
      "          Dropout-17             [-1, 197, 768]               0\n",
      "              Mlp-18             [-1, 197, 768]               0\n",
      "         Identity-19             [-1, 197, 768]               0\n",
      "            Block-20             [-1, 197, 768]               0\n",
      "        LayerNorm-21             [-1, 197, 768]           1,536\n",
      "           Linear-22            [-1, 197, 2304]       1,771,776\n",
      "          Dropout-23         [-1, 12, 197, 197]               0\n",
      "           Linear-24             [-1, 197, 768]         590,592\n",
      "          Dropout-25             [-1, 197, 768]               0\n",
      "        Attention-26             [-1, 197, 768]               0\n",
      "         Identity-27             [-1, 197, 768]               0\n",
      "        LayerNorm-28             [-1, 197, 768]           1,536\n",
      "           Linear-29            [-1, 197, 3072]       2,362,368\n",
      "             GELU-30            [-1, 197, 3072]               0\n",
      "          Dropout-31            [-1, 197, 3072]               0\n",
      "           Linear-32             [-1, 197, 768]       2,360,064\n",
      "          Dropout-33             [-1, 197, 768]               0\n",
      "              Mlp-34             [-1, 197, 768]               0\n",
      "         Identity-35             [-1, 197, 768]               0\n",
      "            Block-36             [-1, 197, 768]               0\n",
      "        LayerNorm-37             [-1, 197, 768]           1,536\n",
      "           Linear-38            [-1, 197, 2304]       1,771,776\n",
      "          Dropout-39         [-1, 12, 197, 197]               0\n",
      "           Linear-40             [-1, 197, 768]         590,592\n",
      "          Dropout-41             [-1, 197, 768]               0\n",
      "        Attention-42             [-1, 197, 768]               0\n",
      "         Identity-43             [-1, 197, 768]               0\n",
      "        LayerNorm-44             [-1, 197, 768]           1,536\n",
      "           Linear-45            [-1, 197, 3072]       2,362,368\n",
      "             GELU-46            [-1, 197, 3072]               0\n",
      "          Dropout-47            [-1, 197, 3072]               0\n",
      "           Linear-48             [-1, 197, 768]       2,360,064\n",
      "          Dropout-49             [-1, 197, 768]               0\n",
      "              Mlp-50             [-1, 197, 768]               0\n",
      "         Identity-51             [-1, 197, 768]               0\n",
      "            Block-52             [-1, 197, 768]               0\n",
      "        LayerNorm-53             [-1, 197, 768]           1,536\n",
      "           Linear-54            [-1, 197, 2304]       1,771,776\n",
      "          Dropout-55         [-1, 12, 197, 197]               0\n",
      "           Linear-56             [-1, 197, 768]         590,592\n",
      "          Dropout-57             [-1, 197, 768]               0\n",
      "        Attention-58             [-1, 197, 768]               0\n",
      "         Identity-59             [-1, 197, 768]               0\n",
      "        LayerNorm-60             [-1, 197, 768]           1,536\n",
      "           Linear-61            [-1, 197, 3072]       2,362,368\n",
      "             GELU-62            [-1, 197, 3072]               0\n",
      "          Dropout-63            [-1, 197, 3072]               0\n",
      "           Linear-64             [-1, 197, 768]       2,360,064\n",
      "          Dropout-65             [-1, 197, 768]               0\n",
      "              Mlp-66             [-1, 197, 768]               0\n",
      "         Identity-67             [-1, 197, 768]               0\n",
      "            Block-68             [-1, 197, 768]               0\n",
      "        LayerNorm-69             [-1, 197, 768]           1,536\n",
      "           Linear-70            [-1, 197, 2304]       1,771,776\n",
      "          Dropout-71         [-1, 12, 197, 197]               0\n",
      "           Linear-72             [-1, 197, 768]         590,592\n",
      "          Dropout-73             [-1, 197, 768]               0\n",
      "        Attention-74             [-1, 197, 768]               0\n",
      "         Identity-75             [-1, 197, 768]               0\n",
      "        LayerNorm-76             [-1, 197, 768]           1,536\n",
      "           Linear-77            [-1, 197, 3072]       2,362,368\n",
      "             GELU-78            [-1, 197, 3072]               0\n",
      "          Dropout-79            [-1, 197, 3072]               0\n",
      "           Linear-80             [-1, 197, 768]       2,360,064\n",
      "          Dropout-81             [-1, 197, 768]               0\n",
      "              Mlp-82             [-1, 197, 768]               0\n",
      "         Identity-83             [-1, 197, 768]               0\n",
      "            Block-84             [-1, 197, 768]               0\n",
      "        LayerNorm-85             [-1, 197, 768]           1,536\n",
      "           Linear-86            [-1, 197, 2304]       1,771,776\n",
      "          Dropout-87         [-1, 12, 197, 197]               0\n",
      "           Linear-88             [-1, 197, 768]         590,592\n",
      "          Dropout-89             [-1, 197, 768]               0\n",
      "        Attention-90             [-1, 197, 768]               0\n",
      "         Identity-91             [-1, 197, 768]               0\n",
      "        LayerNorm-92             [-1, 197, 768]           1,536\n",
      "           Linear-93            [-1, 197, 3072]       2,362,368\n",
      "             GELU-94            [-1, 197, 3072]               0\n",
      "          Dropout-95            [-1, 197, 3072]               0\n",
      "           Linear-96             [-1, 197, 768]       2,360,064\n",
      "          Dropout-97             [-1, 197, 768]               0\n",
      "              Mlp-98             [-1, 197, 768]               0\n",
      "         Identity-99             [-1, 197, 768]               0\n",
      "           Block-100             [-1, 197, 768]               0\n",
      "       LayerNorm-101             [-1, 197, 768]           1,536\n",
      "          Linear-102            [-1, 197, 2304]       1,771,776\n",
      "         Dropout-103         [-1, 12, 197, 197]               0\n",
      "          Linear-104             [-1, 197, 768]         590,592\n",
      "         Dropout-105             [-1, 197, 768]               0\n",
      "       Attention-106             [-1, 197, 768]               0\n",
      "        Identity-107             [-1, 197, 768]               0\n",
      "       LayerNorm-108             [-1, 197, 768]           1,536\n",
      "          Linear-109            [-1, 197, 3072]       2,362,368\n",
      "            GELU-110            [-1, 197, 3072]               0\n",
      "         Dropout-111            [-1, 197, 3072]               0\n",
      "          Linear-112             [-1, 197, 768]       2,360,064\n",
      "         Dropout-113             [-1, 197, 768]               0\n",
      "             Mlp-114             [-1, 197, 768]               0\n",
      "        Identity-115             [-1, 197, 768]               0\n",
      "           Block-116             [-1, 197, 768]               0\n",
      "       LayerNorm-117             [-1, 197, 768]           1,536\n",
      "          Linear-118            [-1, 197, 2304]       1,771,776\n",
      "         Dropout-119         [-1, 12, 197, 197]               0\n",
      "          Linear-120             [-1, 197, 768]         590,592\n",
      "         Dropout-121             [-1, 197, 768]               0\n",
      "       Attention-122             [-1, 197, 768]               0\n",
      "        Identity-123             [-1, 197, 768]               0\n",
      "       LayerNorm-124             [-1, 197, 768]           1,536\n",
      "          Linear-125            [-1, 197, 3072]       2,362,368\n",
      "            GELU-126            [-1, 197, 3072]               0\n",
      "         Dropout-127            [-1, 197, 3072]               0\n",
      "          Linear-128             [-1, 197, 768]       2,360,064\n",
      "         Dropout-129             [-1, 197, 768]               0\n",
      "             Mlp-130             [-1, 197, 768]               0\n",
      "        Identity-131             [-1, 197, 768]               0\n",
      "           Block-132             [-1, 197, 768]               0\n",
      "       LayerNorm-133             [-1, 197, 768]           1,536\n",
      "          Linear-134            [-1, 197, 2304]       1,771,776\n",
      "         Dropout-135         [-1, 12, 197, 197]               0\n",
      "          Linear-136             [-1, 197, 768]         590,592\n",
      "         Dropout-137             [-1, 197, 768]               0\n",
      "       Attention-138             [-1, 197, 768]               0\n",
      "        Identity-139             [-1, 197, 768]               0\n",
      "       LayerNorm-140             [-1, 197, 768]           1,536\n",
      "          Linear-141            [-1, 197, 3072]       2,362,368\n",
      "            GELU-142            [-1, 197, 3072]               0\n",
      "         Dropout-143            [-1, 197, 3072]               0\n",
      "          Linear-144             [-1, 197, 768]       2,360,064\n",
      "         Dropout-145             [-1, 197, 768]               0\n",
      "             Mlp-146             [-1, 197, 768]               0\n",
      "        Identity-147             [-1, 197, 768]               0\n",
      "           Block-148             [-1, 197, 768]               0\n",
      "       LayerNorm-149             [-1, 197, 768]           1,536\n",
      "          Linear-150            [-1, 197, 2304]       1,771,776\n",
      "         Dropout-151         [-1, 12, 197, 197]               0\n",
      "          Linear-152             [-1, 197, 768]         590,592\n",
      "         Dropout-153             [-1, 197, 768]               0\n",
      "       Attention-154             [-1, 197, 768]               0\n",
      "        Identity-155             [-1, 197, 768]               0\n",
      "       LayerNorm-156             [-1, 197, 768]           1,536\n",
      "          Linear-157            [-1, 197, 3072]       2,362,368\n",
      "            GELU-158            [-1, 197, 3072]               0\n",
      "         Dropout-159            [-1, 197, 3072]               0\n",
      "          Linear-160             [-1, 197, 768]       2,360,064\n",
      "         Dropout-161             [-1, 197, 768]               0\n",
      "             Mlp-162             [-1, 197, 768]               0\n",
      "        Identity-163             [-1, 197, 768]               0\n",
      "           Block-164             [-1, 197, 768]               0\n",
      "       LayerNorm-165             [-1, 197, 768]           1,536\n",
      "          Linear-166            [-1, 197, 2304]       1,771,776\n",
      "         Dropout-167         [-1, 12, 197, 197]               0\n",
      "          Linear-168             [-1, 197, 768]         590,592\n",
      "         Dropout-169             [-1, 197, 768]               0\n",
      "       Attention-170             [-1, 197, 768]               0\n",
      "        Identity-171             [-1, 197, 768]               0\n",
      "       LayerNorm-172             [-1, 197, 768]           1,536\n",
      "          Linear-173            [-1, 197, 3072]       2,362,368\n",
      "            GELU-174            [-1, 197, 3072]               0\n",
      "         Dropout-175            [-1, 197, 3072]               0\n",
      "          Linear-176             [-1, 197, 768]       2,360,064\n",
      "         Dropout-177             [-1, 197, 768]               0\n",
      "             Mlp-178             [-1, 197, 768]               0\n",
      "        Identity-179             [-1, 197, 768]               0\n",
      "           Block-180             [-1, 197, 768]               0\n",
      "       LayerNorm-181             [-1, 197, 768]           1,536\n",
      "          Linear-182            [-1, 197, 2304]       1,771,776\n",
      "         Dropout-183         [-1, 12, 197, 197]               0\n",
      "          Linear-184             [-1, 197, 768]         590,592\n",
      "         Dropout-185             [-1, 197, 768]               0\n",
      "       Attention-186             [-1, 197, 768]               0\n",
      "        Identity-187             [-1, 197, 768]               0\n",
      "       LayerNorm-188             [-1, 197, 768]           1,536\n",
      "          Linear-189            [-1, 197, 3072]       2,362,368\n",
      "            GELU-190            [-1, 197, 3072]               0\n",
      "         Dropout-191            [-1, 197, 3072]               0\n",
      "          Linear-192             [-1, 197, 768]       2,360,064\n",
      "         Dropout-193             [-1, 197, 768]               0\n",
      "             Mlp-194             [-1, 197, 768]               0\n",
      "        Identity-195             [-1, 197, 768]               0\n",
      "           Block-196             [-1, 197, 768]               0\n",
      "       LayerNorm-197             [-1, 197, 768]           1,536\n",
      "          Linear-198                 [-1, 1000]         769,000\n",
      "================================================================\n",
      "Total params: 86,415,592\n",
      "Trainable params: 86,415,592\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 408.54\n",
      "Params size (MB): 329.65\n",
      "Estimated Total Size (MB): 738.76\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(vit_base_patch16(), (3, 224, 224), device='cpu')"
   ]
  },
  {
   "attachments": {
    "Screenshot%202022-03-19%20at%2021-18-33%20How%20does%20functools%20partial%20do%20what%20it%20does%20.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "aaccf203",
   "metadata": {},
   "source": [
    "![Screenshot%202022-03-19%20at%2021-18-33%20How%20does%20functools%20partial%20do%20what%20it%20does%20.png](attachment:Screenshot%202022-03-19%20at%2021-18-33%20How%20does%20functools%20partial%20do%20what%20it%20does%20.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328947b3",
   "metadata": {},
   "source": [
    "# Position Embedding for Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3c8b2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc6bc02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
      "        13.],\n",
      "       [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
      "        13.],\n",
      "       [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
      "        13.],\n",
      "       [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
      "        13.],\n",
      "       [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
      "        13.],\n",
      "       [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
      "        13.],\n",
      "       [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
      "        13.],\n",
      "       [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
      "        13.],\n",
      "       [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
      "        13.],\n",
      "       [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
      "        13.],\n",
      "       [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
      "        13.],\n",
      "       [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
      "        13.],\n",
      "       [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
      "        13.],\n",
      "       [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
      "        13.]], dtype=float32), array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.],\n",
      "       [ 2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
      "         2.],\n",
      "       [ 3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,\n",
      "         3.],\n",
      "       [ 4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,\n",
      "         4.],\n",
      "       [ 5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
      "         5.],\n",
      "       [ 6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
      "         6.],\n",
      "       [ 7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,\n",
      "         7.],\n",
      "       [ 8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,\n",
      "         8.],\n",
      "       [ 9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,\n",
      "         9.],\n",
      "       [10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10.,\n",
      "        10.],\n",
      "       [11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
      "        11.],\n",
      "       [12., 12., 12., 12., 12., 12., 12., 12., 12., 12., 12., 12., 12.,\n",
      "        12.],\n",
      "       [13., 13., 13., 13., 13., 13., 13., 13., 13., 13., 13., 13., 13.,\n",
      "        13.]], dtype=float32)]\n",
      "[[[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13.]\n",
      "  [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13.]\n",
      "  [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13.]\n",
      "  [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13.]\n",
      "  [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13.]\n",
      "  [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13.]\n",
      "  [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13.]\n",
      "  [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13.]\n",
      "  [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13.]\n",
      "  [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13.]\n",
      "  [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13.]\n",
      "  [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13.]\n",
      "  [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13.]\n",
      "  [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "  [ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.]\n",
      "  [ 3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.]\n",
      "  [ 4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.]\n",
      "  [ 5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.]\n",
      "  [ 6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.]\n",
      "  [ 7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.]\n",
      "  [ 8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.]\n",
      "  [ 9.  9.  9.  9.  9.  9.  9.  9.  9.  9.  9.  9.  9.  9.]\n",
      "  [10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      "  [11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11.]\n",
      "  [12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12.]\n",
      "  [13. 13. 13. 13. 13. 13. 13. 13. 13. 13. 13. 13. 13. 13.]]]\n",
      "[[[[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13.]\n",
      "   [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13.]\n",
      "   [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13.]\n",
      "   [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13.]\n",
      "   [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13.]\n",
      "   [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13.]\n",
      "   [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13.]\n",
      "   [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13.]\n",
      "   [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13.]\n",
      "   [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13.]\n",
      "   [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13.]\n",
      "   [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13.]\n",
      "   [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13.]\n",
      "   [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13.]]]\n",
      "\n",
      "\n",
      " [[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "   [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "   [ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.]\n",
      "   [ 3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.]\n",
      "   [ 4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.]\n",
      "   [ 5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.]\n",
      "   [ 6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.]\n",
      "   [ 7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.]\n",
      "   [ 8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.]\n",
      "   [ 9.  9.  9.  9.  9.  9.  9.  9.  9.  9.  9.  9.  9.  9.]\n",
      "   [10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      "   [11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11.]\n",
      "   [12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12.]\n",
      "   [13. 13. 13. 13. 13. 13. 13. 13. 13. 13. 13. 13. 13. 13.]]]]\n"
     ]
    }
   ],
   "source": [
    "grid_h = np.arange(14, dtype=np.float32)\n",
    "grid_w = np.arange(14, dtype=np.float32)\n",
    "grid = np.meshgrid(grid_w, grid_h)  # here w goes first\n",
    "print(grid)\n",
    "grid = np.stack(grid, axis=0)\n",
    "print(grid)\n",
    "\n",
    "grid = grid.reshape([2, 1, 14, 14])\n",
    "print(grid)\n",
    "#pos_embed = get_2d_sincos_pos_embed_from_grid(embed_dim, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a804f6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_1d_sincos_pos_embed_from_grid(embed_dim, pos):\n",
    "    \"\"\"\n",
    "    embed_dim: output dimension for each position\n",
    "    pos: a list of positions to be encoded: size (M,)\n",
    "    out: (M, D)\n",
    "    \"\"\"\n",
    "    assert embed_dim % 2 == 0\n",
    "    omega = np.arange(embed_dim // 2, dtype=np.float) \n",
    "    #print('omega: ',omega) # [0,..,383]\n",
    "    omega /= embed_dim / 2.\n",
    "    #print('omega: ',omega) #[0/384,..,383/384]\n",
    "    omega = 1. / 10000**omega  # (D/2,)\n",
    "    #print('omega: ',omega) #(384,)\n",
    "\n",
    "    pos = pos.reshape(-1)  # (M,)\n",
    "    #print('pos: ',pos) # [0,1,..,13,0,1,..,13,..,13] (196,)\n",
    "    out = np.einsum('m,d->md', pos, omega)  # (M, D/2), outer product\n",
    "    #print('out: ',out)\n",
    "    #print('out:',out.shape) (196,384)\n",
    "\n",
    "    emb_sin = np.sin(out) # (M, D/2)\n",
    "    #print('emb_sin: ',emb_sin)\n",
    "    emb_cos = np.cos(out) # (M, D/2)\n",
    "    #print('emb_cos: ',emb_cos)\n",
    "\n",
    "    emb = np.concatenate([emb_sin, emb_cos], axis=1)  # (M, D)\n",
    "    #print('emb: ',emb)\n",
    "    #print('emb: ',emb.shape) (196, 768)\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "702362fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20378/3431695617.py:8: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  omega = np.arange(embed_dim // 2, dtype=np.float)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [ 0.84147098,  0.82843076,  0.81525065, ...,  0.99999999,\n",
       "         0.99999999,  0.99999999],\n",
       "       [ 0.90929743,  0.92799403,  0.94423677, ...,  0.99999998,\n",
       "         0.99999998,  0.99999998],\n",
       "       ...,\n",
       "       [-0.99999021, -0.96734135, -0.87235683, ...,  0.9999993 ,\n",
       "         0.99999933,  0.99999937],\n",
       "       [-0.53657292, -0.75178799, -0.90374037, ...,  0.99999917,\n",
       "         0.99999921,  0.99999924],\n",
       "       [ 0.42016704,  0.12520125, -0.1743702 , ...,  0.99999902,\n",
       "         0.99999907,  0.99999911]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_1d_sincos_pos_embed_from_grid(embed_dim=768, pos=grid[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a97db00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2d_sincos_pos_embed_from_grid(embed_dim, grid):\n",
    "    assert embed_dim % 2 == 0\n",
    "\n",
    "    # use half of dimensions to encode grid_h\n",
    "    emb_h = get_1d_sincos_pos_embed_from_grid(embed_dim // 2, grid[0])  # (H*W, D/2)\n",
    "    #print('emb_h: ',emb_h)\n",
    "    #print('emb_h: ',emb_h.shape) (196,384)\n",
    "    emb_w = get_1d_sincos_pos_embed_from_grid(embed_dim // 2, grid[1])  # (H*W, D/2)\n",
    "    #print('emb_w: ',emb_w)\n",
    "    #print('emb_w: ',emb_w.shape) (196,384)\n",
    "\n",
    "    emb = np.concatenate([emb_h, emb_w], axis=1) # (H*W, D)\n",
    "    #print('emb: ',emb)\n",
    "    #print('emb: ',emb.shape) (196, 768)\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b885730",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20378/3431695617.py:8: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  omega = np.arange(embed_dim // 2, dtype=np.float)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [ 0.84147098,  0.81525065,  0.78859304, ...,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [ 0.90929743,  0.94423677,  0.9698361 , ...,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       ...,\n",
       "       [-0.99999021, -0.87235683, -0.53871858, ...,  0.99999887,\n",
       "         0.99999898,  0.99999907],\n",
       "       [-0.53657292, -0.90374037, -0.9956448 , ...,  0.99999887,\n",
       "         0.99999898,  0.99999907],\n",
       "       [ 0.42016704, -0.1743702 , -0.68575617, ...,  0.99999887,\n",
       "         0.99999898,  0.99999907]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_2d_sincos_pos_embed_from_grid(embed_dim=768, grid=grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "275b792c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2d_sincos_pos_embed(embed_dim, grid_size, cls_token=False):\n",
    "    \"\"\"\n",
    "    grid_size: int of the grid height and width\n",
    "    return:\n",
    "    pos_embed: [grid_size*grid_size, embed_dim] or [1+grid_size*grid_size, embed_dim] (w/ or w/o cls_token)\n",
    "    \"\"\"\n",
    "    grid_h = np.arange(grid_size, dtype=np.float32)\n",
    "    grid_w = np.arange(grid_size, dtype=np.float32)\n",
    "    grid = np.meshgrid(grid_w, grid_h)  # here w goes first\n",
    "    grid = np.stack(grid, axis=0)\n",
    "\n",
    "    grid = grid.reshape([2, 1, grid_size, grid_size])\n",
    "    pos_embed = get_2d_sincos_pos_embed_from_grid(embed_dim, grid)\n",
    "    if cls_token:\n",
    "        pos_embed = np.concatenate([np.zeros([1, embed_dim]), pos_embed], axis=0)\n",
    "    print(pos_embed.shape)\n",
    "    print(pos_embed)\n",
    "    return pos_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99c776d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(197, 768)\n",
      "[[ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  1.          1.\n",
      "   1.        ]\n",
      " [ 0.84147098  0.81525065  0.78859304 ...  1.          1.\n",
      "   1.        ]\n",
      " ...\n",
      " [-0.99999021 -0.87235683 -0.53871858 ...  0.99999887  0.99999898\n",
      "   0.99999907]\n",
      " [-0.53657292 -0.90374037 -0.9956448  ...  0.99999887  0.99999898\n",
      "   0.99999907]\n",
      " [ 0.42016704 -0.1743702  -0.68575617 ...  0.99999887  0.99999898\n",
      "   0.99999907]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20378/3431695617.py:8: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  omega = np.arange(embed_dim // 2, dtype=np.float)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [ 0.84147098,  0.81525065,  0.78859304, ...,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       ...,\n",
       "       [-0.99999021, -0.87235683, -0.53871858, ...,  0.99999887,\n",
       "         0.99999898,  0.99999907],\n",
       "       [-0.53657292, -0.90374037, -0.9956448 , ...,  0.99999887,\n",
       "         0.99999898,  0.99999907],\n",
       "       [ 0.42016704, -0.1743702 , -0.68575617, ...,  0.99999887,\n",
       "         0.99999898,  0.99999907]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_2d_sincos_pos_embed(embed_dim=768, grid_size=14, cls_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0bd89c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2d_sincos_pos_embed(embed_dim, grid_size, cls_token=False):\n",
    "    \"\"\"\n",
    "    grid_size: int of the grid height and width\n",
    "    return:\n",
    "    pos_embed: [grid_size*grid_size, embed_dim] or [1+grid_size*grid_size, embed_dim] (w/ or w/o cls_token)\n",
    "    \"\"\"\n",
    "    grid_h = np.arange(grid_size, dtype=np.float32)\n",
    "    grid_w = np.arange(grid_size, dtype=np.float32)\n",
    "    grid = np.meshgrid(grid_w, grid_h)  # here w goes first\n",
    "    grid = np.stack(grid, axis=0)\n",
    "\n",
    "    grid = grid.reshape([2, 1, grid_size, grid_size])\n",
    "    pos_embed = get_2d_sincos_pos_embed_from_grid(embed_dim, grid)\n",
    "    if cls_token:\n",
    "        pos_embed = np.concatenate([np.zeros([1, embed_dim]), pos_embed], axis=0)\n",
    "    return pos_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "62eb8cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2d_sincos_pos_embed_from_grid(embed_dim, grid):\n",
    "    assert embed_dim % 2 == 0\n",
    "\n",
    "    # use half of dimensions to encode grid_h\n",
    "    emb_h = get_1d_sincos_pos_embed_from_grid(embed_dim // 2, grid[0])  # (H*W, D/2)\n",
    "    emb_w = get_1d_sincos_pos_embed_from_grid(embed_dim // 2, grid[1])  # (H*W, D/2)\n",
    "\n",
    "    emb = np.concatenate([emb_h, emb_w], axis=1) # (H*W, D)\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4bc05b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_1d_sincos_pos_embed_from_grid(embed_dim, pos):\n",
    "    \"\"\"\n",
    "    embed_dim: output dimension for each position\n",
    "    pos: a list of positions to be encoded: size (M,)\n",
    "    out: (M, D)\n",
    "    \"\"\"\n",
    "    assert embed_dim % 2 == 0\n",
    "    omega = np.arange(embed_dim // 2, dtype=np.float)\n",
    "    omega /= embed_dim / 2.\n",
    "    omega = 1. / 10000**omega  # (D/2,)\n",
    "\n",
    "    pos = pos.reshape(-1)  # (M,)\n",
    "    out = np.einsum('m,d->md', pos, omega)  # (M, D/2), outer product\n",
    "\n",
    "    emb_sin = np.sin(out) # (M, D/2)\n",
    "    emb_cos = np.cos(out) # (M, D/2)\n",
    "\n",
    "    emb = np.concatenate([emb_sin, emb_cos], axis=1)  # (M, D)\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809e470f",
   "metadata": {},
   "source": [
    "# MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4837fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PatchEmbed(img_size=224, patch_size=16, in_chans=3, embed_dim=768).grid_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b2389b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9291, 0.1797, 0.0851],\n",
      "         [0.5843, 0.9601, 0.8473],\n",
      "         [0.1176, 0.5848, 0.9984],\n",
      "         [0.3123, 0.7235, 0.8236]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(size=(1,4,3))\n",
    "print(x)\n",
    "mask_ratio = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "17585f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noise:  tensor([[0.4658, 0.7359, 0.6731, 0.9613]])\n",
      "ids_shuffle:  tensor([[0, 2, 1, 3]])\n",
      "ids_restore:  tensor([[0, 2, 1, 3]])\n",
      "ids_keep:  tensor([[0, 2]])\n",
      "ids_keep:  tensor([[[0],\n",
      "         [2]]])\n",
      "ids_keep:  tensor([[[0, 0, 0],\n",
      "         [2, 2, 2]]])\n",
      "x_masked:  tensor([[[0.9291, 0.1797, 0.0851],\n",
      "         [0.1176, 0.5848, 0.9984]]])\n",
      "mask:  tensor([[1., 1., 1., 1.]])\n",
      "mask:  tensor([[0., 0., 1., 1.]])\n",
      "mask:  tensor([[0., 1., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "N, L, D = x.shape  # batch, length, dim\n",
    "len_keep = int(L * (1 - mask_ratio))\n",
    "        \n",
    "noise = torch.rand(N, L, device=x.device)  # noise in [0, 1]\n",
    "print('noise: ', noise)\n",
    "\n",
    "\n",
    "# sort noise for each sample\n",
    "ids_shuffle = torch.argsort(noise, dim=1)  # ascend: small is keep, large is remove\n",
    "print('ids_shuffle: ',ids_shuffle) # arg sort the noise\n",
    "ids_restore = torch.argsort(ids_shuffle, dim=1)\n",
    "print('ids_restore: ',ids_restore) # record the location of [0,1,2,...] for further masking \n",
    "\n",
    "# keep the first subset\n",
    "ids_keep = ids_shuffle[:, :len_keep]\n",
    "print('ids_keep: ',ids_keep)\n",
    "print('ids_keep: ',ids_keep.unsqueeze(-1))\n",
    "print('ids_keep: ',ids_keep.unsqueeze(-1).repeat(1, 1, D))\n",
    "x_masked = torch.gather(x, dim=1, index=ids_keep.unsqueeze(-1).repeat(1, 1, D))\n",
    "print('x_masked: ',x_masked) # mask for data\n",
    "\n",
    "# generate the binary mask: 0 is keep, 1 is remove\n",
    "mask = torch.ones([N, L], device=x.device)\n",
    "print('mask: ',mask)\n",
    "mask[:, :len_keep] = 0\n",
    "print('mask: ',mask)\n",
    "# unshuffle to get the binary mask\n",
    "mask = torch.gather(mask, dim=1, index=ids_restore) # recover to the original order\n",
    "print('mask: ',mask) # mask for position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c79474ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[0., 0., 0.]]], requires_grad=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_mask_token = nn.Parameter(torch.zeros(1, 1, 3))\n",
    "self_mask_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ec28792f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_restore.shape[1] - x_masked.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8c502917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.],\n",
       "         [0., 0., 0.]]], grad_fn=<RepeatBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_mask_token.repeat(x_masked.shape[0], ids_restore.shape[1] - x_masked.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3aa97777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 2, 1, 3]])\n",
      "tensor([[[0],\n",
      "         [2],\n",
      "         [1],\n",
      "         [3]]])\n",
      "tensor([[[0, 0, 0],\n",
      "         [2, 2, 2],\n",
      "         [1, 1, 1],\n",
      "         [3, 3, 3]]])\n"
     ]
    }
   ],
   "source": [
    "print(ids_restore)\n",
    "print(ids_restore.unsqueeze(-1))\n",
    "print(ids_restore.unsqueeze(-1).repeat(1, 1, x_masked.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "45f903a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_:  tensor([[[0.9291, 0.1797, 0.0851],\n",
      "         [0.1176, 0.5848, 0.9984],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000]]], grad_fn=<CatBackward0>)\n",
      "x_:  tensor([[[0.9291, 0.1797, 0.0851],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.1176, 0.5848, 0.9984],\n",
      "         [0.0000, 0.0000, 0.0000]]], grad_fn=<GatherBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mask_tokens = self_mask_token.repeat(x_masked.shape[0], ids_restore.shape[1] - x_masked.shape[1], 1)\n",
    "x_ = torch.cat([x_masked, mask_tokens], dim=1)\n",
    "print('x_: ',x_)\n",
    "x_ = torch.gather(x_, dim=1, index=ids_restore.unsqueeze(-1).repeat(1, 1, x.shape[2]))  # unshuffle\n",
    "print('x_: ',x_)\n",
    "#x = torch.cat([x[:, :1, :], x_], dim=1)  # append cls token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2bd381f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedAutoencoderViT(nn.Module):\n",
    "    \"\"\" Masked Autoencoder with VisionTransformer backbone\n",
    "    \"\"\"\n",
    "    def __init__(self, img_size=224, patch_size=16, in_chans=3,\n",
    "                 embed_dim=1024, depth=24, num_heads=16,\n",
    "                 decoder_embed_dim=512, decoder_depth=8, decoder_num_heads=16,\n",
    "                 mlp_ratio=4., norm_layer=nn.LayerNorm, norm_pix_loss=False):\n",
    "        super().__init__()\n",
    "\n",
    "        # --------------------------------------------------------------------------\n",
    "        # MAE encoder specifics\n",
    "        self.patch_embed = PatchEmbed(img_size, patch_size, in_chans, embed_dim)\n",
    "        num_patches = self.patch_embed.num_patches # 196\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 1, embed_dim), requires_grad=False)  \n",
    "        # fixed sin-cos embedding\n",
    "\n",
    "        self.blocks = nn.ModuleList([\n",
    "            Block(embed_dim, num_heads, mlp_ratio, qkv_bias=True, qk_scale=None, norm_layer=norm_layer)\n",
    "            for i in range(depth)])\n",
    "        self.norm = norm_layer(embed_dim)\n",
    "        # --------------------------------------------------------------------------\n",
    "\n",
    "        # --------------------------------------------------------------------------\n",
    "        # MAE decoder specifics\n",
    "        self.decoder_embed = nn.Linear(embed_dim, decoder_embed_dim, bias=True) # nn.Linear(768, 512)\n",
    "\n",
    "        self.mask_token = nn.Parameter(torch.zeros(1, 1, decoder_embed_dim))\n",
    "\n",
    "        self.decoder_pos_embed = nn.Parameter(torch.zeros(1, num_patches + 1, decoder_embed_dim), requires_grad=False)  # fixed sin-cos embedding\n",
    "\n",
    "        self.decoder_blocks = nn.ModuleList([\n",
    "            Block(decoder_embed_dim, decoder_num_heads, mlp_ratio, qkv_bias=True, qk_scale=None, norm_layer=norm_layer)\n",
    "            for i in range(decoder_depth)])\n",
    "\n",
    "        self.decoder_norm = norm_layer(decoder_embed_dim)\n",
    "        self.decoder_pred = nn.Linear(decoder_embed_dim, patch_size**2 * in_chans, bias=True) # decoder to patch\n",
    "        # --------------------------------------------------------------------------\n",
    "\n",
    "        self.norm_pix_loss = norm_pix_loss\n",
    "\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        # initialization\n",
    "        # initialize (and freeze) pos_embed by sin-cos embedding\n",
    "        pos_embed = get_2d_sincos_pos_embed(self.pos_embed.shape[-1], int(self.patch_embed.num_patches**.5), cls_token=True)\n",
    "        self.pos_embed.data.copy_(torch.from_numpy(pos_embed).float().unsqueeze(0))\n",
    "\n",
    "        decoder_pos_embed = get_2d_sincos_pos_embed(self.decoder_pos_embed.shape[-1], int(self.patch_embed.num_patches**.5), cls_token=True)\n",
    "        self.decoder_pos_embed.data.copy_(torch.from_numpy(decoder_pos_embed).float().unsqueeze(0))\n",
    "\n",
    "        # initialize patch_embed like nn.Linear (instead of nn.Conv2d)\n",
    "        w = self.patch_embed.proj.weight.data\n",
    "        torch.nn.init.xavier_uniform_(w.view([w.shape[0], -1]))\n",
    "\n",
    "        # timm's trunc_normal_(std=.02) is effectively normal_(std=0.02) as cutoff is too big (2.)\n",
    "        torch.nn.init.normal_(self.cls_token, std=.02)\n",
    "        torch.nn.init.normal_(self.mask_token, std=.02)\n",
    "\n",
    "        # initialize nn.Linear and nn.LayerNorm\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            # we use xavier_uniform following official JAX ViT:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "    def patchify(self, imgs):\n",
    "        \"\"\"\n",
    "        imgs: (N, 3, H, W) #(B, 3, 224, 224)\n",
    "        x: (N, L, patch_size**2 *3) #(B, 196, 768)\n",
    "        \"\"\"\n",
    "        p = self.patch_embed.patch_size[0]\n",
    "        assert imgs.shape[2] == imgs.shape[3] and imgs.shape[2] % p == 0\n",
    "\n",
    "        h = w = imgs.shape[2] // p # 14\n",
    "        x = imgs.reshape(shape=(imgs.shape[0], 3, h, p, w, p)) # [B, 3, 224, 224] -> [B, 3, 14, 16, 14, 16]\n",
    "        x = torch.einsum('nchpwq->nhwpqc', x) # [B, 3, 14, 16, 14, 16] -> [B ,14, 14, 16, 16, 3]\n",
    "        x = x.reshape(shape=(imgs.shape[0], h * w, p**2 * 3)) # [B ,14, 14, 16, 16, 3] -> [B, 196, 768]\n",
    "        return x\n",
    "\n",
    "    def unpatchify(self, x):\n",
    "        \"\"\"\n",
    "        x: (N, L, patch_size**2 *3)\n",
    "        imgs: (N, 3, H, W)\n",
    "        \"\"\"\n",
    "        p = self.patch_embed.patch_size[0] \n",
    "        h = w = int(x.shape[1]**.5) # 14\n",
    "        assert h * w == x.shape[1]\n",
    "        \n",
    "        x = x.reshape(shape=(x.shape[0], h, w, p, p, 3))\n",
    "        x = torch.einsum('nhwpqc->nchpwq', x)\n",
    "        imgs = x.reshape(shape=(x.shape[0], 3, h * p, h * p))\n",
    "        return imgs\n",
    "\n",
    "    def random_masking(self, x, mask_ratio):\n",
    "        \"\"\"\n",
    "        Perform per-sample random masking by per-sample shuffling.\n",
    "        Per-sample shuffling is done by argsort random noise.\n",
    "        x: [N, L, D], sequence\n",
    "        \"\"\"\n",
    "        N, L, D = x.shape  # batch, length, dim\n",
    "        len_keep = int(L * (1 - mask_ratio))\n",
    "        \n",
    "        noise = torch.rand(N, L, device=x.device)  # noise in [0, 1]\n",
    "        \n",
    "        # sort noise for each sample\n",
    "        ids_shuffle = torch.argsort(noise, dim=1)  # ascend: small is keep, large is remove\n",
    "        ids_restore = torch.argsort(ids_shuffle, dim=1)\n",
    "\n",
    "        # keep the first subset\n",
    "        ids_keep = ids_shuffle[:, :len_keep]\n",
    "        x_masked = torch.gather(x, dim=1, index=ids_keep.unsqueeze(-1).repeat(1, 1, D))\n",
    "\n",
    "        # generate the binary mask: 0 is keep, 1 is remove\n",
    "        mask = torch.ones([N, L], device=x.device)\n",
    "        mask[:, :len_keep] = 0\n",
    "        # unshuffle to get the binary mask\n",
    "        mask = torch.gather(mask, dim=1, index=ids_restore)\n",
    "\n",
    "        return x_masked, mask, ids_restore\n",
    "\n",
    "    def forward_encoder(self, x, mask_ratio):\n",
    "        # embed patches\n",
    "        x = self.patch_embed(x)\n",
    "\n",
    "        # add pos embed w/o cls token\n",
    "        x = x + self.pos_embed[:, 1:, :]\n",
    "\n",
    "        # masking: length -> length * mask_ratio\n",
    "        x, mask, ids_restore = self.random_masking(x, mask_ratio)\n",
    "        \n",
    "        # x records patches that will be used while mask records patches that have been removed\n",
    "        # ids_restore record the location of [0,1,2,...] for further masking \n",
    "\n",
    "        # append cls token\n",
    "        cls_token = self.cls_token + self.pos_embed[:, :1, :]\n",
    "        cls_tokens = cls_token.expand(x.shape[0], -1, -1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "\n",
    "        # apply Transformer blocks\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "        x = self.norm(x)\n",
    "\n",
    "        return x, mask, ids_restore\n",
    "\n",
    "    def forward_decoder(self, x, ids_restore):\n",
    "        # embed tokens\n",
    "        x = self.decoder_embed(x)\n",
    "\n",
    "        # append mask tokens to sequence\n",
    "        mask_tokens = self.mask_token.repeat(x.shape[0], ids_restore.shape[1] + 1 - x.shape[1], 1)\n",
    "        x_ = torch.cat([x[:, 1:, :], mask_tokens], dim=1)  # no cls token\n",
    "        x_ = torch.gather(x_, dim=1, index=ids_restore.unsqueeze(-1).repeat(1, 1, x.shape[2]))  # unshuffle\n",
    "        x = torch.cat([x[:, :1, :], x_], dim=1)  # append cls token\n",
    "\n",
    "        # add pos embed\n",
    "        x = x + self.decoder_pos_embed\n",
    "\n",
    "        # apply Transformer blocks\n",
    "        for blk in self.decoder_blocks:\n",
    "            x = blk(x)\n",
    "        x = self.decoder_norm(x)\n",
    "\n",
    "        # predictor projection\n",
    "        x = self.decoder_pred(x)\n",
    "\n",
    "        # remove cls token\n",
    "        x = x[:, 1:, :]\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward_loss(self, imgs, pred, mask):\n",
    "        \"\"\"\n",
    "        imgs: [N, 3, H, W]\n",
    "        pred: [N, L, p*p*3]\n",
    "        mask: [N, L], 0 is keep, 1 is remove, \n",
    "        \"\"\"\n",
    "        target = self.patchify(imgs)\n",
    "        if self.norm_pix_loss:\n",
    "            mean = target.mean(dim=-1, keepdim=True)\n",
    "            var = target.var(dim=-1, keepdim=True)\n",
    "            target = (target - mean) / (var + 1.e-6)**.5\n",
    "\n",
    "        loss = (pred - target) ** 2\n",
    "        loss = loss.mean(dim=-1)  # [N, L], mean loss per patch\n",
    "\n",
    "        loss = (loss * mask).sum() / mask.sum()  # mean loss on removed patches\n",
    "        # only calculate loss on masked patches\n",
    "        return loss\n",
    "\n",
    "    def forward(self, imgs, mask_ratio=0.75):\n",
    "        latent, mask, ids_restore = self.forward_encoder(imgs, mask_ratio)\n",
    "        pred = self.forward_decoder(latent, ids_restore)  # [N, L, p*p*3]\n",
    "        loss = self.forward_loss(imgs, pred, mask)\n",
    "        return loss, pred, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "702d650a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_vit_base_patch16_dec512d8b(**kwargs):\n",
    "    model = MaskedAutoencoderViT(\n",
    "        patch_size=16, embed_dim=768, depth=12, num_heads=12,\n",
    "        decoder_embed_dim=512, decoder_depth=8, decoder_num_heads=16,\n",
    "        mlp_ratio=4, norm_layer=partial(nn.LayerNorm, eps=1e-6), **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d1157e",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "613234a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.randn(8, 3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ba5c017e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20378/2456280899.py:8: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  omega = np.arange(embed_dim // 2, dtype=np.float)\n"
     ]
    }
   ],
   "source": [
    "model = mae_vit_base_patch16_dec512d8b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "074c7763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.8490, grad_fn=<DivBackward0>),\n",
       " tensor([[[ 0.6995,  0.5019,  1.3947,  ...,  1.1205, -0.9081,  0.1334],\n",
       "          [ 0.9074,  0.6160,  0.8780,  ...,  0.5689, -0.6779,  0.4867],\n",
       "          [ 0.8140,  0.4418,  1.2419,  ...,  1.0433, -0.9677,  0.2085],\n",
       "          ...,\n",
       "          [ 1.4002,  0.6859,  1.3654,  ...,  0.4943, -1.2859,  0.2011],\n",
       "          [ 1.5061,  0.6085,  1.3184,  ...,  0.4432, -1.2806,  0.0582],\n",
       "          [ 1.5177,  0.5966,  1.2995,  ...,  0.3471, -1.3489,  0.0295]],\n",
       " \n",
       "         [[ 0.6272,  0.4705,  1.5117,  ...,  1.0678, -0.9965,  0.1529],\n",
       "          [ 0.6484,  0.4279,  1.4114,  ...,  1.0436, -1.0049,  0.1988],\n",
       "          [ 0.7230,  0.4008,  1.3506,  ...,  0.9924, -1.0778,  0.2423],\n",
       "          ...,\n",
       "          [ 1.3810,  1.6755,  0.0996,  ...,  0.6344, -1.5846,  0.7858],\n",
       "          [ 1.5166,  1.7469,  0.1386,  ...,  1.4141, -1.6785,  0.8473],\n",
       "          [ 1.0011,  1.4582,  0.8351,  ...,  0.7290, -1.2405,  0.3536]],\n",
       " \n",
       "         [[ 0.5862,  0.4332,  1.3674,  ...,  1.2107, -0.9084,  0.1736],\n",
       "          [ 0.6192,  0.3924,  1.2706,  ...,  1.1857, -0.9073,  0.2166],\n",
       "          [ 0.2439,  0.6202,  0.6917,  ...,  0.5453, -0.4829,  0.5642],\n",
       "          ...,\n",
       "          [ 1.2664,  0.6750,  1.3194,  ...,  0.5829, -1.3357,  0.2356],\n",
       "          [ 0.7357,  1.4849,  1.1412,  ...,  0.0977, -1.0906,  0.8608],\n",
       "          [ 1.3909,  0.5808,  1.2500,  ...,  0.4438, -1.4026,  0.0870]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.8913,  1.0821,  0.6796,  ...,  0.6014, -1.4798,  0.4476],\n",
       "          [ 0.5216,  0.6066,  1.4092,  ...,  1.2685, -0.9591,  0.2221],\n",
       "          [ 0.5964,  0.5742,  1.3398,  ...,  1.2176, -1.0249,  0.2684],\n",
       "          ...,\n",
       "          [ 1.1993,  0.8459,  1.4212,  ...,  0.6940, -1.3592,  0.2144],\n",
       "          [ 1.1947,  1.5751,  0.5932,  ...,  0.6263, -1.2880,  0.5929],\n",
       "          [ 1.4526,  2.0142, -0.2459,  ...,  1.3796, -2.2574,  0.5445]],\n",
       " \n",
       "         [[ 0.4627,  0.6213,  1.4190,  ...,  1.1446, -0.8845,  0.1718],\n",
       "          [ 0.4905,  0.5803,  1.3128,  ...,  1.1265, -0.8872,  0.2215],\n",
       "          [ 0.5603,  0.5545,  1.2460,  ...,  1.0760, -0.9512,  0.2654],\n",
       "          ...,\n",
       "          [ 1.1443,  0.8533,  1.3733,  ...,  0.5506, -1.2815,  0.2488],\n",
       "          [ 1.2494,  0.7766,  1.3271,  ...,  0.4984, -1.2724,  0.1159],\n",
       "          [ 1.1023,  1.0696,  0.3517,  ...,  0.5633, -1.5079,  0.8544]],\n",
       " \n",
       "         [[ 0.5262,  0.5085,  1.4300,  ...,  1.1585, -0.8121,  0.2465],\n",
       "          [ 0.5558,  0.4563,  1.3171,  ...,  1.1238, -0.8140,  0.2909],\n",
       "          [ 0.6294,  0.4221,  1.2397,  ...,  1.0607, -0.8751,  0.3236],\n",
       "          ...,\n",
       "          [ 0.9280,  1.3881,  0.9759,  ...,  0.8563, -1.5300,  0.7520],\n",
       "          [ 1.2658,  0.6384,  1.3296,  ...,  0.5207, -1.1802,  0.1445],\n",
       "          [ 0.9239,  1.2650,  0.7619,  ...,  0.3626, -1.5479,  0.4464]]],\n",
       "        grad_fn=<SliceBackward0>),\n",
       " tensor([[1., 0., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "         [1., 1., 0.,  ..., 1., 0., 1.],\n",
       "         ...,\n",
       "         [0., 1., 1.,  ..., 1., 0., 0.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 0.],\n",
       "         [1., 1., 1.,  ..., 0., 1., 0.]]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = model(images)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a3d104",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
